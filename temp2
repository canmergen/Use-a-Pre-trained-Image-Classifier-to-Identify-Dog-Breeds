def align_region_texts_v4(
    paddle_ocr_texts,
    paddle_ocr_regions,
    fuzzy_threshold: int = 90,
    length_tolerance: int = 2,
):
    """
    paddle_ocr_regions içindeki text değerlerini,
    paddle_ocr_texts içindeki uzun ham metinden daha doğru eşleşmelerle günceller.
    'T.C.' gibi kısa ve noktalı ifadeler bozulmaz.
    """

    # -------------------------------
    # 1) Yardımcı fonksiyonlar
    # -------------------------------
    import re, unicodedata
    from rapidfuzz import fuzz
    from typing import Any, Dict, List, Tuple

    TR_MAP = str.maketrans({
        "İ": "I", "ı": "i",
        "â": "a", "î": "i", "û": "u",
    })

    def _norm(s: str) -> str:
        """T.C., A.Ş. gibi kısaltmaları bozmadan normalize eder."""
        if not isinstance(s, str):
            return ""
        s = s.translate(TR_MAP)
        s = unicodedata.normalize("NFC", s)
        s = re.sub(r"\s+", " ", s).strip().lower()
        return s

    def _has_number(s: str) -> bool:
        return any(ch.isdigit() for ch in s)

    def _get_text(x: Any) -> str:
        """region içinde 'text', 'extractedText', 'extracted_text', 'full_text' hangisi varsa çeker."""
        if isinstance(x, str):
            return x
        if isinstance(x, dict):
            for k in ("text", "extractedText", "extracted_text", "full_text"):
                if k in x and isinstance(x[k], str):
                    return x[k]
        return ""

    def _build_norm_stream_with_map(src: str) -> Tuple[str, List[int]]:
        """
        Normalized stream + orijinal karakter index mapping.
        (fuzzy pencere taraması için gerekli)
        """
        norm_chars = []
        norm2orig = []
        for i, ch in enumerate(src):
            ch2 = ch.translate(TR_MAP)
            ch2 = unicodedata.normalize("NFC", ch2)
            if not ch2.strip():
                continue
            norm_chars.append(ch2.lower())
            norm2orig.append(i)
        return "".join(norm_chars), norm2orig

    # -------------------------------
    # 2) Çok sayfalı mı tek sayfa mı
    # -------------------------------
    is_multi = (
        isinstance(paddle_ocr_regions, list)
        and len(paddle_ocr_regions) > 0
        and isinstance(paddle_ocr_regions[0], list)
    )
    pages = paddle_ocr_regions if is_multi else [paddle_ocr_regions]
    page_texts = paddle_ocr_texts if isinstance(paddle_ocr_texts, list) else [paddle_ocr_texts]

    out_pages = []

    # -------------------------------
    # 3) Her sayfayı işleme
    # -------------------------------
    for p_i, regs in enumerate(pages):

        page_text_raw = _get_text(page_texts[p_i]) if p_i < len(page_texts) else ""
        norm_stream, norm2orig = _build_norm_stream_with_map(page_text_raw)

        page_out = []

        # -------------------------------
        # 4) Her region için eşleşme
        # -------------------------------
        for r in regs:

            r_txt_raw = _get_text(r)
            r_norm = _norm(r_txt_raw)

            if not r_norm:
                page_out.append(r)
                continue

            L = len(r_norm)

            # -------------------------------
            # 4A) Kısa metinlerde doğrudan eşleşme (T.C., NO, %5, "IV", "01" vb.)
            # -------------------------------
            if L <= 6:
                idx = norm_stream.find(r_norm)
                if idx != -1:
                    s_o = norm2orig[idx]
                    e_o = norm2orig[idx + L - 1]
                    r["text"] = page_text_raw[s_o: e_o + 1]
                    page_out.append(r)
                    continue

            # -------------------------------
            # 4B) Sayı içeriyorsa daha esnek threshold
            # -------------------------------
            if _has_number(r_norm):
                local_threshold = min(fuzzy_threshold, 80)
                local_len_tol = max(length_tolerance, 4)
            else:
                local_threshold = fuzzy_threshold
                local_len_tol = length_tolerance

            # -------------------------------
            # 5) Direkt substring
            # -------------------------------
            direct_idx = norm_stream.find(r_norm)
            if direct_idx != -1:
                s_o = norm2orig[direct_idx]
                e_o = norm2orig[direct_idx + L - 1]
                r["text"] = page_text_raw[s_o: e_o + 1]
                page_out.append(r)
                continue

            # -------------------------------
            # 6) Fuzzy pencere taraması
            # -------------------------------
            best_score = -1
            best_s, best_len = None, None

            min_len = max(1, L - local_len_tol)
            max_len = min(len(norm_stream), L + local_len_tol)

            for win_len in range(min_len, max_len + 1):
                if win_len > len(norm_stream):
                    continue

                for start in range(0, len(norm_stream) - win_len + 1):
                    cand = norm_stream[start:start + win_len]
                    score = fuzz.ratio(cand, r_norm)

                    if score > best_score:
                        best_score = score
                        best_s = start
                        best_len = win_len

            if best_score is not None and best_score >= local_threshold:
                s_o = norm2orig[best_s]
                e_o = norm2orig[best_s + best_len - 1]
                r["text"] = page_text_raw[s_o: e_o + 1]

            page_out.append(r)

        out_pages.append(page_out)

    return out_pages if is_multi else out_pages[0]