import re
import unicodedata
from typing import List, Dict, Tuple
import pandas as pd
from rapidfuzz import fuzz

def standardize_table_columns_v2(table_dfs_cleaned: List[pd.DataFrame],
                                 match_threshold: float = 65.0
                                 ) -> List[pd.DataFrame]:
    """
    table_dfs_cleaned içindeki df'lerin kolon adlarını tek şemaya çevirir.

    Hedef kolonlar:
        page_index
        pay_sahibinin_adi_soyadi_unvani
        pay_sahibi_tckn
        pay_sahibi_uyrugu
        pay_sahibi_adresi
        paylarin_toplam_itibari_degeri
        paylarin_edinin_sekli_tarihi
        katilim_sekli
        temsilci_adi_soyadi_unvani
        temsilci_tckn
        tablo_imza_var_mi
    """

    # --- 1) Normalizasyon yardımcıları ---
    TR_MAP = str.maketrans({
        "İ": "I", "I": "I", "ı": "i", "i": "i",
        "Ş": "S", "ş": "s",
        "Ğ": "G", "ğ": "g",
        "Ü": "U", "ü": "u",
        "Ö": "O", "ö": "o",
        "Ç": "C", "ç": "c",
    })

    def norm_col(s: str) -> str:
        if not isinstance(s, str):
            return ""
        s = s.translate(TR_MAP)
        s = unicodedata.normalize("NFKD", s)
        s = "".join(ch for ch in s if not unicodedata.combining(ch))
        s = s.lower()
        s = s.replace("t.c.", "tc").replace("t.c", "tc")
        s = re.sub(r"[^a-z0-9\s]+", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    def token_set(s: str) -> set:
        return set(norm_col(s).split())

    def jaccard(a: str, b: str) -> float:
        ta, tb = token_set(a), token_set(b)
        if not ta or not tb:
            return 0.0
        return len(ta & tb) / len(ta | tb)

    # --- 2) Hedef şema tanımı ---
    canonical_schema: List[Tuple[str, str]] = [
        ("page_index", "page index sayfa no sira"),
        ("pay_sahibinin_adi_soyadi_unvani",
         "pay sahibinin adi soyadi unvani isim pay sahibi ad soyad"),
        ("pay_sahibi_tckn",
         "pay sahibi tc kimlik tckn vergi kimlik vkn no pay sahibi"),
        ("pay_sahibi_uyrugu",
         "pay sahibi uyrugu uyruk nationality"),
        ("pay_sahibi_adresi",
         "pay sahibi adresi adres"),
        ("paylarin_toplam_itibari_degeri",
         "paylarin toplam itibari degeri nominal tutar pay toplam nominal"),
        ("paylarin_edinin_sekli_tarihi",
         "paylarin edinim sekli tarihi edinim sekli edinim tarihi"),
        ("katilim_sekli",
         "katilim sekli katilma sekli"),
        ("temsilci_adi_soyadi_unvani",
         "temsilci temsilcinin adi soyadi unvani vekil ad soyad"),
        ("temsilci_tckn",
         "temsilci temsilcinin tc kimlik tckn vergi kimlik vkn no vekil"),
        ("tablo_imza_var_mi",
         "imza tablo imza var mi signature"),
    ]
    canonical_names = [c[0] for c in canonical_schema]

    # --- 3) Tek df için kolon eşleme ---
    def map_columns(df: pd.DataFrame) -> pd.DataFrame:
        src_cols = list(df.columns)
        norm_map = {c: norm_col(c) for c in src_cols}

        # canonical -> (best_src_col, best_score)
        best_for_canon: Dict[str, Tuple[str, float]] = {}

        # 3.1 KURAL TABANLI EŞLEŞME (kritik kolonlar)
        for c in src_cols:
            n = norm_map[c]

            # İMZA
            if "imza" in n:
                _update_best(best_for_canon, "tablo_imza_var_mi", c, 100.0)

            # TEMSİLCİ TCKN
            if "temsilci" in n and any(t in n for t in ["tc", "tck", "vkn", "vergi", "kimlik"]):
                _update_best(best_for_canon, "temsilci_tckn", c, 100.0)

            # TEMSİLCİ AD SOYAD
            if "temsilci" in n and any(t in n for t in ["adi", "ad", "soyadi", "soyad", "unvani", "unvan"]):
                _update_best(best_for_canon, "temsilci_adi_soyadi_unvani", c, 100.0)

            # PAY SAHİBİ TCKN (temsilci geçmiyorsa)
            if "temsilci" not in n and any(t in n for t in ["tc", "tck", "vkn", "vergi", "kimlik"]):
                _update_best(best_for_canon, "pay_sahibi_tckn", c, 100.0)

            # PAY SAHİBİ UYRUGU
            if any(t in n for t in ["uyruk", "uyrugu"]):
                _update_best(best_for_canon, "pay_sahibi_uyrugu", c, 100.0)

        # 3.2 Fuzzy + Jaccard (kalan canonicallar için)
        for c in src_cols:
            n_col = norm_map[c]
            if not n_col:
                continue

            for canon_name, canon_desc in canonical_schema:
                # eğer bu canonical zaten kural tabanlı 100 puanla doldurulduysa,
                # skor çok düşükse zorlamaya gerek yok
                prev = best_for_canon.get(canon_name)
                if prev is not None and prev[1] >= 100.0:
                    continue

                n_canon = norm_col(canon_desc)
                fuzzy_score = fuzz.token_set_ratio(n_col, n_canon)  # 0–100
                j_score = jaccard(n_col, n_canon) * 100.0
                score = 0.6 * fuzzy_score + 0.4 * j_score

                if score >= match_threshold:
                    _update_best(best_for_canon, canon_name, c, score)

        # 3.3 Yeni df'yi kur
        new_df = pd.DataFrame()
        for canon_name in canonical_names:
            src, _ = best_for_canon.get(canon_name, (None, None))
            if src is not None and src in df.columns:
                new_df[canon_name] = df[src]
            else:
                new_df[canon_name] = pd.NA

        return new_df

    # küçük yardımcı: her canonical için en yüksek skoru sakla
    def _update_best(best_dict: Dict[str, Tuple[str, float]],
                     canon_name: str,
                     src_col: str,
                     score: float):
        prev = best_dict.get(canon_name)
        if (prev is None) or (score > prev[1]):
            best_dict[canon_name] = (src_col, score)

    # fonksiyon içinden erişebilmesi için yeniden tanımlama
    def _wrap_update(*args, **kwargs):
        return _update_best(*args, **kwargs)

    # closure hilesi: map_columns içinde kullanacağız
    global _update_best
    _update_best = _wrap_update

    # --- 4) Tüm df listesine uygula ---
    standardized = [map_columns(df) for df in table_dfs_cleaned]
    return standardized