from typing import Any, Callable, Dict, List, Optional, Tuple, Union
import re

# --- opsiyonel: RapidFuzz varsa daha iyi fuzzy; yoksa difflib fallback ---
try:
    from rapidfuzz.fuzz import ratio as _fz_ratio
except Exception:
    from difflib import SequenceMatcher
    def _fz_ratio(a, b):
        return int(100 * SequenceMatcher(None, a, b).ratio())

def extract_name_boxes_ner_only(
    pages_scaled: Any,
    # NER iki biçimde gelebilir:
    # 1) spaCy nlp objesi (doc.ents => .start_char/.end_char/.label_)
    spacy_nlp: Optional[Any] = None,
    # 2) Harici öngörü: ner_predict(text) -> List[Dict|Tuple]
    #    Kabul edilen örnekler:
    #      [{"start":s,"end":e,"label":"PERSON","score":0.97}, ...]
    #      [(s,e,"PERSON"), ...]
    ner_predict: Optional[Callable[[str], List[Union[Dict, Tuple]]]] = None,
    ocr_conf_min: float = 0.90,          # OCR kutusu eşiği
    fuzzy_blacklist: Optional[List[str]] = None,
    fuzzy_cutoff: int = 88,              # 0-100; 88 genelde “imza/ımza” gibi varyantları yakalar
    min_tokens: Tuple[int, int] = (2, 3) # (min, max) token sayısı
) -> List[Dict[str, Any]]:
    """
    Yalnızca NER ile ad-soyad (PERSON) çıkarır.
    Dönüş: [{page_index, role='ad_soyad', name, matched_text, name_span, bbox, confidence, source}]
    """

    # --- varsayılan kara liste ---
    if fuzzy_blacklist is None:
        fuzzy_blacklist = ["imza", "mühür", "muhur", "kaşe", "kase", "stamp",
                           "seal", "signature", "tasdik", "tescil", "onay", "noter"]

    def _ensure_pages(pages_obj: Any) -> List[List[Dict[str, Any]]]:
        if not pages_obj:
            return []
        if isinstance(pages_obj, list) and pages_obj and isinstance(pages_obj[0], dict):
            return [pages_obj]
        return pages_obj

    def _norm(s: str) -> str:
        s = s.replace("|", "l").replace("’","'").replace("“",'"').replace("”",'"')
        return re.sub(r"\s+", " ", s).strip()

    def _fuzzy_clean(text: str) -> str:
        # kelime kelime dolaş, blacklist ile fuzzy >= cutoff ise kelimeyi sil
        toks = re.findall(r"\w+|\W+", text)  # kelime + ayrac
        out = []
        for t in toks:
            if t.strip() and t.strip().isalnum():
                t_low = t.lower()
                if any(_fz_ratio(t_low, b) >= fuzzy_cutoff for b in fuzzy_blacklist):
                    continue
            out.append(t)
        return "".join(out)

    def _iter_person_spans(text: str) -> List[Tuple[int,int,str]]:
        spans: List[Tuple[int,int,str]] = []
        if spacy_nlp is not None:
            doc = spacy_nlp(text)
            for ent in getattr(doc, "ents", []):
                if str(ent.label_).upper() == "PERSON":
                    spans.append((int(ent.start_char), int(ent.end_char), "PERSON"))
        if ner_predict is not None:
            for item in ner_predict(text) or []:
                if isinstance(item, (list, tuple)) and len(item) >= 3:
                    s, e, lab = int(item[0]), int(item[1]), str(item[2])
                    if lab.upper() == "PERSON":
                        spans.append((s, e, "PERSON"))
                elif isinstance(item, dict):
                    if str(item.get("label","")).upper() == "PERSON":
                        spans.append((int(item["start"]), int(item["end"]), "PERSON"))
        return spans

    def _looks_like_name(fragment: str) -> bool:
        # 2-3 kelime, rakam yok, tamamen alfabetik (noktaya izin)
        if any(ch.isdigit() for ch in fragment):
            return False
        parts = fragment.split()
        if not (min_tokens[0] <= len(parts) <= min_tokens[1]):
            return False
        return all(re.fullmatch(r"[A-Za-zÇĞİÖŞÜçğıöşü.]+", p) for p in parts)

    def _casefix(s: str) -> str:
        parts, out = s.split(), []
        for p in parts:
            if len(p) == 2 and p.endswith(".") and p[0].isalpha():
                out.append(p.upper())
            elif p.isupper():
                out.append(p.title())
            else:
                out.append(p)
        return " ".join(out)

    pages = _ensure_pages(pages_scaled)
    out: List[Dict[str, Any]] = []

    for pi, items in enumerate(pages):
        for it in items:
            conf = it.get("confidence")
            if isinstance(conf, (int, float)) and conf < ocr_conf_min:
                continue  # düşük OCR güveni

            raw = it.get("text") or it.get("txt") or ""
            if not raw:
                continue

            text = _norm(raw)
            text = _fuzzy_clean(text)  # kara liste temizliği (yakın eşleşmeleri de siler)

            spans = _iter_person_spans(text)
            if not spans:
                continue

            # span bazında doğrulama ve çıktı
            bbox = it.get("bbox") or {}
            for s, e, _ in spans:
                frag = text[s:e].strip()
                if not _looks_like_name(frag):
                    continue
                out.append({
                    "page_index": pi,
                    "role": "ad_soyad",
                    "name": _casefix(frag),
                    "matched_text": frag,
                    "name_span": (s, e),
                    "bbox": {
                        "x_min": bbox.get("x_min"),
                        "y_min": bbox.get("y_min"),
                        "width": bbox.get("width"),
                        "height": bbox.get("height"),
                    },
                    "confidence": float(conf) if isinstance(conf, (int, float)) else None,
                    "source": "ner"
                })

    # tekilleştir (aynı sayfa + bbox + span)
    def _k(r):
        b = r["bbox"]; s = r["name_span"]
        return (r["page_index"], r["name"], b.get("x_min"), b.get("y_min"), b.get("width"), b.get("height"), s)
    uniq, seen = [], set()
    for r in out:
        k = _k(r)
        if k not in seen:
            seen.add(k); uniq.append(r)
    return uniq

# 1) Sadece spaCy ile
# import spacy; nlp = spacy.load("tr_core_news_trf")
names = extract_name_boxes_ner_only(pages_scaled, spacy_nlp=nlp, ocr_conf_min=0.90)

# 2) Kendi NER çıktılarınla (start,end,label[,score])
# def my_ner(text): return [{"start":s,"end":e,"label":"PERSON","score":0.98}, ...]
# names = extract_name_boxes_ner_only(pages_scaled, ner_predict=my_ner, ocr_conf_min=0.90)

# 3) Kara liste eşiğini değiştir
# names = extract_name_boxes_ner_only(pages_scaled, spacy_nlp=nlp, fuzzy_cutoff=92)