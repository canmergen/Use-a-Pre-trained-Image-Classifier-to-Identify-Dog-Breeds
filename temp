# -*- coding: utf-8 -*-
import re, json, base64, requests, numpy as np, pandas as pd
import unicodedata
from typing import List, Tuple, Dict, Optional

# ============ Metin normalizasyonu & benzerlik ============

def _strip_diacritics(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFKD', s or "") if not unicodedata.combining(c))

def _norm_text(s: str) -> str:
    s = _strip_diacritics((s or "").upper())
    s = re.sub(r"[^A-Z0-9ÇĞİÖŞÜ\s]", " ", s)
    return re.sub(r"\s+", " ", s).strip()

def _bigrams(s: str) -> set:
    s = _norm_text(s).replace(" ", "")
    return {s[i:i+2] for i in range(max(0, len(s)-1))} if s else set()

def _levenshtein(a: str, b: str) -> int:
    a, b = _norm_text(a), _norm_text(b)
    if not a: return len(b)
    if not b: return len(a)
    dp = list(range(len(b)+1))
    for i, ca in enumerate(a, 1):
        prev, dp[0] = dp[0], i
        for j, cb in enumerate(b, 1):
            ins = dp[j-1] + 1
            dele = dp[j] + 1
            sub = prev + (ca != cb)
            prev, dp[j] = dp[j], min(ins, dele, sub)
    return dp[-1]

def _sim(a: str, b: str) -> float:
    """Jaccard(bigram) ile Levenshtein oranını harmanlar."""
    A, B = _bigrams(a), _bigrams(b)
    j = (len(A & B) / len(A | B)) if (A or B) else 0.0
    lev = 1.0 - (_levenshtein(a, b) / max(1, len(_norm_text(a)), len(_norm_text(b))))
    return 0.6*j + 0.4*lev

def match_known_names_in_text(text: str, known_names: List[str], threshold: float=0.75) -> List[str]:
    """
    OCR metni içinde, verilen known_names listesine fuzzy bakar.
    Eşik üzerindeki tüm kanonik isimleri (listede yazdığı gibi) döner.
    Birden fazla isim bulunabilir; tekrarı kaldırır, orijinal sıra korunur.
    """
    t = _norm_text(text)
    hits = []
    seen = set()
    for name in known_names:
        if not name: 
            continue
        score = _sim(t, name)
        # çok uzun listelerde hız için kısa bir hızlı yol: ad soyadın her iki parçası da metinde kısmen geçiyorsa puanı artırır
        parts = [p for p in _norm_text(name).split() if p]
        if len(parts) >= 2 and all(p[:3] in t for p in parts):  # üç harflik tohumlar
            score = max(score, 0.85)
        if score >= threshold and name not in seen:
            hits.append(name)
            seen.add(name)
    return hits

# ============ TL sayısı yakalama ============

_TL_NUM = re.compile(r"(?<!\d)(\d{1,3}(?:\.\d{3})+|\d+)(?:,\d{1,2})?\s*(?:TL|₺)?", re.IGNORECASE)

def _parse_tl_int(text: str) -> Optional[int]:
    """
    Metinden TL sayısı yakalar: 1.000.000,00 -> 1000000 (int)
    Birden fazla varsa en büyüğünü döner.
    """
    best = None
    for m in _TL_NUM.finditer(text or ""):
        raw = m.group(1)
        v = raw.replace(".", "").replace(" ", "")
        try:
            val = int(v)
            best = val if (best is None or val > best) else best
        except:
            pass
    return best

# ============ Rapor: sadece kutu içi imza, isimler fuzzy-known, sermaye komşuya bakabilir ============

ROLE_KEYS = ["toplanti_baskani", "tutanak_yazmani", "bakanlik_temsilcisi",
             "yk_uyesi", "yk_baskani", "katip", "divan_baskani"]

CAP_HINTS = ["ŞİRKETİN SERMAYESİ", "SERMAYESİ VE PAYLARIN",
             "TOPLAMI İTİBARİ DEĞERİ", "SERMAYE"]

def build_bottom_df_from_report(lower_img: np.ndarray,
                                boxes: List[Tuple[int,int,int,int]],
                                per_box_df: pd.DataFrame,
                                known_names: List[str],
                                name_sim_threshold: float = 0.75) -> pd.DataFrame:
    """
    - İsim: sadece o kutunun OCR metninden, fuzzy known_names ile
    - İmza: sadece o kutunun 'sig' değeri
    - Sermaye: başlık kutusu ve komşuları (i-1, i, i+1) içinden en büyük sayı
    """
    n = len(per_box_df)
    texts = [str(per_box_df.loc[i, "text_preview"] or "") for i in range(n)]
    roles  = [per_box_df.loc[i, "role_best"] if "role_best" in per_box_df.columns else None for i in range(n)]
    sigs   = [bool(per_box_df.loc[i, "sig"]) for i in range(n)]

    # --- Sermaye ---
    sermaye = None
    # önce başlık ipuçlarını içeren kutulara yakın bak
    scored = []
    for i, t in enumerate(texts):
        score = sum(hint in _norm_text(t) for hint in CAP_HINTS)
        if score:
            scored.append((score, i))
    for _, i in sorted(scored, reverse=True):
        for j in [i-1, i, i+1]:
            if 0 <= j < n:
                val = _parse_tl_int(texts[j])
                if val is not None:
                    sermaye = val if sermaye is None else max(sermaye, val)
        if sermaye is not None:
            break
    # hala yoksa: tüm kutuların en büyüğü
    if sermaye is None:
        vals = [_parse_tl_int(t) for t in texts]
        sermaye = max([v for v in vals if v is not None], default=None)

    out = {
        "sermaye_toplam_tl": sermaye,
        "toplanti_baskani_ad_soyad": None, "toplanti_baskani_imza_var_mi": None,
        "tutanak_yazmani_ad_soyad": None,  "tutanak_yazmani_imza_var_mi": None,
        "bakanlik_temsilcisi_ad_soyad": None, "bakanlik_temsilcisi_imza_var_mi": None,
        "yk_uyesi_ad_soyad": None, "yk_uyesi_imza_var_mi": None,
        "yk_baskani_ad_soyad": None, "yk_baskani_imza_var_mi": None,
        "katip_ad_soyad": None, "katip_imza_var_mi": None,
        "divan_baskani_ad_soyad": None, "divan_baskani_imza_var_mi": None,
    }

    key_map = {
        "toplanti_baskani": ("toplanti_baskani_ad_soyad", "toplanti_baskani_imza_var_mi"),
        "tutanak_yazmani":  ("tutanak_yazmani_ad_soyad",  "tutanak_yazmani_imza_var_mi"),
        "bakanlik_temsilcisi": ("bakanlik_temsilcisi_ad_soyad","bakanlik_temsilcisi_imza_var_mi"),
        "yk_uyesi": ("yk_uyesi_ad_soyad", "yk_uyesi_imza_var_mi"),
        "yk_baskani": ("yk_baskani_ad_soyad", "yk_baskani_imza_var_mi"),
        "katip": ("katip_ad_soyad", "katip_imza_var_mi"),
        "divan_baskani": ("divan_baskani_ad_soyad", "divan_baskani_imza_var_mi"),
    }

    def _set(role_key: str, i: int):
        """Sadece kendi kutusunun isim/imza bilgisi."""
        if role_key not in key_map: 
            return
        k_name, k_sig = key_map[role_key]
        text_here = texts[i]
        sig_here  = sigs[i]

        # isimler: fuzzy-known (çoklu olabilir)
        names = match_known_names_in_text(text_here, known_names, threshold=name_sim_threshold)
        name_val = "; ".join(names) if names else None

        if name_val is not None:
            out[k_name] = name_val
        if sig_here is not None:
            out[k_sig] = bool(sig_here)

    # kutu bazında rolleri işle
    for i, rk in enumerate(roles):
        if rk in ROLE_KEYS:
            _set(rk, i)

    return pd.DataFrame([out])