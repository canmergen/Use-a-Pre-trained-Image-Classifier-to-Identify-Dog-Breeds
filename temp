# -*- coding: utf-8 -*-
from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
import re, difflib, time, json
import numpy as np

def classify_hazirun_single(
    doc_res: Dict[str, Any],
    *,
    # OCR kaynakları (en az biri)
    tc_new: Optional[Any] = None,                  # callable client: ocr/run_ocr/predict/infer/get_text/__call__
    NEW_URL: Optional[str] = None,                 # REST endpoint (image base64 JSON)

    # OCR ayarları
    ocr_lang: str = "tur+eng+lat",
    ocr_psm: int = 6,
    ocr_oem: int = 1,
    ocr_extra_config: Optional[str] = None,
    http_timeout_s: float = 12.0,
    http_retries: int = 3,
    http_backoff_s: float = 0.9,

    # Performans: başlık bandı + downscale ile OCR
    ocr_on_top_ratio: float = 0.33,               # [0.2, 0.5] önerilir
    ocr_downscale_max_w: int = 2200,              # OCR için yeterli genişlik
    ocr_use_jpeg: bool = True,                    # PNG büyükse JPEG(92) tercih et

    # Tek liste anahtar ifadeler (fuzzy + coverage)
    keywords: Optional[List[str]] = None,
    fuzzy_min_ratio: float = 0.86,                # 0..1
    phrase_window: int = 12,                      # kelime penceresi

    # Güçlü başlıklar (yakalanırsa tablo şartını baypas edebilir)
    strong_phrases: Optional[List[str]] = None,
    strong_phrase_ratio: float = 0.90,            # ≥ bu oranda yakalanırsa "hemen hazirun"

    # Karar eşikleri
    min_hit_phrases: int = 3,                     # ≥ bu kadar ifade yakalanırsa kabul
    min_total_score: float = 4.5,                 # veya toplam skor ≥ eşik

    # OCR hatasını negatif sayma kontrolü
    assume_nonhazirun_on_ocr_fail: bool = False,  # False: unknown_pages'a at

    # TABLO zorunluluğu
    require_table: bool = True,
    table_require_mode: str = "soft",             # "soft" | "hard"
    table_min_intersections: int = 10,            # min. çizgi kesişimi (biraz gevşek)
    table_min_cells: int = 4,                     # min. hücre tahmini
    table_min_area_ratio: float = 0.06,           # tablo alanı / sayfa alanı min oranı

    # Çıktı
    debug: bool = False
) -> Dict[str, Any]:
    """
    - 'soft' modda: güçlü başlık varsa tablo şartını baypas eder, yoksa tablo aranır.
    - 'hard' modda: tablo yoksa sayfa direkt 'non_hazirun'.
    - OCR boş/timeout negatif sayılmaz (unknown_pages); istersen assume_nonhazirun_on_ocr_fail=True yap.
    - En az 1 sayfa kabul edilirse belge 'HAZIRUNDUR'; sadece o sayfalar image+meta ile döner.
    """

    # ---------------- local helpers ----------------
    def _ratio_init():
        try:
            from rapidfuzz import fuzz
            return lambda a,b: float(fuzz.partial_ratio(a, b)) / 100.0
        except Exception:
            return lambda a,b: difflib.SequenceMatcher(None, a, b).ratio()
    _ratio = _ratio_init()

    def _tr_lower(s: str) -> str:
        return (s or "").replace("I","ı").replace("İ","i").lower()

    def _normalize_text(s: str) -> str:
        t = _tr_lower(s)
        t = re.sub(r"[_–—\-•・·]+", " ", t)
        t = re.sub(r"[^\w\s%./]", " ", t, flags=re.UNICODE)
        t = re.sub(r"\s+", " ", t).strip()
        return t

    WORD_RE = re.compile(r"\w+", flags=re.UNICODE)
    def _tokens(s: str) -> List[str]:
        return WORD_RE.findall(s)

    def _img_top_band_and_downscale(bgr: np.ndarray) -> np.ndarray:
        import cv2
        h, w = bgr.shape[:2]
        top_h = max(1, int(h * max(0.18, min(0.6, ocr_on_top_ratio))))
        roi = bgr[:top_h, :]
        if w > ocr_downscale_max_w:
            scale = ocr_downscale_max_w / float(w)
            nh = max(1, int(round(roi.shape[0] * scale)))
            roi = cv2.resize(roi, (ocr_downscale_max_w, nh), interpolation=cv2.INTER_AREA)
        return roi

    def _img_to_b64(img: np.ndarray) -> str:
        import cv2, base64
        if ocr_use_jpeg:
            ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 92])
        else:
            ok, buf = cv2.imencode(".png", img)
        if not ok:
            return ""
        return base64.b64encode(buf).decode("utf-8")

    # ---- tablo tespiti (morfolojik) ----
    def _has_table(bgr: np.ndarray) -> Tuple[bool, Dict[str, Any]]:
        import cv2
        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
        g = cv2.GaussianBlur(gray, (3,3), 0)
        bw = cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                   cv2.THRESH_BINARY_INV, 35, 10)
        h, w = bw.shape
        horiz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (max(18, w//90), 1))
        vert_kernel  = cv2.getStructuringElement(cv2.MORPH_RECT, (1, max(18, h//60)))
        horiz = cv2.morphologyEx(bw, cv2.MORPH_OPEN, horiz_kernel, iterations=1)
        vert  = cv2.morphologyEx(bw, cv2.MORPH_OPEN, vert_kernel,  iterations=1)
        horiz = cv2.dilate(horiz, np.ones((1,3), np.uint8), iterations=1)
        vert  = cv2.dilate(vert,  np.ones((3,1), np.uint8), iterations=1)
        inter = cv2.bitwise_and(horiz, vert)
        intersections = int(np.count_nonzero(inter > 0))
        lines = cv2.bitwise_or(horiz, vert)
        num, labels, stats, _ = cv2.connectedComponentsWithStats(lines, connectivity=8)
        areas = stats[1:, cv2.CC_STAT_AREA] if num > 1 else np.array([])
        max_area = int(areas.max()) if areas.size else 0
        area_ratio = max_area / float(h*w) if (h*w) else 0.0
        approx_cells = int(max(intersections // 8, (areas.size > 0) * (max_area // max(1,(w//40)*(h//60)))))
        ok = (
            intersections >= table_min_intersections and
            approx_cells   >= table_min_cells and
            area_ratio     >= table_min_area_ratio
        )
        dbg = {
            "intersections": intersections,
            "approx_cells": approx_cells,
            "max_table_area_ratio": round(area_ratio, 4)
        }
        return bool(ok), dbg

    def _ocr_via_tc_new(img: np.ndarray) -> str:
        if tc_new is None: return ""
        from PIL import Image
        import cv2
        pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        cfg = [f"--psm {int(ocr_psm)}", f"--oem {int(ocr_oem)}"]
        if ocr_extra_config: cfg.append(ocr_extra_config)
        kwargs: Dict[str, Any] = {"lang": ocr_lang, "config": " ".join(cfg)}
        for name in ("ocr","run_ocr","predict","infer","get_text","__call__"):
            fn = getattr(tc_new, name, None)
            if callable(fn):
                try:
                    txt = fn(pil, **kwargs)
                    if isinstance(txt, dict): txt = txt.get("text","")
                    return txt if isinstance(txt, str) else str(txt)
                except TypeError:
                    try:
                        txt = fn(pil, output_type="text", **kwargs)
                        if isinstance(txt, dict): txt = txt.get("text","")
                        return txt if isinstance(txt, str) else str(txt)
                    except Exception:
                        pass
                except Exception:
                    pass
        return ""

    def _ocr_via_http(img: np.ndarray) -> str:
        if not NEW_URL: return ""
        import requests
        payload = {
            "image": _img_to_b64(img),
            "lang": ocr_lang or "tur",
            "config": " ".join(filter(None, [f"--psm {int(ocr_psm)}", f"--oem {int(ocr_oem)}", ocr_extra_config]))
        }
        last_err = None
        for k in range(http_retries + 1):
            try:
                r = requests.post(NEW_URL, json=payload, timeout=http_timeout_s)
                r.raise_for_status()
                try:
                    j = r.json()
                except Exception:
                    j = json.loads(r.text)
                return j.get("text","") or ""
            except Exception as e:
                last_err = e
                if k < http_retries:
                    time.sleep(http_backoff_s * (1.5**k))
                else:
                    if debug: print(f"[OCR HTTP] hata: {last_err}")
        return ""

    def _ocr_text(img_full: np.ndarray) -> Tuple[str, Dict[str, Any]]:
        roi = _img_top_band_and_downscale(img_full)
        txt = ""; err = None
        if NEW_URL:
            try:
                txt = _ocr_via_http(roi)
            except Exception as e:
                err = e
        if not txt and tc_new is not None:
            try:
                txt = _ocr_via_tc_new(roi)
            except Exception as e:
                err = e
        return txt, ({} if err is None else {"error": str(err)})

    def _phrase_best_score(phrase: str, text: str, toks: List[str]) -> Tuple[float, Dict[str, Any]]:
        ph = _tr_lower((phrase or "").strip())
        if not ph: return 0.0, {"why":"empty"}
        s_fz = _ratio(ph, text)
        ph_toks = [t for t in WORD_RE.findall(ph) if t]
        cover_best = 0.0
        if ph_toks and toks:
            need = set(ph_toks)
            for s in range(0, max(1, len(toks)-phrase_window+1), max(1, phrase_window//2)):
                e = min(len(toks), s + phrase_window)
                window = toks[s:e]
                cov = sum(1 for t in need if t in window) / max(1, len(need))
                cover_best = max(cover_best, cov)
        prefix_hits = 0.0
        if ph_toks and toks:
            pref = sum(1 for t in ph_toks if any(tt.startswith(t) for tt in toks))
            prefix_hits = pref / max(1, len(ph_toks))
        best = max(s_fz, cover_best, prefix_hits)
        return best, {"fuzzy": round(s_fz,3), "coverage": round(cover_best,3), "prefix": round(prefix_hits,3), "best": round(best,3)}

    # ---------------- defaults ----------------
    if keywords is None:
        keywords = [
            "hazır bulunanlar listesi","hazir bulunanlar listesi","hazirun cetveli",
            "genel kurul","olağan genel kurul","liste örneği",
            "pay sahibinin ad soyad unvanı","ad soyad","ad/soyad/unvanı","kimlik numarası",
            "vergi kimlik","mersis numarası","uyruğu","adresi",
            "payların itibari değeri","ediniliş şekli","ediniliş tarihi",
            "katılım şekli","temsilci türü","temsilcinin ad soyad unvanı",
            "temsilcinin kimlik numarası","imza",
            "şirketin sermayesi","payların toplam itibari değeri",
            "asgari toplantı nisabı","mevcut toplantı nisabı",
            "divan başkanı","oy toplama memuru","yönetim kurulu üyeleri",
            "anonim şirketi","a.ş","aş","limited şirketi","ltd şti","ltd. şti."
        ]
    if strong_phrases is None:
        strong_phrases = [
            "hazır bulunanlar listesi","hazir bulunanlar listesi","hazirun cetveli",
            "genel kurulda hazır bulunanlar listesi"
        ]

    images: List[np.ndarray] = list(doc_res.get("images", []))
    metas:  List[Dict[str, Any]] = list(doc_res.get("metas", []))
    n = len(images)

    hazirun_pages: List[Dict[str, Any]] = []
    non_hazirun_pages: List[Dict[str, Any]] = []
    unknown_pages: List[Dict[str, Any]] = []
    first_match_index: Optional[int] = None

    for i in range(n):
        img = images[i]

        # 1) OCR (üst band + downscale, HTTP->fallback)
        text_raw, err_info = _ocr_text(img)
        if not text_raw:
            if assume_nonhazirun_on_ocr_fail:
                non_hazirun_pages.append({"index": i, "reason": "OCR boş/hata", "hits": 0, "total_score": 0.0, **err_info})
            else:
                unknown_pages.append({"index": i, "reason": "OCR boş/hata", **err_info})
            continue

        text = _normalize_text(text_raw)
        toks = _tokens(text)

        # 2) Güçlü başlık kontrolü
        strong_hit = False
        strong_best = 0.0
        for ph in strong_phrases:
            sc, _ = _phrase_best_score(ph, text, toks)
            strong_best = max(strong_best, sc)
            if sc >= strong_phrase_ratio:
                strong_hit = True
                break

        # 3) TABLO zorunluluğu (moda göre)
        skip_table_check = (require_table is False) or (table_require_mode == "soft" and strong_hit)
        if require_table and not skip_table_check:
            has_tbl, tbl_dbg = _has_table(img)
            if not has_tbl:
                non_hazirun_pages.append({
                    "index": i,
                    "reason": "no_table",
                    **({"table_debug": tbl_dbg, "strong_best": round(strong_best,3)} if debug else {})
                })
                continue

        # 4) Tek-liste fuzzy/coverage skoru
        hit_cnt, score_sum = 0, 0.0
        ev: List[Dict[str, Any]] = []
        for ph in keywords:
            sc, det = _phrase_best_score(ph, text, toks)
            if sc >= fuzzy_min_ratio:
                hit_cnt += 1
            score_sum += sc
            if debug and sc >= 0.5:
                ev.append({"phrase": ph, **det})

        total_score = hit_cnt + (score_sum / max(1, len(keywords))) * 2.0

        # 5) Karar: güçlü başlık veya skor eşikleri
        is_hazirun = strong_hit or (hit_cnt >= min_hit_phrases) or (total_score >= min_total_score)

        if is_hazirun:
            if first_match_index is None:
                first_match_index = i
            hazirun_pages.append({
                "index": i,
                "image": images[i],
                "meta": metas[i] if i < len(metas) else {},
                "hits": int(hit_cnt),
                "total_score": float(round(total_score,3)),
                "strong_best": float(round(strong_best,3)),
                **({"evidence": ev[:20]} if debug else {})
            })
        else:
            row = {
                "index": i,
                "reason": "Eşik altı",
                "hits": int(hit_cnt),
                "total_score": float(round(total_score,3)),
                "strong_best": float(round(strong_best,3))
            }
            if debug:
                row["ocr_preview"] = text[:300]
            non_hazirun_pages.append(row)

    flag = "HAZIRUNDUR" if len(hazirun_pages) > 0 else "HAZIRUN DEĞİLDİR"

    return {
        "flag": flag,
        "first_match_index": first_match_index,
        "hazirun_pages": hazirun_pages,           # sadece eşleşen (image+meta)
        "non_hazirun_pages": non_hazirun_pages,   # tablo yok / eşik altı vb. gerekçeler
        "unknown_pages": unknown_pages,           # OCR başarısız/boş sayfalar
        "page_count": n
    }