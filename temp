def _extract_company(text: str, lines: List[str]) -> Tuple[Optional[str], Optional[str], Dict]:
    dbg: Dict = {}
    T = unicodedata.normalize("NFKC", text or "")
    if not T.strip():
        return None, None, {"reason":"empty_text"}

    # --- tür demiri (konum) ---
    GEN = r"(?:\s*[’'`´\"“”]?\s*(?:NIN|NİN|NUN|NÜN|IN|İN|UN|ÜN))?"
    TYPE_CORE = (
        rf"(ANON[İI]M\s+{_spaced_token('ŞİRKET')}"
        rf"|A\.?\s*Ş|AŞ"
        rf"|LTD\s*\.?\s*ŞT[İI]|LTD\s*\.?\s*ST[İI]"
        rf"|L[İI]M[İI]TED\s+{_spaced_token('ŞİRKET')}){GEN}"
    )
    type_hits = list(re.finditer(TYPE_CORE, T, flags=re.IGNORECASE | re.DOTALL))
    if not type_hits:
        # tür yoksa hiç uğraşmayalım, yalnızca türü metinden tahmin et
        return None, _map_type_to_canonical(T), {"reason":"no_type_anchor"}

    m = type_hits[-1]                                 # en sondaki demir
    raw_type = m.group(1)
    ctype = _map_type_to_canonical(raw_type) or _map_type_to_canonical(m.group(0))

    # --- sol bağlamı satırlara böl ---
    LEFT_WIN = 900
    left = T[max(0, m.start()-LEFT_WIN):m.start()]
    left_lines = [ln.strip(" ,.-:;’'") for ln in left.splitlines() if ln.strip()]

    # Gürültü başlıkları / doldurucular
    NOISE = {
        "GENEL","KURUL","TOPLANTISI","TOPLANTISINDA","HAZIR","BULUNANLAR","LİSTESİ","ÖRNEĞİ",
        "TARİHLİ","OLAĞAN","OLAĞANÜSTÜ","GÜNDEM","TUTANAK","LİSTE","EK-","SAYILI",
        "KİMLİK","VERGİ","AD/SOYAD","NUMARASI","NUMARA","ADRESİ","MERKEZİ","ÜNVANI","ŞUBE"
    }
    STOPTAIL = {"AN","VE","TIC","TİC","SAN","VE.","TIC.","TİC.","SAN.","DE","DA","VEYA","İLE"}
    # içeriğe ağırlık veren alan anahtarları
    DOMAIN_HINTS = {"HİZMETLERİ","SANAYİ","TİCARET","LOJİSTİK","GIDA","İNŞAAT","TEKSTİL","YAZILIM","ENERJİ","OTOMOTİV","MOBİLYA","MADEN","EĞİTİM","SAĞLIK","SİSTEMLERİ"}

    def clean_tokens(s: str) -> List[str]:
        s = re.sub(r"\s+", " ", s)
        # tür varyantlarını sök
        s = re.sub(r"\b(ANONIM|ANONİM|LIMITED|LİMİTED|LTD\.?\s*ŞTİ|LTD\.?\s*STİ|A\.?\s*Ş|AŞ|Ş\s*İ\s*R\s*K\s*E\s*T[İI])\b",
                   "", s, flags=re.IGNORECASE)
        toks = [t for t in s.split() if t.upper() not in NOISE]
        while toks and (toks[-1].upper() in STOPTAIL or len(toks[-1]) < 2):
            toks.pop()
        while toks and len(toks[0]) < 2:
            toks.pop(0)
        return toks

    def score_name_from_tokens(toks: List[str]) -> float:
        if not toks: return 0.0
        name = " ".join(toks)
        base = _score_name(name)
        # alan ipuçları varsa bonus
        bonus = 0.12 if any(t.upper() in DOMAIN_HINTS for t in toks) else 0.0
        return base + bonus

    # --- 6 satıra kadar geri tarayıp aday üret ---
    candidates: List[Tuple[float, str]] = []
    n = len(left_lines)
    for i in range(n-1, max(-1, n-6)-1, -1):                 # son 6 satır
        toks_i = clean_tokens(left_lines[i]) if i >= 0 else []
        if toks_i:
            sc = score_name_from_tokens(toks_i)
            candidates.append((sc, " ".join(toks_i)))
        # bir üst satırla birleşim
        if i-1 >= 0:
            toks_combo = clean_tokens(left_lines[i-1] + " " + left_lines[i])
            if toks_combo:
                sc = score_name_from_tokens(toks_combo)
                candidates.append((sc, " ".join(toks_combo)))

    # ek: aynı satırda türün SOLU
    same_line_left = left_lines[-1].split(raw_type, 1)[0].strip(" ,.-:;’'") if left_lines else ""
    toks_same = clean_tokens(same_line_left)
    if toks_same:
        candidates.append((score_name_from_tokens(toks_same), " ".join(toks_same)))

    if candidates:
        best_sc, best_nm = max(candidates, key=lambda x: x[0])
        if best_sc > 0.35:                                   # düşük eşiği bilinçli tuttum
            return _upper_tr(best_nm), ctype, {"reason":"backscan_multi", "score":best_sc, "type":ctype}

    # --- satır bazlı en son yedek: tür geçen satırın bir üstü ---
    T_lines = [ln.strip() for ln in T.splitlines() if ln.strip()]
    for k in range(len(T_lines)-1, -1, -1):
        if re.search(TYPE_CORE, T_lines[k], flags=re.IGNORECASE):
            # aynı satır solu
            left_inline = T_lines[k].split(re.search(TYPE_CORE, T_lines[k], flags=re.IGNORECASE).group(0))[0]
            toks = clean_tokens(left_inline)
            if toks and _score_name(" ".join(toks)) > 0.3:
                return _upper_tr(" ".join(toks)), ctype, {"reason":"same_line_left_fallback", "type":ctype}
            # bir üst satır
            if k > 0:
                toks = clean_tokens(T_lines[k-1])
                if toks and _score_name(" ".join(toks)) > 0.3:
                    return _upper_tr(" ".join(toks)), ctype, {"reason":"prev_line_fallback", "type":ctype}

    return None, ctype, {"reason":"exhausted", "type":ctype}