# -*- coding: utf-8 -*-
import cv2, json, base64, requests, re, numpy as np, pandas as pd
import unicodedata
from typing import Any, List, Tuple, Dict, Optional

# =========================
# 0) Sabitler / Yardımcılar
# =========================
def _strip_diacritics(s: str) -> str:
    return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))

def _norm_text(s: str) -> str:
    s = (s or "").upper()
    s = _strip_diacritics(s)
    s = re.sub(r"\s+", " ", s).strip()
    return s

NAME_TOKEN = re.compile(r"[A-ZÇĞİÖŞÜ]{2,}(?:\s+[A-ZÇĞİÖŞÜ]{2,})+")
DROP_WORDS = [
    "TOPLANTI","TOPLANII","BAŞKANI","BASKANI","YÖNETİM","KURULU","ÜYESİ","UYESI","YK",
    "BAKANLIK","TEMSİLCİSİ","TEMSILCISI","KATİP","KÂTİP","YAZMANI",
    "DİVAN","DIVAN","İMZA","IMZA","KAŞE","MÜHÜR","STAMP",
    "ASALATEN","VEKALETEN","HAZIRUN","HAZİRUN","HAZIRIN"
]

ROLE_ALIASES: Dict[str, List[str]] = {
    "toplanti_baskani":    ["TOPLANTI BAŞKANI","TOPLANII BAŞKANI","DİVAN BAŞKANI","DIVAN BASKANI"],
    "tutanak_yazmani":     ["TUTANAK YAZMANI","YAZMAN"],
    "bakanlik_temsilcisi": ["BAKANLIK TEMSİLCİSİ","TİCARET BAKANLIĞI TEMSİLCİSİ","TICARET BAKANLIGI TEMSILCISI"],
    "yk_uyesi":            ["YÖNETİM KURULU ÜYESİ","YONETIM KURULU UYESI","YK ÜYESİ","YK UYESI"],
    "yk_baskani":          ["YÖNETİM KURULU BAŞKANI","YONETIM KURULU BASKANI","YK BAŞKANI","YK BASKANI"],
    "katip":               ["KÂTİP","KATİP","OY TOPLAYICI","OY TOPLAMA MEMURU","OY TOPLAYAN"],
    "divan_baskani":       ["DİVAN BAŞKANI","DIVAN BASKANI"],
}

# ------------- fuzzy eşleştirme -------------
def _lev(a: str, b: str) -> int:
    la, lb = len(a), len(b)
    if la == 0: return lb
    if lb == 0: return la
    dp = list(range(lb+1))
    for i, ca in enumerate(a, 1):
        prev = dp[0]
        dp[0] = i
        for j, cb in enumerate(b, 1):
            ins = dp[j-1] + 1
            dele = dp[j] + 1
            sub = prev + (ca != cb)
            prev = dp[j]
            dp[j] = min(ins, dele, sub)
    return dp[lb]

def _tokens(s: str) -> List[str]:
    t = _norm_text(s)
    return [tok for tok in re.split(r"[^A-ZÇĞİÖŞÜ]+", t) if tok]

def _alias_hits_fuzzy(text_u: str, alias: str,
                      per_token_max_dist: int = 2,
                      require_ratio: float = 0.8) -> bool:
    tt = _tokens(text_u)
    aa = _tokens(alias)
    if not tt or not aa:
        return False
    ok = 0
    for a in aa:
        if len(a) <= 3:
            if a in tt: ok += 1
            continue
        best = min((_lev(a, t) for t in tt), default=99)
        if best <= per_token_max_dist:
            ok += 1
    return ok >= max(1, int(round(len(aa) * require_ratio)))

def match_roles_fuzzy(text_u: str, ROLE_ALIASES: dict,
                      per_token_max_dist: int = 2,
                      require_ratio: float = 0.8) -> List[str]:
    hits = []
    for role_key, aliases in ROLE_ALIASES.items():
        if any(_alias_hits_fuzzy(text_u, al, per_token_max_dist, require_ratio) for al in aliases):
            hits.append(role_key)
    return hits

# ------------- isim temizleyici -------------
def cleanup_name(name: Optional[str]) -> Optional[str]:
    if not name:
        return None
    t = _norm_text(name)
    drop = set(_norm_text(w) for w in DROP_WORDS)
    toks = [tok for tok in re.split(r"\s+", t) if tok and tok not in drop and not tok.isdigit()]
    if not toks:
        return None
    # sondaki 2-3 token genel olarak isim-soyisim
    tail = toks[-3:]
    tail = [re.sub(r"[^A-ZÇĞİÖŞÜ\-']", "", x) for x in tail]
    tail = [x for x in tail if len(x) >= 2]
    if not tail:
        return None
    return " ".join(w.capitalize() for w in tail)

# ------------- isim çıkarıcılar -------------
def _extract_name_general(text_u: str) -> Optional[str]:
    t = text_u
    for w in DROP_WORDS:
        t = re.sub(rf"\b{w}\b", " ", t, flags=re.IGNORECASE)
    t = re.sub(r"[^A-ZÇĞİÖŞÜa-zçğıöşü\.\-\'\s]", " ", t).upper()
    t = re.sub(r"\s+", " ", t).strip()
    m = NAME_TOKEN.search(t)
    if m:
        return cleanup_name(m.group(0))
    parts = [p for p in t.split() if len(p) >= 2]
    return cleanup_name(" ".join(parts[-3:])) if len(parts) >= 2 else None

def _extract_name_after_label(text: str, label_aliases: List[str]) -> Optional[str]:
    raw = text or ""
    lines = [ln.strip() for ln in raw.splitlines() if ln.strip()]
    if not lines:
        return None

    norm_lines = [_norm_text(ln) for ln in lines]
    norm_aliases = [_norm_text(a) for a in label_aliases]

    label_idx = None
    for i, nl in enumerate(norm_lines):
        if any(na in nl for na in norm_aliases):
            label_idx = i; break
    if label_idx is None:
        return None

    cand_lines = lines[label_idx: min(label_idx + 4, len(lines))]

    for cand in cand_lines:
        tmp = _norm_text(cand)
        # etiket/düşürülecek kelimeleri temizle
        for w in set(norm_aliases) | set(_norm_text(w) for w in DROP_WORDS):
            tmp = re.sub(rf"\b{re.escape(w)}\b", " ", tmp)
        tmp = re.sub(r"\s+", " ", tmp).strip()

        if sum(ch.isdigit() for ch in tmp) > 3:
            continue

        m = NAME_TOKEN.search(tmp)
        if m:
            return cleanup_name(m.group(0))

        nm = cleanup_name(tmp)
        if nm:
            return nm
    return None

# =========================
# 1) Kutu normalizasyonu
# =========================
def _to_xywh(b: Any) -> Optional[Tuple[int,int,int,int]]:
    if isinstance(b, (tuple, list, np.ndarray)) and len(b) == 4:
        x,y,w,h = [int(round(float(v))) for v in b];  return (x,y,w,h)
    for attrs in [("x","y","w","h"), ("left","top","width","height")]:
        if all(hasattr(b, a) for a in attrs):
            x,y,w,h = [int(round(float(getattr(b,a)))) for a in attrs];  return (x,y,w,h)
    for attrs in [("x0","y0","x1","y1"), ("left","top","right","bottom")]:
        if all(hasattr(b, a) for a in attrs):
            x0,y0,x1,y1 = [float(getattr(b,a)) for a in attrs]
            return (int(round(x0)), int(round(y0)), int(round(x1-x0)), int(round(y1-y0)))
    if isinstance(b, dict):
        if all(k in b for k in ("x","y","w","h")):
            return (int(b["x"]), int(b["y"]), int(b["w"]), int(b["h"]))
        if all(k in b for k in ("x0","y0","x1","y1")):
            return (int(b["x0"]), int(b["y0"]), int(b["x1"]-b["x0"]), int(b["y1"]-b["y0"]))
    return None

def normalize_boxes(boxes: List[Any]) -> List[Tuple[int,int,int,int]]:
    out=[]
    for b in boxes:
        nb = _to_xywh(b)
        if nb is None: continue
        x,y,w,h = nb
        if w>0 and h>0: out.append((x,y,w,h))
    return out

def draw_boxes_with_ids(img_bgr: np.ndarray,
                        boxes_xywh: List[Tuple[int,int,int,int]],
                        thickness: int = 2) -> np.ndarray:
    vis = img_bgr.copy()
    if vis.ndim == 2:
        vis = cv2.cvtColor(vis, cv2.COLOR_GRAY2BGR)
    for i,(x,y,w,h) in enumerate(boxes_xywh):
        cv2.rectangle(vis, (x,y), (x+w, y+h), (0,200,0), thickness)
        cv2.putText(vis, f"{i}", (x+4, y+18), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,120,0), 2, cv2.LINE_AA)
    return vis

# =========================
# 2) OCR (remote) & imza
# =========================
def _ocr_remote_png(img_bgr: np.ndarray, url: str,
                    lang: str="tur", config: str="--psm 6 --oem 1") -> str:
    ok, buf = cv2.imencode(".png", img_bgr)
    if not ok: return ""
    img_b64 = base64.b64encode(buf).decode()
    payload = {"image": img_b64, "lang": lang, "config": config}
    try:
        r = requests.post(url, json=payload, timeout=30)
        if r.ok:
            j = json.loads(r.text)
            return (j.get("text") or "").strip()
    except Exception:
        pass
    return ""

def ocr_text_from_box_remote(img: np.ndarray, box_xywh: Tuple[int,int,int,int], url: str) -> str:
    x,y,w,h = box_xywh
    roi = img[y:y+h, x:x+w]
    if roi.ndim==2:
        roi = cv2.cvtColor(roi, cv2.COLOR_GRAY2BGR)
    return _ocr_remote_png(roi, url=url, lang="tur", config="--psm 6 --oem 1")

def has_signature(img: np.ndarray, box_xywh: Tuple[int,int,int,int],
                  ink_ratio_thr: float=0.012, thinness_max: float=0.45) -> bool:
    x,y,w,h = box_xywh
    roi = img[y:y+h, x:x+w]
    gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY) if roi.ndim==3 else roi
    thr = cv2.threshold(cv2.GaussianBlur(gray,(3,3),0), 0, 255,
                        cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]
    ink_ratio = cv2.countNonZero(thr) / max(1, w*h)
    if ink_ratio < ink_ratio_thr:
        return False
    cnts,_ = cv2.findContours(thr, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts: return False
    c = max(cnts, key=cv2.contourArea)
    A = cv2.contourArea(c); P = max(1.0, cv2.arcLength(c, True))
    thinness = 4*np.pi*A/(P*P)
    return thinness < thinness_max

# =========================
# 3) Komşudan isim
# =========================
def nearest_name_from_neighbors(i: int,
                                boxes_xywh: List[Tuple[int,int,int,int]],
                                texts_u: List[str],
                                same_row_tol: int = 20,
                                dx_max_factor: float = 1.7) -> Tuple[Optional[str], Optional[int]]:
    xi, yi, wi, hi = boxes_xywh[i]
    row_y_min = yi - same_row_tol
    row_y_max = yi + hi + same_row_tol
    dx_max = int(wi * dx_max_factor)

    cands=[]
    for j,(xj,yj,wj,hj) in enumerate(boxes_xywh):
        if j==i: continue
        if not (row_y_min <= yj <= row_y_max): continue
        if xj <= xi or (xj-xi) > dx_max: continue
        cands.append((j, xj-xi))
    cands.sort(key=lambda t:t[1])

    if not cands:
        below=[]
        for j,(xj,yj,wj,hj) in enumerate(boxes_xywh):
            if j==i: continue
            gap = yj - (yi+hi)
            if 0 < gap < int(1.2*hi):
                below.append((j, abs(xj-xi)))
        below.sort(key=lambda t:t[1])
        cands = below

    for j,_ in cands:
        name = _extract_name_general(texts_u[j])
        if name:
            return name, j
    return None, None

# =========================
# 4) Kutuları incele (debug)
# =========================
def inspect_boxes(lower_img: np.ndarray,
                  boxes: List[Any],
                  NEW_URL: str,
                  ink_ratio_thr: float=0.012,
                  thinness_max: float=0.45,
                  debug: bool=True) -> Tuple[np.ndarray, pd.DataFrame]:
    boxes_xywh = normalize_boxes(boxes)
    vis_img = draw_boxes_with_ids(lower_img, boxes_xywh)

    rows = []
    for i,b in enumerate(boxes_xywh):
        text = ocr_text_from_box_remote(lower_img, b, NEW_URL).strip()
        text_u = text.upper()
        sig  = has_signature(lower_img, b, ink_ratio_thr=ink_ratio_thr, thinness_max=thinness_max)

        # FUZZY rol tespiti
        role_hits = match_roles_fuzzy(text_u, ROLE_ALIASES, per_token_max_dist=2, require_ratio=0.8)

        # Etiket satırından sonra isim ya da genel isim
        name_here = None
        for rk in role_hits:
            name_here = _extract_name_after_label(text, ROLE_ALIASES[rk]) or _extract_name_general(text_u)
            if name_here:
                break
        if name_here:
            name_here = cleanup_name(name_here)

        rows.append({
            "i": i,
            "bbox": b,
            "sig": bool(sig),
            "role_hits": ",".join(role_hits) if role_hits else "",
            "name_in_box": name_here,
            "text_preview": re.sub(r"\s+", " ", text_u)[:160]
        })

    per_box_df = pd.DataFrame(rows, columns=["i","bbox","sig","role_hits","name_in_box","text_preview"])
    if debug:
        print(f"[INFO] {len(boxes_xywh)} box")
        display(per_box_df)

    return vis_img, per_box_df

# =========================
# 5) Nihai tablo
# =========================
def build_bottom_df_from_report(lower_img: np.ndarray,
                                boxes: List[Any],
                                per_box_df: pd.DataFrame) -> pd.DataFrame:
    boxes_xywh = normalize_boxes(boxes)
    texts_u = [None]*len(boxes_xywh)
    sigs    = [False]*len(boxes_xywh)
    for _,r in per_box_df.iterrows():
        i = int(r["i"]); texts_u[i] = str(r["text_preview"]); sigs[i] = bool(r["sig"])

    def _parse_tl(text: str) -> Optional[float]:
        TL_NUM = re.compile(r"(\d{1,3}(?:\.\d{3})*(?:,\d{2})?|\d+)\s*(TL|₺)?", re.IGNORECASE)
        best=None
        for m in TL_NUM.finditer(text or ""):
            raw = m.group(1)
            v = raw.replace(".", "").replace(" ", "").replace(",", ".")
            try:
                val = float(v)
                best = val if (best is None or val>best) else best
            except: pass
        return best

    cap_keys = ["ŞİRKETİN SERMAYESİ","SERMAYESİ VE PAYLARIN TOPLAMI","SERMAYE","TOPLAM İTİBARİ DEĞERİ"]
    idxs = sorted([(sum(k in (t or "") for k in cap_keys), i) for i,t in enumerate(texts_u)], reverse=True)
    sermaye = None
    for score,i in idxs[:3]:
        if score==0: break
        for j in [i-1,i,i+1]:
            if 0 <= j < len(texts_u):
                v = _parse_tl(texts_u[j] or "")
                if v is not None: sermaye=v; break
        if sermaye is not None: break
    if sermaye is None:
        vals = [_parse_tl(t or "") for t in texts_u]
        sermaye = max([v for v in vals if v is not None], default=None)

    out = {
        "sermaye_toplam_tl": sermaye,
        "toplanti_baskani_ad_soyad": None, "toplanti_baskani_imza_var_mi": None,
        "tutanak_yazmani_ad_soyad": None,  "tutanak_yazmani_imza_var_mi": None,
        "bakanlik_temsilcisi_ad_soyad": None, "bakanlik_temsilcisi_imza_var_mi": None,
        "yk_uyesi_ad_soyad": None, "yk_uyesi_imza_var_mi": None,
        "yk_baskani_ad_soyad": None, "yk_baskani_imza_var_mi": None,
        "katip_ad_soyad": None, "katip_imza_var_mi": None,
        "divan_baskani_ad_soyad": None, "divan_baskani_imza_var_mi": None,
    }

    def _maybe_set(k_name, k_sig, val, sig):
        if out[k_name] is None and val: out[k_name] = val
        if out[k_sig]  is None and sig is not None: out[k_sig]  = bool(sig)

    for _,r in per_box_df.iterrows():
        i = int(r["i"]); t = r["text_preview"]; sig_here = bool(r["sig"])
        role_hits = (r["role_hits"] or "").split(",") if r["role_hits"] else []

        # fallback: raporda rol yoksa fuzzy dene
        if not role_hits:
            role_hits = match_roles_fuzzy(t, ROLE_ALIASES)

        if not role_hits:
            continue

        name_here = r.get("name_in_box") or None
        if not name_here:
            # kutudan türet
            for rk in role_hits:
                name_here = _extract_name_after_label(t, ROLE_ALIASES.get(rk, [])) or _extract_name_general(t)
                if name_here: break

        if not name_here:
            # komşudan tamamla
            nn, jn = nearest_name_from_neighbors(i, boxes_xywh, [str(x or "") for x in texts_u])
            if nn:
                name_here = nn
                if jn is not None:
                    sig_here = sigs[jn]

        if name_here:
            name_here = cleanup_name(name_here)

        role = role_hits[0]
        if role == "toplanti_baskani":
            _maybe_set("toplanti_baskani_ad_soyad","toplanti_baskani_imza_var_mi", name_here, sig_here)
        elif role == "tutanak_yazmani":
            _maybe_set("tutanak_yazmani_ad_soyad","tutanak_yazmani_imza_var_mi", name_here, sig_here)
        elif role == "bakanlik_temsilcisi":
            _maybe_set("bakanlik_temsilcisi_ad_soyad","bakanlik_temsilcisi_imza_var_mi", name_here, sig_here)
        elif role == "yk_uyesi":
            _maybe_set("yk_uyesi_ad_soyad","yk_uyesi_imza_var_mi", name_here, sig_here)
        elif role == "yk_baskani":
            _maybe_set("yk_baskani_ad_soyad","yk_baskani_imza_var_mi", name_here, sig_here)
        elif role == "katip":
            _maybe_set("katip_ad_soyad","katip_imza_var_mi", name_here, sig_here)
        elif role == "divan_baskani":
            _maybe_set("divan_baskani_ad_soyad","divan_baskani_imza_var_mi", name_here, sig_here)

    return pd.DataFrame([out])