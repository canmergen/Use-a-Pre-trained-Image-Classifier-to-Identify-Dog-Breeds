def _find_company(
    lines: List[str],
    *,
    fuzzy_type_thresh: float = 0.82,
    fuzzy_join_lines: bool = True,
) -> Tuple[Optional[str], Optional[str]]:
    """
    Üst bölüm OCR satırlarından şirket adını ve türünü yakala.
    Dönüş: (cname_raw, ctype)
    Yaklaşım:
      1) İlk ~12 satırı birleştir (flat).
      2) Tip (A.Ş., LTD. ŞTİ., ANONİM ŞİRKETİ, …) için boşluk/dağınık-harf toleranslı regex ile YER tespit et.
      3) Tip başlangıcından sola doğru token bazlı genişletme yap (header kelimelerinde dur).
      4) 's AN' → 'SAN' birleştirmesi ve basit normalizasyon.
    """
    # ---------------- helpers ----------------
    def _quality_score(name: str) -> float:
        if not name: return 0.0
        s = unicodedata.normalize("NFKC", name)
        letters = sum(ch.isalpha() for ch in s)
        digits  = sum(ch.isdigit() for ch in s)
        if letters < 3 or letters <= digits:
            return 0.0
        toks = [t for t in re.split(r"\s+", s.strip()) if t]
        return 0.6*min(len(s)/80.0, 1.0) + 0.3*min(len(toks)/8.0, 1.0) + 0.1*(letters/(letters+digits+1e-6))

    def _merge_split_san(name: str) -> str:
        name = re.sub(r"\bs\s+an(\.|,)", r"SAN\1", name, flags=re.IGNORECASE)
        name = re.sub(r"\bs\s+an\b", "SAN", name, flags=re.IGNORECASE)
        return name

    def _spaced(word: str) -> str:
        m = (word.replace("İ","I").replace("ı","i")
                 .replace("Ş","S").replace("ş","s")
                 .replace("Ğ","G").replace("ğ","g")
                 .replace("Ü","U").replace("ü","u")
                 .replace("Ö","O").replace("ö","o")
                 .replace("Ç","C").replace("ç","c"))
        letters = [re.escape(ch) for ch in m if ch.strip()]
        return r"\s*".join(letters)

    def _map_type_to_label(type_text: str) -> Optional[str]:
        up = _normalize_line(type_text)
        for creg, label in TYPE_REGEX:
            if creg.search(up):
                return label
        return None

    # header/gürültü bariyeri
    HEADER_WORDS = {
        "GENEL","KURUL","KURULDA","HAZIR","BULUNANLAR","LİSTESİ","LISTESI","TOPLANTI",
        "TUTANAĞI","TUTANAGI","PAY","SAHİBİNİN","SAHIBININ","TC","TCKN","VKN","VKNO",
        "AD","SOYAD","ADRES","ÜNVAN","UNVAN","KATILIM","TEMSİLCİ","IMZA","İMZA",
        "TOPLAM","İTİBARİ","ITIBARI","GÜNDEM"
    }

    # ---------------- inputs ----------------
    src = [ln for ln in (lines or []) if isinstance(ln, str)]
    if not src:
        return None, None

    # ilk 12 satır yeterli; tek karakter/simge satırlarını at
    filt = []
    for ln in src[:12]:
        s = (ln or "").strip()
        if not s:
            continue
        if re.fullmatch(r"[^\wçğıöşüÇĞİÖŞÜ]+|[A-Za-zÇĞİÖŞÜçğıöşü]", s):
            continue
        filt.append(s)

    flat = re.sub(r"\s+", " ", " ".join(filt if filt else src[:12])).strip()
    if not flat:
        return None, None

    # ---------------- type detection ----------------
    spaced_anchors = [
        _spaced("ANONIM")+r"\s+"+_spaced("SIRKET")+r"[Iİ]?",
        _spaced("LIMITED")+r"\s+"+_spaced("SIRKET")+r"[Iİ]?",
        r"L\s*TD\.?\s*"+_spaced("STI"),
        _spaced("A")+r"\.?\s*"+_spaced("S")+r"\.?",  # A.Ş.
        _spaced("AS"),
        _spaced("HOLDING"),
        _spaced("KOOPERATIF"),
        _spaced("KOLEKTIF")+r"\s+"+_spaced("SIRKET")+r"[Iİ]?",
        _spaced("KOMANDIT")+r"\s+"+_spaced("SIRKET")+r"[Iİ]?",
        _spaced("VAKIF"),
        _spaced("DERNEK"),
    ]
    TYPE_ANY = re.compile(r"(?:\b" + r"\b|\b".join(spaced_anchors) + r"\b)", re.IGNORECASE)

    mtype = TYPE_ANY.search(flat)
    if not mtype:
        # geri dönüş: mevcut eski mantığa bırak
        # (senin önceki REGEX/FUZZY blokların aşağıda tekrar çalışacak)
        pass
    else:
        # ---------------- smart left-extend around type ----------------
        ts = mtype.start()  # tipin başladığı index
        left = flat[:ts].rstrip()

        # soldan bir pencere al (yeterince geniş)
        window = left[-160:] if len(left) > 160 else left

        # header bariyerine kadar en sağdaki aday segmenti seç
        # sağdan sola ilk header kelimesi geçişinde kır
        upw = unicodedata.normalize("NFKC", window).upper()
        cut = 0
        for hw in HEADER_WORDS:
            k = upw.rfind(hw)
            if k != -1:
                cut = max(cut, k + len(hw))
        candidate_zone = window[cut:].strip()

        # token bazlı geri genişletme: en az 2 anlamlı (>=3 harf) token yakala
        toks = candidate_zone.split()
        keep = []
        for t in reversed(toks):
            keep.append(t)
            if sum(1 for z in keep if len(re.sub(r"[^A-Za-zÇĞİÖŞÜçğıöşü0-9]", "", z)) >= 3) >= 2:
                # yeterli bağlam toplandı
                pass
        name_guess = " ".join(reversed(keep)).strip()

        # 's AN' → 'SAN' düzeltmesi + sadeleştirme
        name_guess = _merge_split_san(name_guess)
        name_guess = re.sub(r"\s+", " ", name_guess).strip()

        # kalite kontrolü; zayıfsa aşağıdaki klasik yaklaşımlara düş
        if _quality_score(name_guess) > 0:
            ctype = _map_type_to_label(mtype.group(0))
            return name_guess, ctype

    # ---------------- fallback 1: satır çiftlerini birleştirerek ara ----------------
    best = None  # (score, cname_raw, ctype)
    for i in range(len(src)-1):
        pair = re.sub(r"\s+", " ", (src[i] + " " + src[i+1])).strip()
        mm = TYPE_ANY.search(pair)
        if not mm:
            continue
        left = pair[:mm.start()].strip()
        left = _merge_split_san(left)
        if _quality_score(left) <= 0:
            continue
        ctype = _map_type_to_label(mm.group(0))
        if (best is None) or (_quality_score(left) > best[0]):
            best = (_quality_score(left), left, ctype)
    if best:
        return best[1], best[2]

    # ---------------- fallback 2: eski REGEX/FUZZY mantığı ----------------
    best_regex = None  # (score, line_idx, cname_raw, ctype)
    for i, raw in enumerate(src):
        norm = _normalize_line(raw)
        for creg, label in TYPE_REGEX:
            mm = creg.search(norm)
            if not mm:
                continue
            cand = raw.strip() if mm.start() == 0 else raw[:mm.start()].strip()
            if _quality_score(cand) > 0 and ((best_regex is None) or (_quality_score(cand) > best_regex[0]) or (_quality_score(cand) == best_regex[0] and i < best_regex[1])):
                best_regex = (_quality_score(cand), i, str(cand), label)
    if best_regex:
        return best_regex[2], best_regex[3]

    best_fuzzy = None  # (rank, line_idx, cname_raw, ctype)
    for i, raw in enumerate(src):
        norm = _normalize_line(raw)
        best_label, best_score = None, 0.0
        for canonical, variants in CANON_TYPES.items():
            sc = max(_fuzzy_ratio(v, norm) for v in variants)
            if sc > best_score:
                best_score, best_label = sc, canonical
        if best_label and best_score >= fuzzy_type_thresh:
            cand = raw.strip()
            q = _quality_score(cand)
            if q > 0:
                rank = 0.7*best_score + 0.3*min(q, 1.0)
                if (best_fuzzy is None) or (rank > best_fuzzy[0]) or (rank == best_fuzzy[0] and i < best_fuzzy[1]):
                    best_fuzzy = (rank, i, str(cand), best_label)
    if best_fuzzy:
        return best_fuzzy[2], best_fuzzy[3]

    if fuzzy_join_lines and src:
        joined_raw = " ".join(src).strip()
        joined_norm = _normalize_line(joined_raw)
        best_label, best_score = None, 0.0
        for canonical, variants in CANON_TYPES.items():
            sc = max(_fuzzy_ratio(v, joined_norm) for v in variants)
            if sc > best_score:
                best_score, best_label = sc, canonical
        if best_label and best_score >= fuzzy_type_thresh:
            head = " ".join([ln.strip() for ln in src[:3]]).strip()
            cand = head if _quality_score(head) >= _quality_score(joined_raw) else joined_raw
            if _quality_score(cand) > 0:
                return str(cand), best_label

    return None, None