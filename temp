# -*- coding: utf-8 -*-
from __future__ import annotations
from typing import Any, Dict, List, Optional, Tuple
import re, difflib, time, json
import numpy as np

def classify_hazirun_single(
    doc_res: Dict[str, Any],
    *,
    # OCR kaynakları (en az biri)
    tc_new: Optional[Any] = None,                  # callable client: ocr/run_ocr/predict/infer/get_text/__call__
    NEW_URL: Optional[str] = None,                 # REST endpoint (image base64 JSON)

    # OCR ayarları
    ocr_lang: str = "tur+eng+lat",
    ocr_psm: int = 6,
    ocr_oem: int = 1,
    ocr_extra_config: Optional[str] = None,
    http_timeout_s: float = 12.0,
    http_retries: int = 3,
    http_backoff_s: float = 0.9,

    # Performans: başlık bandı + downscale ile OCR
    ocr_on_top_ratio: float = 0.33,               # [0.2, 0.5] önerilir
    ocr_downscale_max_w: int = 2200,              # OCR için yeterli genişlik
    ocr_use_jpeg: bool = True,                    # PNG büyükse JPEG(92) tercih et

    # Tek liste anahtar ifadeler (fuzzy + coverage)
    keywords: Optional[List[str]] = None,
    fuzzy_min_ratio: float = 0.86,                # 0..1
    phrase_window: int = 12,                      # kelime penceresi

    # Karar eşikleri
    min_hit_phrases: int = 3,                     # ≥ bu kadar ifade yakalanırsa kabul
    min_total_score: float = 4.5,                 # veya toplam skor ≥ eşik

    # OCR hatasını negatif sayma kontrolü
    assume_nonhazirun_on_ocr_fail: bool = False,  # False: unknown_pages'a at

    # TABLO zorunluluğu
    require_table: bool = True,
    table_min_intersections: int = 12,            # min. çizgi kesişimi
    table_min_cells: int = 6,                     # min. hücre tahmini (yaklaşık)
    table_min_area_ratio: float = 0.10,           # tablo alanı / sayfa alanı min oran
    table_debug_crop_ratio: float = 0.85,         # en büyük tablo maskesini kırpma için

    # Çıktı
    debug: bool = False
) -> Dict[str, Any]:
    """
    - Önce tablolu sayfa zorunluluğu (morfolojik çizgi çıkarımı): tablo yoksa sayfa 'non_hazirun' (no_table).
    - Varsa: üst bant OCR (downscale + JPEG/PNG) -> HTTP (NEW_URL) -> tc_new fallback.
    - Tek 'keywords' listesiyle fuzzy + token-coverage + prefix bazlı skorlar.
    - En az 1 sayfa eşikleri geçerse belge 'HAZIRUNDUR', aksi halde 'HAZIRUN DEĞİLDİR'.
    - Sadece 'hazirun' sayfalarının image+meta'larını döndürür.
    """

    # ---------------- local helpers ----------------
    def _ratio_init():
        try:
            from rapidfuzz import fuzz
            return lambda a,b: float(fuzz.partial_ratio(a, b)) / 100.0
        except Exception:
            return lambda a,b: difflib.SequenceMatcher(None, a, b).ratio()
    _ratio = _ratio_init()

    def _tr_lower(s: str) -> str:
        return (s or "").replace("I","ı").replace("İ","i").lower()

    def _normalize_text(s: str) -> str:
        t = _tr_lower(s)
        t = re.sub(r"[_–—\-•・·]+", " ", t)
        t = re.sub(r"[^\w\s%./]", " ", t, flags=re.UNICODE)
        t = re.sub(r"\s+", " ", t).strip()
        return t

    WORD_RE = re.compile(r"\w+", flags=re.UNICODE)
    def _tokens(s: str) -> List[str]:
        return WORD_RE.findall(s)

    def _img_top_band_and_downscale(bgr: np.ndarray) -> np.ndarray:
        import cv2
        h, w = bgr.shape[:2]
        top_h = max(1, int(h * max(0.18, min(0.6, ocr_on_top_ratio))))
        roi = bgr[:top_h, :]
        if w > ocr_downscale_max_w:
            scale = ocr_downscale_max_w / float(w)
            nh = max(1, int(round(roi.shape[0] * scale)))
            roi = cv2.resize(roi, (ocr_downscale_max_w, nh), interpolation=cv2.INTER_AREA)
        return roi

    def _img_to_b64(img: np.ndarray) -> str:
        import cv2, base64
        if ocr_use_jpeg:
            ok, buf = cv2.imencode(".jpg", img, [int(cv2.IMWRITE_JPEG_QUALITY), 92])
        else:
            ok, buf = cv2.imencode(".png", img)
        if not ok:
            return ""
        return base64.b64encode(buf).decode("utf-8")

    # ---- tablo tespiti (morfolojik) ----
    def _has_table(bgr: np.ndarray) -> Tuple[bool, Dict[str, Any]]:
        import cv2
        gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
        # adaptif binarizasyon -> çizgileri öne çıkar
        g = cv2.GaussianBlur(gray, (3,3), 0)
        bw = cv2.adaptiveThreshold(g, 255, cv2.ADAPTIVE_THRESH_MEAN_C,
                                   cv2.THRESH_BINARY_INV, 35, 10)
        h, w = bw.shape
        # yatay/dikey çizgi ekstraksiyonu
        horiz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (max(20, w//80), 1))
        vert_kernel  = cv2.getStructuringElement(cv2.MORPH_RECT, (1, max(20, h//50)))
        horiz = cv2.morphologyEx(bw, cv2.MORPH_OPEN, horiz_kernel, iterations=1)
        vert  = cv2.morphologyEx(bw, cv2.MORPH_OPEN, vert_kernel,  iterations=1)
        # çizgileri kalınlaştır
        horiz = cv2.dilate(horiz, np.ones((1,3), np.uint8), iterations=1)
        vert  = cv2.dilate(vert,  np.ones((3,1), np.uint8), iterations=1)
        # kesişimler
        inter = cv2.bitwise_and(horiz, vert)
        intersections = int(np.count_nonzero(inter > 0))
        # büyük tablo bölgesini bul
        lines = cv2.bitwise_or(horiz, vert)
        # bağlı bileşenler
        num, labels, stats, _ = cv2.connectedComponentsWithStats(lines, connectivity=8)
        areas = stats[1:, cv2.CC_STAT_AREA] if num > 1 else np.array([])
        max_area = int(areas.max()) if areas.size else 0
        area_ratio = max_area / float(h*w) if (h*w) else 0.0
        # hücre tahmini: kesişimlerin yoğunluğuna göre kaba yaklaşım
        approx_cells = int(max(intersections // 8, (areas.size > 0) * (max_area // max(1,(w//40)*(h//60)))))
        ok = (
            intersections >= table_min_intersections and
            approx_cells   >= table_min_cells and
            area_ratio     >= table_min_area_ratio
        )
        dbg = {
            "intersections": intersections,
            "approx_cells": approx_cells,
            "max_table_area_ratio": round(area_ratio, 4)
        }
        return bool(ok), dbg

    def _ocr_via_tc_new(img: np.ndarray) -> str:
        if tc_new is None: return ""
        from PIL import Image
        import cv2
        pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        cfg = [f"--psm {int(ocr_psm)}", f"--oem {int(ocr_oem)}"]
        if ocr_extra_config: cfg.append(ocr_extra_config)
        kwargs: Dict[str, Any] = {"lang": ocr_lang, "config": " ".join(cfg)}
        for name in ("ocr","run_ocr","predict","infer","get_text","__call__"):
            fn = getattr(tc_new, name, None)
            if callable(fn):
                try:
                    txt = fn(pil, **kwargs)
                    if isinstance(txt, dict): txt = txt.get("text","")
                    return txt if isinstance(txt, str) else str(txt)
                except TypeError:
                    try:
                        txt = fn(pil, output_type="text", **kwargs)
                        if isinstance(txt, dict): txt = txt.get("text","")
                        return txt if isinstance(txt, str) else str(txt)
                    except Exception:
                        pass
                except Exception:
                    pass
        return ""

    def _ocr_via_http(img: np.ndarray) -> str:
        if not NEW_URL: return ""
        import requests
        payload = {
            "image": _img_to_b64(img),
            "lang": ocr_lang or "tur",
            "config": " ".join(filter(None, [f"--psm {int(ocr_psm)}", f"--oem {int(ocr_oem)}", ocr_extra_config]))
        }
        last_err = None
        for k in range(http_retries + 1):
            try:
                r = requests.post(NEW_URL, json=payload, timeout=http_timeout_s)
                r.raise_for_status()
                try:
                    j = r.json()
                except Exception:
                    j = json.loads(r.text)
                return j.get("text","") or ""
            except Exception as e:
                last_err = e
                if k < http_retries:
                    time.sleep(http_backoff_s * (1.5**k))
                else:
                    if debug: print(f"[OCR HTTP] hata: {last_err}")
        return ""

    def _ocr_text(img_full: np.ndarray) -> Tuple[str, Dict[str, Any]]:
        roi = _img_top_band_and_downscale(img_full)
        txt = ""; err = None
        if NEW_URL:
            try:
                txt = _ocr_via_http(roi)
            except Exception as e:
                err = e
        if not txt and tc_new is not None:
            try:
                txt = _ocr_via_tc_new(roi)
            except Exception as e:
                err = e
        return txt, ({} if err is None else {"error": str(err)})

    def _phrase_best_score(phrase: str, text: str, toks: List[str]) -> Tuple[float, Dict[str, Any]]:
        ph = _tr_lower((phrase or "").strip())
        if not ph: return 0.0, {"why":"empty"}
        s_fz = _ratio(ph, text)
        ph_toks = [t for t in WORD_RE.findall(ph) if t]
        cover_best = 0.0
        if ph_toks and toks:
            need = set(ph_toks)
            for s in range(0, max(1, len(toks)-phrase_window+1), max(1, phrase_window//2)):
                e = min(len(toks), s + phrase_window)
                window = toks[s:e]
                cov = sum(1 for t in need if t in window) / max(1, len(need))
                cover_best = max(cover_best, cov)
        prefix_hits = 0.0
        if ph_toks and toks:
            pref = sum(1 for t in ph_toks if any(tt.startswith(t) for tt in toks))
            prefix_hits = pref / max(1, len(ph_toks))
        best = max(s_fz, cover_best, prefix_hits)
        return best, {"fuzzy": round(s_fz,3), "coverage": round(cover_best,3), "prefix": round(prefix_hits,3), "best": round(best,3)}

    # ---------------- defaults ----------------
    if keywords is None:
        keywords = [
            # başlık ve varyantlar
            "hazır bulunanlar listesi","hazir bulunanlar listesi","hazirun cetveli",
            "genel kurul","olağan genel kurul","liste örneği",
            # tablo başlıkları / alanlar
            "pay sahibinin ad soyad unvanı","ad soyad","ad/soyad/unvanı","kimlik numarası",
            "vergi kimlik","mersis numarası","uyruğu","adresi",
            "payların itibari değeri","ediniliş şekli","ediniliş tarihi",
            "katılım şekli","temsilci türü","temsilcinin ad soyad unvanı",
            "temsilcinin kimlik numarası","imza",
            # alt metin
            "şirketin sermayesi","payların toplam itibari değeri",
            "asgari toplantı nisabı","mevcut toplantı nisabı",
            # imza blokları
            "divan başkanı","oy toplama memuru","yönetim kurulu üyeleri",
            # şirket tipleri
            "anonim şirketi","a.ş","aş","limited şirketi","ltd şti","ltd. şti."
        ]

    images: List[np.ndarray] = list(doc_res.get("images", []))
    metas:  List[Dict[str, Any]] = list(doc_res.get("metas", []))
    n = len(images)

    hazirun_pages: List[Dict[str, Any]] = []
    non_hazirun_pages: List[Dict[str, Any]] = []
    unknown_pages: List[Dict[str, Any]] = []
    first_match_index: Optional[int] = None

    for i in range(n):
        img = images[i]

        # 1) TABLO zorunluluğu
        if require_table:
            has_tbl, tbl_dbg = _has_table(img)
            if not has_tbl:
                non_hazirun_pages.append({
                    "index": i,
                    "reason": "no_table",
                    **({"table_debug": tbl_dbg} if debug else {})
                })
                continue  # OCR aşamasına geçmeden reddet
        # 2) OCR (üst bant + downscale, HTTP->fallback)
        text_raw, err_info = _ocr_text(img)

        if not text_raw:
            if assume_nonhazirun_on_ocr_fail:
                non_hazirun_pages.append({"index": i, "reason": "OCR boş/hata", "hits": 0, "total_score": 0.0, **err_info})
            else:
                unknown_pages.append({"index": i, "reason": "OCR boş/hata", **err_info})
            continue

        text = _normalize_text(text_raw)
        toks = _tokens(text)

        # 3) Tek-liste fuzzy/coverage skoru
        hit_cnt, score_sum = 0, 0.0
        ev: List[Dict[str, Any]] = []
        for ph in keywords:
            sc, det = _phrase_best_score(ph, text, toks)
            if sc >= fuzzy_min_ratio:
                hit_cnt += 1
            score_sum += sc
            if debug and sc >= 0.5:
                ev.append({"phrase": ph, **det})

        total_score = hit_cnt + (score_sum / max(1, len(keywords))) * 2.0
        is_hazirun = (hit_cnt >= min_hit_phrases) or (total_score >= min_total_score)

        if is_hazirun:
            if first_match_index is None:
                first_match_index = i
            hazirun_pages.append({
                "index": i,
                "image": images[i],
                "meta": metas[i] if i < len(metas) else {},
                "hits": int(hit_cnt),
                "total_score": float(round(total_score,3)),
                **({"evidence": ev[:20]} if debug else {})
            })
        else:
            row = {"index": i, "reason": "Eşik altı", "hits": int(hit_cnt), "total_score": float(round(total_score,3))}
            if debug:
                row["ocr_preview"] = text[:300]
            non_hazirun_pages.append(row)

    flag = "HAZIRUNDUR" if len(hazirun_pages) > 0 else "HAZIRUN DEĞİLDİR"

    return {
        "flag": flag,
        "first_match_index": first_match_index,
        "hazirun_pages": hazirun_pages,           # sadece eşleşen (image+meta)
        "non_hazirun_pages": non_hazirun_pages,   # tablo yok / eşik altı vb. gerekçeler
        "unknown_pages": unknown_pages,           # OCR başarısız/boş sayfalar
        "page_count": n
    }