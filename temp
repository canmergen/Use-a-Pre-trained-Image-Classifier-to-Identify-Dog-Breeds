# -*- coding: utf-8 -*-
from __future__ import annotations
from typing import Any, Callable, Dict, List, Optional, Tuple
import re, difflib, time, json
import numpy as np

def classify_hazirun_single(
    doc_res: Dict[str, Any],
    *,
    # OCR kaynakları (en az biri)
    tc_new: Optional[Any] = None,           # callable client: ocr/run_ocr/predict/infer/get_text/__call__
    NEW_URL: Optional[str] = None,          # REST endpoint (image base64 JSON)

    # OCR ayarları
    ocr_lang: str = "tur+eng+lat",
    ocr_psm: Optional[int] = 6,
    ocr_oem: Optional[int] = 1,
    ocr_extra_config: Optional[str] = None,
    http_timeout_s: float = 12.0,
    http_retries: int = 3,
    http_backoff_s: float = 0.9,

    # OCR hız/kararlılık için: sadece üst bandı oku
    ocr_on_top_ratio: float = 0.33,         # [0.2, 0.5] tipik
    ocr_downscale_max_w: int = 2200,        # HTTP için downscale (OCR için yeterli)

    # Anahtar ifadeler (tek liste, fuzzy + dağıtık eşleşme)
    keywords: Optional[List[str]] = None,
    fuzzy_min_ratio: float = 0.86,          # 0..1
    phrase_window: int = 12,

    # Karar eşikleri
    min_hit_phrases: int = 3,               # ≥ bu kadar ifade tutarsa
    min_total_score: float = 4.5,           # veya toplam skor ≥ bu eşikse

    # OCR başarısızlığını negatif sayma
    assume_nonhazirun_on_ocr_fail: bool = False,

    # Çıktı
    debug: bool = False
) -> Dict[str, Any]:
    """
    En az bir sayfa eşikleri geçerse belge HAZIRUNDUR.
    OCR hatası alan sayfalar negatif sayılmaz (unknown_pages'a atılır) — istersen
    assume_nonhazirun_on_ocr_fail=True yapabilirsin.
    """

    # ---------------- helpers ----------------
    def _ratio_init():
        try:
            from rapidfuzz import fuzz
            return lambda a,b: float(fuzz.partial_ratio(a, b)) / 100.0
        except Exception:
            return lambda a,b: difflib.SequenceMatcher(None, a, b).ratio()
    _ratio = _ratio_init()

    def _tr_lower(s: str) -> str:
        return (s or "").replace("I","ı").replace("İ","i").lower()

    def _normalize_text(s: str) -> str:
        t = _tr_lower(s)
        t = re.sub(r"[_–—\\-•・·]+", " ", t)
        t = re.sub(r"[^\w\s%./]", " ", t, flags=re.UNICODE)
        t = re.sub(r"\s+", " ", t).strip()
        return t

    WORD_RE = re.compile(r"\w+", flags=re.UNICODE)
    def _tokens(s: str) -> List[str]:
        return WORD_RE.findall(s)

    def _img_top_band_and_downscale(bgr: np.ndarray) -> np.ndarray:
        import cv2
        h, w = bgr.shape[:2]
        top_h = max(1, int(h * max(0.18, min(0.6, ocr_on_top_ratio))))
        roi = bgr[:top_h, :]
        if w > ocr_downscale_max_w:
            scale = ocr_downscale_max_w / float(w)
            nh = max(1, int(round(roi.shape[0] * scale)))
            roi = cv2.resize(roi, (ocr_downscale_max_w, nh), interpolation=cv2.INTER_AREA)
        return roi

    def _img_to_png_b64(img: np.ndarray) -> str:
        import cv2, base64
        ok, buf = cv2.imencode(".png", img)
        if not ok: return ""
        return base64.b64encode(buf).decode("utf-8")

    def _ocr_via_tc_new(img: np.ndarray) -> str:
        if tc_new is None: return ""
        from PIL import Image
        import cv2
        pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        kwargs: Dict[str, Any] = {}
        cfg = []
        if ocr_psm is not None: cfg.append(f"--psm {int(ocr_psm)}")
        if ocr_oem is not None: cfg.append(f"--oem {int(ocr_oem)}")
        if ocr_extra_config:    cfg.append(ocr_extra_config)
        if cfg: kwargs["config"] = " ".join(cfg)
        if ocr_lang: kwargs["lang"] = ocr_lang

        for name in ("ocr","run_ocr","predict","infer","get_text","__call__"):
            fn = getattr(tc_new, name, None)
            if callable(fn):
                try:
                    txt = fn(pil, **kwargs)
                    if isinstance(txt, dict): txt = txt.get("text","")
                    return txt if isinstance(txt, str) else str(txt)
                except TypeError:
                    try:
                        txt = fn(pil, output_type="text", **kwargs)
                        if isinstance(txt, dict): txt = txt.get("text","")
                        return txt if isinstance(txt, str) else str(txt)
                    except Exception:
                        pass
                except Exception:
                    pass
        return ""

    def _ocr_via_http(img: np.ndarray) -> str:
        if not NEW_URL: return ""
        import requests
        payload = {
            "image": _img_to_png_b64(img),
            "lang": ocr_lang or "tur",
            "config": " ".join(
                ([f"--psm {int(ocr_psm)}"] if ocr_psm is not None else []) +
                ([f"--oem {int(ocr_oem)}"] if ocr_oem is not None else []) +
                ([ocr_extra_config] if ocr_extra_config else [])
            )
        }
        last_err = None
        for k in range(http_retries + 1):
            try:
                r = requests.post(NEW_URL, json=payload, timeout=http_timeout_s)
                r.raise_for_status()
                try:
                    j = r.json()
                except Exception:
                    j = json.loads(r.text)
                return j.get("text","") or ""
            except Exception as e:
                last_err = e
                if k < http_retries:
                    time.sleep(http_backoff_s * (1.5**k))
                else:
                    raise last_err
        return ""

    def _ocr_text(img_full: np.ndarray) -> str:
        roi = _img_top_band_and_downscale(img_full)
        # Önce HTTP (varsa), sonra tc_new fallback
        if NEW_URL:
            try:
                t = _ocr_via_http(roi)
                if t: return t
            except Exception as e:
                if debug: print(f"[OCR HTTP] hata: {e}")
        if tc_new:
            t = _ocr_via_tc_new(roi)
            if t: return t
        return ""

    def _phrase_best_score(phrase: str, text: str, toks: List[str]) -> Tuple[float, Dict[str, Any]]:
        ph = _tr_lower((phrase or "").strip())
        if not ph:
            return 0.0, {"why": "empty"}
        # 1) Direct fuzzy
        s_fz = _ratio(ph, text)
        # 2) Coverage in window
        ph_toks = [t for t in _tokens(ph) if t]
        cover_best = 0.0; cover_detail = {}
        if ph_toks and toks:
            need = set(ph_toks)
            # hızlı tarama
            starts = list(range(0, max(1, len(toks)-phrase_window+1), max(1, phrase_window//2)))
            for s in starts:
                e = min(len(toks), s + phrase_window)
                window = toks[s:e]
                cov = sum(1 for t in need if t in window) / max(1, len(need))
                if cov > cover_best:
                    cover_best = cov; cover_detail = {"window_start": s, "window_end": e, "need": len(need)}
        # 3) Prefix
        prefix_hits = 0.0
        if ph_toks and toks:
            pref = sum(1 for t in ph_toks if any(tt.startswith(t) for tt in toks))
            prefix_hits = pref / max(1, len(ph_toks))
        best = max(s_fz, cover_best, prefix_hits)
        return best, {"fuzzy": round(s_fz,3), "coverage": round(cover_best,3), "prefix": round(prefix_hits,3), "best": round(best,3)}

    # ---------------- defaults ----------------
    if keywords is None:
        keywords = [
            "hazır bulunanlar listesi","hazir bulunanlar listesi","hazirun cetveli",
            "genel kurul","olağan genel kurul","liste örneği",
            "pay sahibinin ad soyad unvanı","ad soyad","ad/soyad/unvanı","kimlik numarası",
            "vergi kimlik","mersis numarası","uyruğu","adresi",
            "payların itibari değeri","ediniliş şekli","ediniliş tarihi",
            "katılım şekli","temsilci türü","temsilcinin ad soyad unvanı",
            "temsilcinin kimlik numarası","imza",
            "şirketin sermayesi","payların toplam itibari değeri",
            "asgari toplantı nisabı","mevcut toplantı nisabı",
            "divan başkanı","oy toplama memuru","yönetim kurulu üyeleri",
            "anonim şirketi","a.ş","aş","limited şirketi","ltd şti","ltd. şti."
        ]

    images: List[np.ndarray] = list(doc_res.get("images", []))
    metas:  List[Dict[str, Any]] = list(doc_res.get("metas", []))
    n = len(images)

    hazirun_pages: List[Dict[str, Any]] = []
    non_hazirun_pages: List[Dict[str, Any]] = []
    unknown_pages: List[Dict[str, Any]] = []
    first_match_index: Optional[int] = None

    for i in range(n):
        img = images[i]
        # OCR (retry+fallback içeride; üst band + downscale)
        try:
            raw = _ocr_text(img) or ""
        except Exception as e:
            if assume_nonhazirun_on_ocr_fail:
                non_hazirun_pages.append({"index": i, "reason": f"OCR hata: {e}", "hits": 0, "total_score": 0.0})
            else:
                unknown_pages.append({"index": i, "reason": f"OCR hata: {e}"})
            continue

        text = _normalize_text(raw)
        toks = _tokens(text)

        # Boş metin: unknown olarak işaretle (negatif sayma)
        if not text:
            if assume_nonhazirun_on_ocr_fail:
                non_hazirun_pages.append({"index": i, "reason": "OCR boş metin", "hits": 0, "total_score": 0.0})
            else:
                unknown_pages.append({"index": i, "reason": "OCR boş metin"})
            continue

        # Her ifade için en iyi skor
        hit_cnt = 0; score_sum = 0.0; dbg_details = []
        for ph in keywords:
            sc, det = _phrase_best_score(ph, text, toks)
            if sc >= fuzzy_min_ratio:
                hit_cnt += 1
            score_sum += sc
            if debug and sc >= 0.5:
                dbg_details.append({"phrase": ph, **det})

        total_score = hit_cnt + (score_sum / max(1, len(keywords))) * 2.0
        is_hazirun = (hit_cnt >= min_hit_phrases) or (total_score >= min_total_score)

        if is_hazirun:
            if first_match_index is None:
                first_match_index = i
            hazirun_pages.append({
                "index": i,
                "image": images[i],
                "meta": metas[i] if i < len(metas) else {},
                "hits": int(hit_cnt),
                "total_score": float(round(total_score,3)),
                **({"evidence": dbg_details[:20]} if debug else {})
            })
        else:
            row = {"index": i, "reason": "Eşik altı", "hits": int(hit_cnt), "total_score": float(round(total_score,3))}
            if debug:
                row["ocr_preview"] = text[:300]
            non_hazirun_pages.append(row)

    flag = "HAZIRUNDUR" if len(hazirun_pages) > 0 else "HAZIRUN DEĞİLDİR"

    return {
        "flag": flag,
        "first_match_index": first_match_index,
        "hazirun_pages": hazirun_pages,           # sadece eşleşen sayfalar
        "non_hazirun_pages": non_hazirun_pages,   # negatifler (gerekçeli)
        "unknown_pages": unknown_pages,           # OCR fail/boş metin
        "page_count": n
    }