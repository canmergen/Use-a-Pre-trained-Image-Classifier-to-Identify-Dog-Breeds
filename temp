def clean_header_phrase_substrings(
    top_df: pd.DataFrame,
    *,
    text_col: str = "şirket_adı",
    fuzzy_threshold: int = 82,      # istersen 78-85 aralığında oynat
    min_window_tokens: int = 3,
    max_window_tokens: int = 10,
    max_passes: int = 3,
    debug: bool = False,
    # ---- yeni korumalar ----
    max_header_search_chars: int = 350,   # sadece metnin ilk kısmında başlık arıyoruz
) -> pd.DataFrame:
    """
    Satırları silmez. text_col içindeki 'başlık/şablon' cümlesini (örn. GENEL KURULDA HAZIR BULUNANLAR LİSTESİ)
    yalnızca o blok olarak kaldırır; şirket adı/türüne dokunmaz. OCR gürültüsüne dayanıklı fuzzy alt-dizgi kullanır.
    """

    if text_col not in top_df.columns:
        raise ValueError(f"'{text_col}' column not found")

    # --- 1) sabit şablonlar ---
    exact_patterns = [
        r"GENEL\s+KURULDA\s+HAZ[İI]R\s+BULUNANLAR\s+L[İI]STES[İI]",
        r"HAZ[İI]R\s+BULUNANLAR\s+L[İI]STES[İI]",
        r"TOPLANTIYA\s+KATILANLAR",
        r"TOPLANTI\s+TUTANA[ĞG][Iİ]",
        r"G[UÜ]NDEM\s+MADDELER[İI]",
        r"KARARLAR",
    ]
    exact_re = re.compile("|".join(exact_patterns), flags=re.IGNORECASE)

    templates = [
        "GENEL KURULDA HAZIR BULUNANLAR LISTESI",
        "HAZIR BULUNANLAR LISTESI",
        "TOPLANTIYA KATILANLAR",
        "TOPLANTI TUTANAGI",
        "GUNDEM MADDELERI",
        "KARARLAR",
    ]
    # başlık olma olasılığını güçlendiren anahtar kelimeler (en az birini içermeli)
    header_keywords = {"GENEL","KURUL","HAZIR","BULUNANLAR","LİSTE","LISTE","TOPLANTI","TUTANAK","GÜNDEM","GUNDEM","ÖRNEĞİ","ORNEGI"}

    # --- 2) normalizasyon yardımcıları ---
    tr_map  = str.maketrans({"İ":"I","I":"I","ı":"I","Ş":"S","ş":"S","Ğ":"G","ğ":"G","Ü":"U","ü":"U","Ö":"O","ö":"O","Ç":"C","ç":"C"})
    ocr_map = str.maketrans({"0":"O","1":"I","5":"S","8":"B","2":"Z","!":"I","|":"I"})
    def norm(s: str) -> str:
        s = unicodedata.normalize("NFKD", s or "")
        s = s.translate(tr_map).translate(ocr_map)
        s = re.sub(r"\s+", " ", s)
        return s.strip().upper()

    # --- 3) tokenizasyon: span bilgisi saklanır ---
    token_re = re.compile(r"\w+", flags=re.UNICODE)
    def tokenize_with_spans(s: str) -> list[tuple[str,int,int]]:
        return [(m.group(0), m.start(), m.end()) for m in token_re.finditer(s)]

    # --- 4) fuzzy skorlayıcı ---
    try:
        from rapidfuzz.fuzz import token_set_ratio, partial_ratio
        def fuzzy_score(a: str, b: str) -> int:
            return max(token_set_ratio(a, b), partial_ratio(a, b))
    except Exception:
        def fuzzy_score(a: str, b: str) -> int:
            return 0  # RapidFuzz yoksa sadece exact çalışır

    # --- 5) type-guard: şirket türü demirleri görülürse o span silinmeyecek
    TYPE_ANCHOR = re.compile(
        r"(?:\bANON[İI]M\s+Ş[İI]RKET[İI]\b|\bA\.?\s*Ş\b|\bAŞ\b|\bA\.?\s*S\b|"
        r"\bLTD\s*\.?\s*ŞT[İI]\b|\bLTD\s*\.?\s*ST[İI]\b|\bL[İI]M[İI]TED\s+Ş[İI]RKET[İI]\b|"
        r"\bHOLD[İI]NG\b|\bKOOPERAT[İI]F\b|\bKOMAND[İI]T\s+Ş[İI]RKET[İI]\b|\bDERNEK\b|\bVAKF[İI]\b|\bVAKIF\b)",
        re.IGNORECASE
    )

    def remove_span(text: str, start: int, end: int) -> str:
        new_text = (text[:start] + " " + text[end:]).strip()
        return re.sub(r"\s{2,}", " ", new_text)

    def looks_like_header(s_norm: str) -> bool:
        # en az bir header kelimesi içermeli
        return any(k in s_norm for k in header_keywords)

    def clean_once(original: str) -> tuple[str,bool]:
        # 0) sadece baştaki kısımda arama yap (çok uzun satırları korur)
        head_limit = max_header_search_chars
        search_area = original[:head_limit]

        # a) exact kaldırma
        new_s, n = exact_re.subn(" ", search_area)
        if n > 0:
            cleaned = remove_span(original, 0, len(search_area)).replace(search_area, re.sub(r"\s{2,}"," ", new_s).strip()+" ")
            return re.sub(r"\s{2,}", " ", cleaned).strip(), True

        # b) fuzzy alt-dizgi penceresi
        toks = tokenize_with_spans(search_area)
        if not toks:
            return original, False

        best = (-1, None, None)  # (score, st, en)
        for win in range(min_window_tokens, max(min(len(toks), max_window_tokens)+1, min_window_tokens)):
            for i in range(0, len(toks)-win+1):
                st = toks[i][1]; en = toks[i+win-1][2]
                cand = search_area[st:en]
                n_cand = norm(cand)
                if not n_cand:
                    continue
                # header anahtar kelime şartı
                if not looks_like_header(n_cand):
                    continue
                # type-guard: pencere içinde tür demiri varsa atla
                if TYPE_ANCHOR.search(cand):
                    continue
                # tür demirinin SOLUNDA kalmasına özen göster (eğer satırda varsa)
                m_type = TYPE_ANCHOR.search(search_area)
                if m_type and en > m_type.start():
                    continue

                score = max(fuzzy_score(n_cand, norm(t)) for t in templates)
                if score > best[0]:
                    best = (score, st, en)

        score, st, en = best
        if score >= fuzzy_threshold and st is not None:
            cleaned_head = remove_span(search_area, st, en)
            # sadece başta aradığımız bölümü değiştir
            cleaned = original[:0] + cleaned_head + original[len(search_area):]
            return cleaned, True

        return original, False

    cleaned_vals = []
    total_changes = 0
    for val in top_df[text_col].astype(str):
        s = val
        changed_any = False
        for _ in range(max_passes):
            s, changed = clean_once(s)
            if not changed:
                break
            changed_any = True
        cleaned_vals.append(s)
        if changed_any and debug:
            total_changes += 1

    top_df[text_col] = cleaned_vals
    if debug:
        print(f"Updated {total_changes} row(s) in '{text_col}' via guarded header substring removal.")
    return top_df