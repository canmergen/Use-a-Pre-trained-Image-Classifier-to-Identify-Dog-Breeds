def _extract_company(text: str, lines: List[str]) -> Tuple[Optional[str], Optional[str], Dict]:
    dbg = {}
    T_norm = _norm_spaces(text)
    T_raw  = _nfkc(text)
    L = [_norm_spaces(ln) for ln in lines if isinstance(ln,str) and ln.strip()]

    # === 1) Aynı satırda şirket adı + türü (genişletilmiş) ===
    GEN = r"(?:\s*[’'`´\"“”]?\s*(?:NIN|NİN|NUN|NÜN|IN|İN|UN|ÜN))?"
    inline_match = re.search(
        rf"([A-ZÇĞİÖŞÜ0-9\s\.\-\/&’']{{3,}})\s+("
        rf"ANON[İI]M\s+{_spaced_token('ŞİRKET')}"
        rf"|A\.?\s*Ş|AŞ"
        rf"|LTD\s*\.?\s*ŞT[İI]|LTD\s*\.?\s*ST[İI]"
        rf"|L[İI]M[İI]TED\s+{_spaced_token('ŞİRKET')}"
        rf")"
        rf"{GEN}",
        T_norm, flags=re.IGNORECASE|re.DOTALL
    )
    if inline_match:
        cname = re.sub(r"\s+", " ", inline_match.group(1)).strip(" ,.-:;’'")
        raw_type = re.sub(GEN + r"$", "", inline_match.group(2), flags=re.IGNORECASE)
        ctype = _map_type_to_canonical(raw_type)
        cname = re.sub(r"\b(ANONIM|ANONİM|LIMITED|LİMİTED|Ş\s*İ\s*R\s*K\s*E\s*T[İI]|A\.?\s*Ş|AŞ)\b",
                       "", cname, flags=re.IGNORECASE)
        cname = re.sub(r"\s+", " ", cname).strip(" ,.-:;’'")
        return _upper_tr(cname), ctype, {"reason":"inline_match","best_score":1.0,"best_name":cname,"type":ctype}

    # === 2) Yakınlık tabanlı geri tarama ===
    AS   = r"(?:A\.?\s*Ş|A\.?\s*S|AŞ|AS)"+GEN
    ANON = r"ANON[İI]M\s+"+_spaced_token("ŞİRKET")+GEN
    LTD  = r"(?:LTD\s*\.?\s*ŞT[İI]|LTD\s*\.?\s*ST[İI]|L[İI]M[İI]TED\s+"+_spaced_token("ŞİRKET")+r")"+GEN
    SIRK = _spaced_token("ŞİRKET")+GEN
    CORE = rf"(?:{AS}|{ANON}|{LTD}|KOLEKT[İI]F\s+{SIRK}|AD[İI]\s+KOMAND[İI]T\s+{SIRK}|SERMAYES[İI]\s+PAYLARA\s+BÖLÜNMÜŞ\s+KOMAND[İI]T\s+{SIRK}|KOMAND[İI]T\s+{SIRK}|HOLD[İI]NG|KOOPERAT[İI]F|VAKF[Iİ]|VAKIF|DERNEK)"
    TYPE_RE = re.compile(CORE, re.IGNORECASE)
    matches = list(TYPE_RE.finditer(T_norm))
    if not matches:
        # --- 2a) Agresif inline fallback (tüm metne bak) ---
        fallback = re.search(
            rf"([A-ZÇĞİÖŞÜ0-9][A-ZÇĞİÖŞÜ0-9\s\.\-\/&’']{{6,}}?)\s+("
            rf"ANON[İI]M\s+{_spaced_token('ŞİRKET')}"
            rf"|A\.?\s*Ş|AŞ"
            rf"|LTD\s*\.?\s*ŞT[İI]|LTD\s*\.?\s*ST[İI]"
            rf"|L[İI]M[İI]TED\s+{_spaced_token('ŞİRKET')}"
            rf")",
            T_norm, flags=re.IGNORECASE|re.DOTALL
        )
        if fallback:
            left  = fallback.group(1)[-200:]  # son 200 karakter
            # tipik başlıkları ayıkla
            left = re.sub(r"GENEL\s+KURULDA\s+HAZIR\s+BULUNANLAR\s+LİSTESİ(?:\s+ÖRNEĞİ)?", " ", left, flags=re.IGNORECASE)
            left = re.sub(r"\s+", " ", left).strip(" ,.-:;’'")
            ctype = _map_type_to_canonical(fallback.group(2))
            return _upper_tr(left), ctype, {"reason":"fallback_inline","raw_left":left,"type":ctype}
        return None, None, {"reason":"no_type_match"}

    # === 2b) Eşleşmelerden aday üret ---
    FILLERS = {"VE","DE","DA","TE","TA","İLE","VEYA","VE.","DE.","DA.","TE.","TA."}
    STOPTAIL = {"AN","VE","TIC","TİC","SAN","VE.","TIC.","TİC.","SAN."}
    STOPWORDS = {
        "GENEL","KURUL","TOPLANTISI","TOPLANTISINDA","HAZIR","BULUNANLAR","LİSTESİ","GÜNDEM",
        "TARİHLİ","OLAĞAN","OLAĞANÜSTÜ","YILLIK","TUTANAK","PAY","PAYLARIN","PAYLAR",
        "KİMLİK","VERGİ","SAHİBİNİN","SAHİPLERİNİN","TEMSİLCİ","TEMSİLEN","KATILIM",
        "KATILAN","TOPLAM","EDEN","SAYILI","SIRA","AD/SOYAD","NUMARA","ADRESİ","MERKEZİ",
        "ŞUBE","ÜNVANI","YÖNETİM","GÖREV","LİSTE","EK-",
    }

    def _clean_name(s: str) -> str:
        s = re.sub(r"[^\w\s\.\-\/&’'ÇĞİÖŞÜçğıöşü]", " ", s)
        s = re.sub(r"\s+", " ", s).strip(" ,.-:;’'")
        toks = s.split()
        while toks and (toks[-1].upper() in FILLERS or toks[-1].upper() in STOPTAIL or len(toks[-1]) < 3):
            toks.pop()
        toks = [t for t in toks if t.upper() not in STOPWORDS]
        while toks and len(toks[0]) < 2: toks.pop(0)
        return " ".join(toks).strip(" ,.-:;’'")

    def _compact_right(tokens: List[str], min_tok=2, max_tok=14) -> str:
        tokens = tokens[-max_tok:]
        for start in range(max(0, len(tokens)-min_tok), -1, -1):
            cand = " ".join(tokens[start:])
            if _score_name(cand) > 0:
                return cand
        return " ".join(tokens[-min_tok:])

    candidates: List[Tuple[float,str,str]] = []
    for m in matches:
        ctype = _map_type_to_canonical(m.group(0))
        at = m.start()
        left_raw = T_raw[max(0, at-800):at]  # pencereyi biraz büyüttüm
        boundary = max(left_raw.rfind("\n"), left_raw.rfind(";"), left_raw.rfind(":"),
                       left_raw.rfind("."), left_raw.rfind("—"), left_raw.rfind("–"))
        seg = left_raw[boundary+1:] if boundary >= 0 else left_raw
        seg = _clean_name(seg)
        seg = _compact_right(seg.split(), 2, 14)
        if seg:
            dist = len(left_raw) - (boundary+1 if boundary>=0 else 0)
            prox = max(0.0, 1.0 - dist/700.0)
            sc = 0.75*_score_name(seg) + 0.25*prox
            candidates.append((sc, seg, ctype or ""))

    if not candidates:
        # --- 2c) Agresif fallback: tip + önceki satır ---
        last = matches[-1]
        ctype_last = _map_type_to_canonical(last.group(0)) or _map_type_to_canonical(T_norm)
        ctx = T_norm[max(0, last.start()-240):last.start()]
        # son boş olmayan satır
        parts = [p.strip(" ,.-:;’'") for p in ctx.splitlines() if p.strip()]
        guess = parts[-1] if parts else ctx.strip(" ,.-:;’'")
        guess = re.sub(r"GENEL\s+KURULDA\s+HAZIR\s+BULUNANLAR\s+LİSTESİ(?:\s+ÖRNEĞİ)?", " ", guess, flags=re.IGNORECASE)
        guess = re.sub(r"\s+", " ", guess).strip(" ,.-:;’'")
        return (_upper_tr(guess) if guess else None), ctype_last, {"reason":"no_candidates_fallback","line_guess":guess,"type":ctype_last}

    best = max(candidates, key=lambda x: x[0])
    cname = best[1]
    ctype = best[2] or _map_type_to_canonical(matches[-1].group(0)) or _map_type_to_canonical(T_norm)
    return _upper_tr(cname), ctype, {"best_score":best[0], "best_name":cname, "type":ctype}