def _extract_company(text: str, lines: List[str]) -> Tuple[Optional[str], Optional[str], Dict]:
    """
    1) Tür demirini aşırı toleranslı yakala (ŞİRKET / S I R K E T, A.Ş., LTD. ŞTİ. vs.)
    2) Demirin solundan 1200 char pencere al; son 6 satır + aynı satır solundan aday üret.
    3) Gürültü başlıkları at; kısa doldurucuları ve 'AN/VE/TİC/SAN' kuyruklarını kes.
    4) Uzunluk + token + büyük harf oranı + alan anahtarları ile skorla; en iyiyi döndür.
    """
    dbg: Dict = {}
    T = unicodedata.normalize("NFKC", text or "")
    if not T.strip():
        return None, None, {"reason":"empty_text"}

    # --- helpers (inline) ---
    def upper_tr(s: str) -> str:
        mp = {"i":"İ","ı":"I","ş":"Ş","ğ":"Ğ","ü":"Ü","ö":"Ö","ç":"Ç"}
        return "".join(mp.get(ch, ch.upper()) for ch in s or "")

    def spaced_word(w: str) -> str:
        # "şirket" -> "[sş]\s*[ıi]\s*r\s*k\s*e\s*t[ıi]?"
        m = {"ş": r"[sşSŞ]", "ı": r"[ıiIİ]", "i": r"[ıiIİ]"}
        out = []
        for ch in w.lower():
            if ch in m: out.append(m[ch])
            else:       out.append(re.escape(ch))
        return r"\s*".join(out)
    SIRKET = spaced_word("şirket")

    # --- tür demiri (çok toleranslı) ---
    GEN = r"(?:\s*[’'`´\"“”]?\s*(?:NIN|NİN|NUN|NÜN|IN|İN|UN|ÜN))?"
    TYPE_CORE = (
        rf"(ANON[İI]M\s+{SIRKET}"
        rf"|A\.?\s*Ş|AŞ|A\.?\s*S"
        rf"|LTD\s*\.?\s*ŞT[İI]|LTD\s*\.?\s*ST[İI]"
        rf"|L[İI]M[İI]TED\s+{SIRKET}){GEN}"
    )
    hits = list(re.finditer(TYPE_CORE, T, flags=re.IGNORECASE | re.DOTALL))
    if not hits:
        # en azından türü tüm metinden tahmin et
        return None, _map_type_to_canonical(T), {"reason":"no_type_anchor"}

    m = hits[-1]  # en sondaki tip demiri en güvenlisi
    raw_type = m.group(1)
    ctype = _map_type_to_canonical(raw_type) or _map_type_to_canonical(m.group(0))

    # --- sol bağlamdan aday üret ---
    LEFT_WIN = 1200
    window = T[max(0, m.start()-LEFT_WIN):m.start()]
    win_lines = [ln.strip(" ,.-:;’'") for ln in window.splitlines() if ln.strip()]

    # gürültü / doldurucu sözlükleri
    NOISE = {
        "GENEL","KURUL","TOPLANTISI","TOPLANTISINDA","HAZIR","BULUNANLAR","LİSTESİ","ÖRNEĞİ",
        "TARİHLİ","OLAĞAN","OLAĞANÜSTÜ","GÜNDEM","TUTANAK","LİSTE","EK-","SAYILI",
        "KİMLİK","VERGİ","AD/SOYAD","NUMARASI","NUMARA","ADRESİ","MERKEZİ","ÜNVANI","ŞUBE",
        "TOPLAM","EDEN","KATILIM","TEMSİLCİ","TEMSİLEN"
    }
    STOPTAIL = {"AN","VE","TIC","TİC","SAN","VE.","TIC.","TİC.","SAN.","DE","DA","VEYA","İLE"}

    DOMAIN_HINTS = {
        "HİZMETLERİ","SANAYİ","TİCARET","LOJİSTİK","GIDA","İNŞAAT","TEKSTİL",
        "YAZILIM","ENERJİ","OTOMOTİV","MOBİLYA","MADEN","EĞİTİM","SAĞLIK","SİSTEMLERİ"
    }

    def clean_tokens(s: str) -> List[str]:
        # tür sökümü + başlık gürültüsü atımı + kuyruk kesimi
        s = re.sub(r"\s+", " ", s)
        s = re.sub(rf"\b(ANONIM|ANONİM|LIMITED|LİMİTED|{SIRKET}|LTD\.?\s*ŞTİ|LTD\.?\s*STİ|A\.?\s*Ş|AŞ|A\.?\s*S)\b",
                   "", s, flags=re.IGNORECASE)
        toks = [t for t in s.split() if t.upper() not in NOISE]
        while toks and (toks[-1].upper() in STOPTAIL or len(toks[-1]) < 2):
            toks.pop()
        while toks and len(toks[0]) < 2:
            toks.pop(0)
        return toks

    def score_name(name: str) -> float:
        if not name: return 0.0
        s = unicodedata.normalize("NFKC", name)
        letters = sum(ch.isalpha() for ch in s)
        digits  = sum(ch.isdigit() for ch in s)
        if letters < 3 or letters <= digits:
            return 0.0
        toks = name.split()
        base = 0.55*min(len(s)/90,1.0) + 0.35*min(len(toks)/9,1.0) + 0.10*(letters/(letters+digits+1e-6))
        bonus = 0.12 if any(t.upper() in DOMAIN_HINTS for t in toks) else 0.0
        return base + bonus

    candidates: List[Tuple[float,str]] = []

    # aynı satır: türün sol segmenti
    if win_lines:
        same_left = win_lines[-1]
        # tür kalıbını satır içinde bulup solunu al
        mline = re.search(TYPE_CORE, same_left, flags=re.IGNORECASE)
        if mline:
            toks = clean_tokens(same_left[:mline.start()])
            nm = " ".join(toks)
            candidates.append((score_name(nm), nm))

    # son 6 satır ve (üst+alt) birleşimleri
    n = len(win_lines)
    for i in range(n-1, max(-1, n-6)-1, -1):
        if i >= 0:
            nm = " ".join(clean_tokens(win_lines[i]))
            candidates.append((score_name(nm), nm))
        if i-1 >= 0:
            nm2 = " ".join(clean_tokens(win_lines[i-1] + " " + win_lines[i]))
            candidates.append((score_name(nm2), nm2))

    # en iyi aday
    best_sc, best_nm = 0.0, ""
    for sc, nm in candidates:
        if sc > best_sc:
            best_sc, best_nm = sc, nm

    if best_sc >= 0.30 and best_nm:
        return upper_tr(best_nm), ctype, {"reason":"ok", "score":best_sc, "type":ctype}

    # satır bazlı son yedek: ham metin satırlarında tür geçen satır ve bir üstü
    T_lines = [ln.strip() for ln in T.splitlines() if ln.strip()]
    for k in range(len(T_lines)-1, -1, -1):
        if re.search(TYPE_CORE, T_lines[k], flags=re.IGNORECASE):
            left_inline = re.split(TYPE_CORE, T_lines[k], flags=re.IGNORECASE)[0]
            nm = " ".join(clean_tokens(left_inline))
            if score_name(nm) >= 0.30:
                return upper_tr(nm), ctype, {"reason":"inline_fallback", "type":ctype}
            if k > 0:
                nm2 = " ".join(clean_tokens(T_lines[k-1]))
                if score_name(nm2) >= 0.30:
                    return upper_tr(nm2), ctype, {"reason":"prevline_fallback", "type":ctype}

    # ad bulunamadı; en azından türü ver
    return None, ctype, {"reason":"exhausted", "type":ctype, "hits":len(hits)}