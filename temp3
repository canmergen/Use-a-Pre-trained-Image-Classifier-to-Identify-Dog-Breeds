import re, unicodedata
from typing import Any, List

# --- yardımcılar ---
_TR_MAP = str.maketrans({
    "İ": "I", "I": "I", "ı": "i",
    "Ş": "S", "ş": "s",
    "Ğ": "G", "ğ": "g",
    "Ü": "U", "ü": "u",
    "Ö": "O", "ö": "o",
    "Ç": "C", "ç": "c",
})

def _norm(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = s.translate(_TR_MAP)
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = re.sub(r"[^A-Za-z0-9]+", "", s).lower()
    return s

def _get_text(x: Any) -> str:
    if isinstance(x, str):
        return x
    if isinstance(x, dict):
        for k in ("text", "extractedText", "extracted_text", "full_text"):
            v = x.get(k)
            if isinstance(v, str):
                return v
    return ""

def _build_norm_stream_with_map(src: str):
    """
    src -> norm_stream, norm_idx -> orijinal idx map.
    Boşluk/noktalama/aksan atılırken hangi orijinal indexe denk geldiğini tutar.
    """
    norm_chars = []
    norm_to_orig = []
    # önce TR harfleri düzleştir, aksanları ayır
    tr = src.translate(_TR_MAP)
    decomp = unicodedata.normalize("NFKD", tr)

    # decomp ile src aynı uzunlukta olmayabilir; pozisyon eşlemesi için
    # orijinal indexi ayrı sayaçla götürüyoruz.
    orig_i = 0
    for ch in src:
        # src'deki mevcut karakterin normalize edilmiş eşleniğini üret
        ch_tr = ch.translate(_TR_MAP)
        ch_dec = unicodedata.normalize("NFKD", ch_tr)
        # combining mi?
        base = "".join(c for c in ch_dec if not unicodedata.combining(c))
        base = re.sub(r"[^A-Za-z0-9]+", "", base)
        if base:
            for _ in base.lower():
                norm_chars.append(_)
                norm_to_orig.append(orig_i)
        orig_i += 1

    return "".join(norm_chars), norm_to_orig

# --- ana fonksiyon ---
def align_region_texts_by_substring(
    paddle_ocr_texts: Any,                 # str | dict | List[str|dict]
    paddle_ocr_regions: Any,               # List[dict] | List[List[dict]]
):
    """
    Region textlerini, sayfa metni içinde normalize-alt-dizi eşleşmesi bulunursa
    sayfadaki orijinal yazımla değiştirir; bulunamazsa olduğu gibi bırakır.
    Yapı korunur (tek sayfa -> List[dict], çok sayfa -> List[List[dict]]).
    """
    is_multi = len(paddle_ocr_regions) > 0 and isinstance(paddle_ocr_regions[0], list)
    pages = paddle_ocr_regions if is_multi else [paddle_ocr_regions]
    page_texts = paddle_ocr_texts if isinstance(paddle_ocr_texts, list) else [paddle_ocr_texts]*len(pages)

    out_pages: List[List[dict]] = []
    for i, regs in enumerate(pages):
        page_text_raw = _get_text(page_texts[i]) if i < len(page_texts) else ""
        norm_stream, norm2orig = _build_norm_stream_with_map(page_text_raw)

        page_out = [dict(r) for r in regs]
        for r in page_out:
            r_txt = _get_text(r)
            r_norm = _norm(r_txt)
            if not r_norm:
                continue
            # norm akışında alt dizi ara
            j = norm_stream.find(r_norm)
            if j != -1:
                # norm akışındaki [j, j+len) aralığını orijinal indekslere geri çevir
                start_orig = norm2orig[j]
                end_norm_idx = j + len(r_norm) - 1
                end_orig = norm2orig[end_norm_idx]
                # orijinal substring (kapalı aralık, bu yüzden +1)
                canonical_piece = page_text_raw[start_orig:end_orig+1]
                if canonical_piece.strip():
                    r["text"] = canonical_piece  # yalnızca parça değişir
        out_pages.append(page_out)

    return out_pages if is_multi else out_pages[0]

paddle_ocr_regions_aligned = align_region_texts_by_substring(
    paddle_ocr_texts,
    paddle_ocr_regions
)