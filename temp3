# -*- coding: utf-8 -*-
def extract_roles_and_bottom(
    lower_img,
    result,
    table_df_final,
    ocr_fn,                         # def ocr_fn(img, xywh, *, lang, psm, oem, url) -> str
    *,
    new_url=None,
    lang="tur+eng",
    psm_list=(11, 6),
    oem_list=(1, 3),
    known_names=None,
    role_threshold=0.60,            # metin fallback eşiği
    soft_toplanti_floor=0.50,       # toplanti_baskani soft-assign
    name_sim_threshold=0.88,        # bilinen isimle eşleme eşiği
    force_margin_px=10,             # roleblock kapsama toleransı
    iou_thresh=0.25,                # roleblock IoU eşiği
    debug=False,
):
    import re, unicodedata
    from dataclasses import dataclass
    from typing import Any, Dict, List, Optional, Tuple
    import numpy as np
    import pandas as pd
    from rapidfuzz import fuzz

    # =========================
    # Text utilities
    # =========================
    def tr_upper(s: str) -> str:
        return (s or "").replace("i","İ").replace("ı","I").upper()
    def tr_lower(s: str) -> str:
        return (s or "").replace("I","ı").replace("İ","i").lower()
    def tr_title(s: str) -> str:
        parts = re.split(r"(\s+)", s or ""); out=[]
        for w in parts:
            if not w or w.isspace(): out.append(w); continue
            out.append(tr_upper(w[:1]) + tr_lower(w[1:]))
        return "".join(out)
    def strip_diac(s: str) -> str:
        return "".join(c for c in unicodedata.normalize("NFD", s) if not unicodedata.combining(c))
    def canon_key(name: str) -> str:
        k = re.sub(r"[^A-ZÇĞIİÖŞÜ ]", " ", tr_upper(strip_diac(name or "")))
        toks = [t for t in k.split() if len(t) >= 2]
        return " ".join(toks)
    def norm_space(s: str) -> str:
        return re.sub(r"\s+", " ", (s or "").strip())
    def is_all_caps_ctx(s: str) -> bool:
        letters = re.findall(r"[A-ZÇĞIİÖŞÜ]", tr_upper(s or ""))
        total   = len(re.findall(r"[A-Za-zÇĞIİÖŞÜçğıişöü]", s or ""))
        return len(letters) >= max(1, int(0.8*total))

    # =========================
    # Geometry
    # =========================
    def to_xywh(obj: Any) -> Optional[Tuple[int,int,int,int]]:
        if isinstance(obj, dict) and "bbox" in obj: obj = obj["bbox"]
        if isinstance(obj, (tuple, list, np.ndarray)) and len(obj)==4:
            x1,y1,a,b = [int(round(float(v))) for v in obj]
            if a>x1 and b>y1: return (x1,y1,a-x1,b-y1)  # xyxy
            return (x1,y1,a,b)
        if isinstance(obj, dict):
            if all(k in obj for k in ("x","y","w","h")):
                return (int(obj["x"]), int(obj["y"]), int(obj["w"]), int(obj["h"]))
            if all(k in obj for k in ("x0","y0","x1","y1")):
                x0,y0,x1,y1 = int(obj["x0"]),int(obj["y0"]),int(obj["x1"]),int(obj["y1"])
                return (x0,y0,x1-x0,y1-y0)
        if hasattr(obj, "__dict__"):
            def get(o,*n):
                for t in n:
                    if hasattr(o,t): return getattr(o,t)
                return None
            x=get(obj,"x","x0","left"); y=get(obj,"y","y0","top")
            w=get(obj,"w","width");     h=get(obj,"h","height")
            x1=get(obj,"x1","right");   y1=get(obj,"y1","bottom")
            if None not in (x,y,w,h):   return (int(x),int(y),int(w),int(h))
            if None not in (x,y,x1,y1): return (int(x),int(y),int(x1)-int(x),int(y1)-int(y))
        return None
    def xywh_to_xyxy(b): x,y,w,h=b; return (x,y,x+w,y+h)
    def expand_xyxy(b, m): x0,y0,x1,y1=b; return (x0-m, y0-m, x1+m, y1+m)
    def iou_xyxy(a, b):
        ax0,ay0,ax1,ay1=a; bx0,by0,bx1,by1=b
        ix=max(0, min(ax1,bx1)-max(ax0,bx0)); iy=max(0, min(ay1,by1)-max(ay0,by0))
        inter=ix*iy
        if inter<=0: return 0.0
        a_area=max(1,(ax1-ax0)*(ay1-ay0)); b_area=max(1,(bx1-bx0)*(by1-by0))
        return inter/(a_area+b_area-inter)
    def contains_xyxy(outer, inner, tol=0):
        ox0,oy0,ox1,oy1=outer; ix0,iy0,ix1,iy1=inner
        return (ix0>=ox0-tol and iy0>=oy0-tol and ix1<=ox1+tol and iy1<=oy1+tol)

    # =========================
    # OCR helpers
    # =========================
    CONFUSION = str.maketrans({"0":"O","1":"I","5":"S","8":"B","€":"E","$":"S","@":"A"})
    ALT_MAP = {"Ş":"S","Ğ":"G","İ":"I","I":"I","Ü":"U","Ö":"O","Ç":"C",
               "ş":"s","ğ":"g","ı":"i","i":"i","ü":"u","ö":"o","ç":"c"}

    def normalize_hard(s: str) -> str:
        if not s: return ""
        s = "".join(ALT_MAP.get(c, c) for c in s)
        s = unicodedata.normalize("NFD", s)
        s = "".join(c for c in s if not unicodedata.combining(c))
        s = s.translate(CONFUSION).upper()
        s = re.sub(r"[^A-Z0-9\s]", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        # sık OCR hataları
        s = s.replace("TOFLANI","TOPLANTI").replace("TOPLANI","TOPLANTI").replace("TOPLANT1","TOPLANTI")
        s = s.replace("BAS KANI","BASKANI").replace("BAS I","BASKANI")
        return s

    def ocr_text(img, xywh, lang, psm_list, oem_list, url):
        x,y,w,h = xywh
        pad = max(3, int(0.04*max(w,h)))
        crop=(max(0,x-pad), max(0,y-pad),
              min(img.shape[1],x+w+pad)-max(0,x-pad),
              min(img.shape[0],y+h+pad)-max(0,y-pad))
        best=""; bestq=-1e9
        for psm in psm_list:
            for oem in oem_list:
                try:
                    txt=ocr_fn(img, crop, lang=lang, psm=psm, oem=oem, url=url)
                except Exception:
                    txt=""
                q = len(re.findall(r"[A-Za-zÇĞIİÖŞÜçğışöü]", txt)) - 2*len(re.findall(r"[^\w\s]", txt))
                if q>bestq: bestq, best = q, txt
        return best

    # =========================
    # Role dictionaries and fuzzy role detector
    # =========================
    ROLE_PRIORITY = ["sermaye","toplanti_baskani","bakanlik_temsilcisi",
                     "yk_baskani","yk_uyesi","tutanak_yazmani","katip","divan_baskani"]

    ROLE_ALIASES = {
        "toplanti_baskani": ["TOPLANTI BASKANI","TOPLANTI BSK","TOPLANTI BASKAN","TOPLANTI BASKAN I"],
        "bakanlik_temsilcisi": ["BAKANLIK TEMSILCISI","TICARET BAKANLIGI TEMSILCISI"],
        "yk_baskani": ["YK BASKANI","YONETIM KURULU BASKANI","YK BSK"],
        "yk_uyesi": ["YK UYESI","YONETIM KURULU UYESI"],
        "tutanak_yazmani": ["TUTANAK YAZMANI","YAZMAN"],
        "katip": ["KATIP","OY TOPLAMA MEMURU","OY TOPLAYICI"],
        "divan_baskani": ["DIVAN BASKANI","DIVAN BSK"],
        "sermaye": [
            "SIRKETIN SERMAYESI",
            "SERMAYESI VE PAYLARIN TOPLAMI ITIBARI DEGERI",
            "ASGARI TOPLANTI NISABI",
            "MEVCUT TOPLANTI NISABI",
        ],
    }

    ROLE_WORD_SET = {
        "TOPLANTI","BASKAN","BASKANI","BAKANLIK","TEMSILCISI","YK","YONETIM","KURULU",
        "UYESI","YAZMAN","KATIP","DIVAN","SERMAYESI","NISABI","PAY","TOPLAMI"
    }

    def gen_ngrams(tokens, nmin=1, nmax=5):
        L=len(tokens)
        for n in range(nmin, min(nmax, L)+1):
            for i in range(0, L-n+1):
                yield " ".join(tokens[i:i+n])

    def fuzzy_best_role(text: str):
        """
        text -> (role or None, score [0..1], reason)
        n-gram + alias + co-occurrence(TOPLANTI, BASKAN[I])
        """
        t = normalize_hard(text)
        toks = t.split()
        has_top = max((fuzz.partial_ratio("TOPLANTI", t), fuzz.token_set_ratio("TOPLANTI", t)))/100.0
        has_bsk = max(fuzz.partial_ratio("BASKAN", t), fuzz.partial_ratio("BASKANI", t))/100.0

        best_role, best_score, why = None, 0.0, ""
        for role in ROLE_PRIORITY:
            aliases = ROLE_ALIASES[role]
            alias_full = max(fuzz.token_set_ratio(t, a) for a in aliases)/100.0
            ng_best = 0.0
            for ng in gen_ngrams(toks, 1, 5):
                ng_best = max(ng_best, max(fuzz.token_set_ratio(ng, a) for a in aliases)/100.0)
            sc = max(alias_full, ng_best)
            if role == "toplanti_baskani" and min(has_top, has_bsk) >= 0.75:
                sc = max(sc, 0.92); why = "co-occur(TOPLANTI+BASKAN[I])"
            if role == "sermaye" and any(ch.isdigit() for ch in t):
                sc = max(sc, sc + 0.05)
            if sc > best_score:
                best_role, best_score, why = role, sc, why or f"alias/ngram:{sc:.2f}"

        if best_score >= role_threshold:
            return best_role, best_score, why
        if best_role == "toplanti_baskani" and best_score >= soft_toplanti_floor and min(has_top, has_bsk) >= 0.70:
            return best_role, best_score, "soft-assign(toplanti+baskan)"
        return None, best_score, "low-score"

    # =========================
    # Name extraction
    # =========================
    def build_role_patterns():
        pats=[]
        cores=[
            r"TOPLANTI\s+BASKAN[I]?", r"(?:YK|YONETIM\s+KURULU)\s+BASKANI",
            r"(?:YK|YONETIM\s+KURULU)\s+UYESI",
            r"(?:TICARET\s+BAKANLIGI|BAKANLIK)\s+TEMSILCISI",
            r"SIRKETIN\s+SERMAYESI",
            r"SERMAYESI\s+VE\s+PAYLARIN\s+TOPLAMI\s+ITIBARI\s+DEGERI",
            r"ASGARI\s+TOPLANTI\s+NISABI", r"MEVCUT\s+TOPLANTI\s+NISABI",
            r"KATIP", r"TUTANAK\s+YAZMANI", r"DIVAN\s+BASKANI",
        ]
        for c in cores:
            pats.append(re.compile(rf"\b{c}\b", flags=re.IGNORECASE))
        for w in ROLE_WORD_SET:
            pats.append(re.compile(rf"\b{re.escape(w)}\b", flags=re.IGNORECASE))
        return pats

    ROLE_PATTERNS = build_role_patterns()
    STOP_SHORT = {"DR","SN","PZ","MR","MRS","MS","DR.","SN.","AV","AV."}

    def scrub_roles(text: str) -> str:
        t = text or ""
        # ağır normalize + bilinen rol kelimelerini sil
        t = normalize_hard(t)
        for pat in ROLE_PATTERNS: t = pat.sub(" ", t)
        # kalan 'TOPLANTI' varyantlarını süpür
        t = re.sub(r"\bT\w*PLANT\w*\b", " ", t)
        t = re.sub(r"\b\d{6,}\b"," ", t)   # uzun ID
        return norm_space(t)

    def clean_tokens(toks: List[str]) -> List[str]:
        out=[]
        for t in toks:
            if t in STOP_SHORT or t in ROLE_WORD_SET: continue
            if len(t) < 2: continue
            out.append(t)
        return out

    def strict_candidates(text: str) -> List[str]:
        txt = scrub_roles(text)
        out=[]
        # ALL CAPS 2-3 kelime
        for m in re.finditer(r"\b([A-ZÇĞIİÖŞÜ]{2,}(?:\s+[A-ZÇĞIİÖŞÜ]{2,}){1,2})\b", tr_upper(txt)):
            toks = clean_tokens(m.group(1).split())
            if 2 <= len(toks) <= 3: out.append(" ".join(toks))
        # Baş harf büyük 2-3 kelime
        for m in re.finditer(r"\b([A-ZÇĞIİÖŞÜ][a-zçğıiöşü’']+(?:\s+[A-ZÇĞIİÖŞÜ][a-zçğıiöşü’']+){1,2})\b", txt):
            toks = clean_tokens(m.group(1).split())
            if 2 <= len(toks) <= 3: out.append(" ".join(toks))
        seen=set(); res=[]
        for n in out:
            k=canon_key(n)
            if k and k not in seen: seen.add(k); res.append(n)
        return res

    def promote_and_format(name: str, ctx: str, KN_CANON: Dict[str,str], thr: float) -> Optional[str]:
        if not name: return None
        key = canon_key(name)
        best = KN_CANON.get(key)
        if not best:
            for k,v in KN_CANON.items():
                if fuzz.token_set_ratio(key, k)/100.0 >= thr:
                    best = v; break
        if not best:
            toks = clean_tokens(name.split())
            if not (2 <= len(toks) <= 3): return None
            best = tr_title(" ".join(toks))
        return tr_upper(best) if is_all_caps_ctx(ctx) else best

    # =========================
    # Known names canon
    # =========================
    if known_names is None:
        pools=[]
        for c in ["pay_sahibinin_ad_soyadi_unvani","temsilci_adi_soyadi_unvani"]:
            if c in table_df_final.columns:
                pools.append(table_df_final[c].dropna().astype(str))
        known_names = pd.concat(pools).dropna().astype(str).unique().tolist() if pools else []
    KN_CANON={}
    for kn in known_names:
        k=canon_key(kn)
        if k and (k not in KN_CANON or len(KN_CANON[k])<len(kn)): KN_CANON[k]=kn

    # =========================
    # Role blocks (header boxes) → classify with fuzzy_best_role
    # =========================
    role_blocks=[]
    for rb in (result.get("roles") or []):
        b = to_xywh(rb if not (isinstance(rb,dict) and "bbox" in rb) else rb["bbox"])
        if not b: continue
        txt = (rb.get("txt") if isinstance(rb, dict) else getattr(rb, "txt", None))
        if not txt or not txt.strip():
            txt = ocr_text(lower_img, b, lang, psm_list, oem_list, new_url)
        r, sc, why = fuzzy_best_role(txt)
        if r:
            role_blocks.append({"bbox": b, "role": r, "score": sc, "txt": txt, "why": why})

    # =========================
    # Final boxes normalize
    # =========================
    def normalize_with_ref(seq):
        out=[]
        if seq is None: return out
        try: it=list(seq)
        except Exception: it=[seq]
        for item in it:
            xywh = to_xywh(item if not (isinstance(item,dict) and "bbox" in item) else item["bbox"])
            if xywh and xywh[2]>0 and xywh[3]>0: out.append((xywh, item))
        return out

    pairs = normalize_with_ref(result.get("final") or result.get("roles") or [])
    boxes_xywh = [p[0] for p in pairs]
    objs        = [p[1] for p in pairs]
    boxes_xyxy  = [xywh_to_xyxy(b) for b in boxes_xywh]

    sigs=[]
    for sb in result.get("sigs", []) or []:
        b = to_xywh(sb if not (isinstance(sb,dict) and "bbox" in sb) else sb["bbox"])
        if b: sigs.append(xywh_to_xyxy(b))

    H,W = lower_img.shape[:2]

    # =========================
    # Per box scoring
    # =========================
    rows=[]
    for i,(xywh,xyxy,obj) in enumerate(zip(boxes_xywh, boxes_xyxy, objs)):
        # text
        obj_txt=None
        if isinstance(obj, dict): obj_txt=obj.get("txt")
        if (obj_txt is None) and hasattr(obj,"txt"): obj_txt=getattr(obj,"txt")
        text = obj_txt if (obj_txt and obj_txt.strip()) else ocr_text(lower_img, xywh, lang, psm_list, oem_list, new_url)
        text = norm_space(text)

        # 1) role-block overlap → forced
        forced=None; reasons=[]
        box_exp_xyxy = expand_xyxy(xyxy, force_margin_px)
        candidates=[]
        for rb in role_blocks:
            rb_xyxy = xywh_to_xyxy(rb["bbox"])
            if contains_xyxy(rb_xyxy, box_exp_xyxy, tol=0) or iou_xyxy(rb_xyxy, box_exp_xyxy) >= iou_thresh:
                bx=(xyxy[0]+xyxy[2])/2.0; by=(xyxy[1]+xyxy[3])/2.0
                rx=(rb_xyxy[0]+rb_xyxy[2])/2.0; ry=(rb_xyxy[1]+rb_xyxy[3])/2.0
                dist = (bx-rx)**2 + (by-ry)**2
                candidates.append({"rb": rb, "dist": dist})
        if candidates:
            chosen = min(candidates, key=lambda c: (c["dist"], -c["rb"].get("score", 0.0)))
            forced = chosen["rb"]["role"]
            reasons.append("roleblock")

        # 2) text fallback with fuzzy
        if forced:
            role_best, role_score = forced, 1.0
        else:
            r, sc, why = fuzzy_best_role(text)
            role_best, role_score = r, sc
            reasons.append(why)

        # names
        cands = strict_candidates(text)
        final=[]
        for c in cands:
            p = promote_and_format(c, text, KN_CANON, name_sim_threshold)
            if p and all(tr_upper(w) not in ROLE_WORD_SET for w in p.split()):
                final.append(p)
        # de-dup in box
        seen=set(); uni=[]
        for n in final:
            k=canon_key(n)
            if k not in seen:
                seen.add(k); uni.append(n)

        # signature overlap
        sig_hit = any(
            (max(xyxy[0], s[0]) < min(xyxy[2], s[2]) and max(xyxy[1], s[1]) < min(xyxy[3], s[3]))
            for s in sigs
        )

        rows.append({
            "i": i,
            "bbox": xywh,
            "sig": sig_hit,
            "role_best": role_best,
            "role_score": float(role_score),
            "role_reasons": ";".join([r for r in reasons if r]),
            "name_in_box": "; ".join(uni) if uni else None,
            "text_preview": text[:220],
        })

    per_box_df = pd.DataFrame(rows, columns=["i","bbox","sig","role_best","role_score","role_reasons","name_in_box","text_preview"])

    # rol bazında isim de-dup
    def _lastname(s: str) -> str:
        toks = canon_key(s).split()
        return toks[-1] if toks else ""
    def dedupe_within_role_strict(df: pd.DataFrame) -> pd.DataFrame:
        out = []; seen = {}
        for _, r in df.iterrows():
            role = r.get("role_best"); names = r.get("name_in_box")
            if not role or not isinstance(names, str) or not names.strip():
                out.append(names); continue
            kept = seen.setdefault(role, [])
            curr = []
            for nm in [p.strip() for p in names.split(";") if p.strip()]:
                add = True
                ck = canon_key(nm); ln = _lastname(nm)
                for prev in kept:
                    if canon_key(prev) == ck:
                        add=False; break
                    if _lastname(prev) == ln:
                        fn1 = " ".join(canon_key(nm).split()[:-1])
                        fn2 = " ".join(canon_key(prev).split()[:-1])
                        if fn1 and fn2 and fuzz.ratio(fn1, fn2) >= 98:
                            add=False; break
                if add:
                    kept.append(nm); curr.append(nm)
            out.append("; ".join(curr) if curr else None)
        df = df.copy(); df["name_in_box"] = out
        return df
    per_box_df = dedupe_within_role_strict(per_box_df)

    # =========================
    # Sermaye değeri (çoklu kaynak)
    # =========================
    sermaye=None
    if "sermaye" in result and result["sermaye"] is not None:
        s_txt = getattr(result["sermaye"], "txt", None) if hasattr(result["sermaye"], "__dict__") \
                else (result["sermaye"].get("txt") if isinstance(result["sermaye"], dict) else None)
        if s_txt:
            m = re.search(r"(\d{1,3}(?:\.\d{3})+)", s_txt)
            if m: sermaye = int(m.group(1).replace(".",""))
    if sermaye is None:
        previews = " ".join(per_box_df["text_preview"].fillna("").tolist())
        m = re.search(r"(\d{1,3}(?:\.\d{3})+)", previews)
        if m: sermaye = int(m.group(1).replace(".",""))
    if sermaye is None and "paylarin_toplam_itibari_degeri(tl)" in table_df_final.columns:
        try:
            sermaye = int(pd.to_numeric(table_df_final["paylarin_toplam_itibari_degeri(tl)"], errors="coerce").fillna(0).sum())
        except Exception:
            pass

    # =========================
    # bottom_df (tek satır)
    # =========================
    out = {
        "sermaye_toplam_tl": sermaye,
        "toplanti_baskani_ad_soyad": None, "toplanti_baskani_imza_var_mi": None,
        "tutanak_yazmani_ad_soyad":  None, "tutanak_yazmani_imza_var_mi":  None,
        "bakanlik_temsilcisi_ad_soyad": None, "bakanlik_temsilcisi_imza_var_mi": None,
        "yk_uyesi_ad_soyad": None, "yk_uyesi_imza_var_mi": None,
        "yk_baskani_ad_soyad": None, "yk_baskani_imza_var_mi": None,
        "katip_ad_soyad": None, "katip_imza_var_mi": None,
        "divan_baskani_ad_soyad": None, "divan_baskani_imza_var_mi": None,
    }
    name_cols = {
        "toplanti_baskani":"toplanti_baskani_ad_soyad",
        "tutanak_yazmani":"tutanak_yazmani_ad_soyad",
        "bakanlik_temsilcisi":"bakanlik_temsilcisi_ad_soyad",
        "yk_uyesi":"yk_uyesi_ad_soyad",
        "yk_baskani":"yk_baskani_ad_soyad",
        "katip":"katip_ad_soyad",
        "divan_baskani":"divan_baskani_ad_soyad",
    }
    sig_cols = {k: v.replace("_ad_soyad","_imza_var_mi") for k,v in name_cols.items()}
    for _,r in per_box_df.iterrows():
        role=r.get("role_best")
        if not role or role=="sermaye": continue
        ncol=name_cols.get(role); scol=sig_cols.get(role)
        raw=r.get("name_in_box")
        if isinstance(raw, str) and ";" in raw:
            parts=[p.strip() for p in raw.split(";") if p.strip()]
        elif isinstance(raw, str) and raw.strip():
            parts=[raw.strip()]
        else:
            parts=[]
        if not parts: continue
        if role=="yk_uyesi":
            out[ncol] = (out[ncol]+"; "+"; ".join(parts)) if out[ncol] else "; ".join(parts)
        else:
            if out[ncol] is None: out[ncol] = "; ".join(parts)
        if scol and out[scol] is None:
            out[scol] = bool(r.get("sig"))
    bottom_df = pd.DataFrame([out])

    if debug:
        try:
            from IPython.display import display
            print(f"[INFO] role_blocks={len(role_blocks)}, boxes={len(per_box_df)}")
            if role_blocks:
                display(pd.DataFrame([{"role":rb["role"], "score":rb["score"], "bbox":rb["bbox"],
                                       "txt":str(rb.get('txt',''))[:80], "why":rb.get("why","")} for rb in role_blocks]))
            display(per_box_df); display(bottom_df)
        except Exception:
            pass

    return per_box_df, bottom_df