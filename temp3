def build_per_box_df_onecall(
    lower_img,
    final_boxes,
    *,
    sig_boxes,
    role_blocks,
    sermaye_boxes,
    known_names,
    ocr_url: str,
    lang: str = "tur+eng+lat",
    role_threshold: float = 0.80,      # sadece loc!="roles" için kullanılır
    name_sim_threshold: float = 0.82,  # isim benzerlik eşiği
):
    """
    - text_preview: roles -> ilgili role_block OCR; diğerleri -> final_box OCR (gerekirse fallback)
    - name_in_box: HER ZAMAN text_preview bazlı.
      * İsimler rollerden ÖNCEKİ metinden alınmaz (kırpılır).
      * Çoklu isim destekli, sıra korunur, '; ' ile ayrılır.
      * Gibberish/boilerplate metinler filtrelenir.
      * known_names varsa, sadece havuzdan eşleşen isimler kabul edilir (gibberish'i kesmek için).
    - sermaye: amount öncelik text_preview; fallback text0/text1.
    """
    import re, json, base64, unicodedata
    from typing import Any, Tuple, List, Dict, Optional
    import numpy as np
    import pandas as pd
    import cv2, requests
    from rapidfuzz import fuzz

    # ---------- geometry ----------
    def _to_xywh(b: Any) -> Optional[Tuple[int,int,int,int]]:
        if isinstance(b, (tuple, list, np.ndarray)) and len(b)==4:
            x,y,w,h = [int(round(float(v))) for v in b]; return (x,y,w,h)
        if isinstance(b, dict):
            if all(k in b for k in ("x","y","w","h")):  return int(b["x"]), int(b["y"]), int(b["w"]), int(b["h"])
            if all(k in b for k in ("x0","y0","x1","y1")):  return int(b["x0"]), int(b["y0"]), int(b["x1"]-b["x0"]), int(b["y1"]-b["y0"])
            if all(k in b for k in ("left","top","right","bottom")):  return int(b["left"]), int(b["top"]), int(b["right"]-b["left"]), int(b["bottom"]-b["top"])
        return None
    def _to_xyxy(b: Any) -> Tuple[int,int,int,int]:
        x,y,w,h = _to_xywh(b); return (x, y, x+w, y+h)
    def _iou(a, b) -> float:
        ax1,ay1,ax2,ay2 = a; bx1,by1,bx2,by2 = b
        ix1,iy1 = max(ax1,bx1), max(ay1,by1); ix2,iy2 = min(ax2,bx2), min(ay2,by2)
        iw, ih = max(0, ix2-ix1), max(0, iy2-iy1); inter = iw*ih
        if inter == 0: return 0.0
        aarea = (ax2-ax1)*(ay2-ay1); barea = (bx2-bx1)*(by2-by1)
        return inter / (aarea + barea - inter + 1e-9)
    def _contains(outer, inner, pad=2) -> bool:
        ox1,oy1,ox2,oy2 = outer; ix1,iy1,ix2,iy2 = inner
        return (ix1 >= ox1-pad) and (iy1 >= oy1-pad) and (ix2 <= ox2+pad) and (iy2 <= oy2+pad)
    def _any_overlap(a, group) -> bool:
        for g in group:
            if _iou(a, g) > 0 or _contains(a, g) or _contains(g, a): return True
        return False
    def _area(bxyxy) -> int:
        x1,y1,x2,y2 = bxyxy
        return max(0, x2-x1) * max(0, y2-y1)
    def _xyxy_to_xywh(bxyxy: Tuple[int,int,int,int]) -> Tuple[int,int,int,int]:
        x1,y1,x2,y2 = bxyxy
        return (x1, y1, max(0, x2-x1), max(0, y2-y1))

    # ---------- normalize ----------
    def _strip_diac(s: str) -> str:
        return "".join(c for c in unicodedata.normalize("NFKD", s) if not unicodedata.combining(c))
    def _U(s: str) -> str:
        s = (s or "").upper(); return re.sub(r"\s+"," ",_strip_diac(s)).strip()
    _OCR_SUBS = {"!":"I","|":"I","ı":"i","İ":"I","1":"I","l":"I","0":"O","€":"E"}
    def _norm_ocr(s: str) -> str:
        if not s: return ""
        s = "".join(c for c in unicodedata.normalize("NFKD", s) if not unicodedata.combining(c))
        s = "".join(_OCR_SUBS.get(c, c) for c in s)
        s = s.upper()
        s = re.sub(r"[^A-Z0-9\s]", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    # ---------- roles ----------
    ROLE_ALIASES: Dict[str, List[str]] = {
        "toplanti_baskani": ["TOPLANTI BAŞKANI","TOPLANTI BASKANI"],
        "divan_baskani":    ["DİVAN BAŞKANI","DIVAN BASKANI"],
        "yk_baskani":       ["YÖNETİM KURULU BAŞKANI","YONETIM KURULU BASKANI","YK BAŞKANI","YK BASKANI","YÖNETİM KURULU BAŞI"],
        "yk_uyesi":         ["YÖNETİM KURULU ÜYESİ","YONETİM KURULU UYESI","YK ÜYESİ","YK UYESI","YÖNETİM KURULU ÜYELERİ","YONETİM KURULU UYELERI"],
        "bakanlik_temsilcisi": ["BAKANLIK TEMSİLCİSİ","BAKANLIK TEMSILCISI","TİCARET BAKANLIĞI TEMSİLCİSİ","TICARET BAKANLIGI TEMSILCISI"],
        "katip": ["KÂTİP","KATİP","OY TOPLAMA MEMURU","OY TOPLAYICI"],
        "tutanak_yazmani": ["IUIANAK","TUTANAK YAZMANI","YAZMAN"],
    }
    ROLE_ANCHORS = {
        "toplanti_baskani": {"TOPLANTI","BASKAN","BASKANI"},
        "divan_baskani":    {"DIVAN","BASKANI"},
        "yk_baskani":       {"YONETIM","KURULU","BASKANI","YK","BAŞKANI"},
        "yk_uyesi":         {"YONETIM","KURULU","UYESI","UYE","UYELERI","YK"},
        "bakanlik_temsilcisi": {"BAKANLIK","TEMSILCISI","TICARET"},
        "katip": {"KATIP","KÂTIP","KATİP","OY","TOPLAMA","MEMURU"},
        "tutanak_yazmani": {"TUTANAK","YAZMANI","YAZMAN"},
    }
    ROLE_PRIORITY = ["toplanti_baskani","divan_baskani","yk_baskani","yk_uyesi","bakanlik_temsilcisi","katip","tutanak_yazmani"]
    ROLE_TOKENS = set(sum([a.split() for v in ROLE_ALIASES.values() for a in v], [])) | {
        "YÖNETİM","KURULU","ÜYE","ÜYELERİ","ÜYELER","ÜYESİ","BAŞKAN","BAŞKANI","KATİP","KÂTİP",
        "DİVAN","OY","TOPLAMA","MEMURU","TEMSİLCİSİ","BAKANLIK","YAZMAN","İMZA","IMZA","KAŞE","MÜHÜR","STAMP"
    }
    ROLE_TOKENS_U = { _U(t) for t in ROLE_TOKENS }

    # — rol öncesini buda —
    ROLE_REGEX = re.compile(
        r"(YÖNETİM\s+KURULU\s+BAŞKANI|YÖNETİM\s+KURULU\s+ÜYELERİ|YÖNETİM\s+KURULU\s+ÜYESİ|YK\s+BAŞKANI|DIVAN\s+BASKANI|DİVAN\s+BAŞKANI|TOPLANTI\s+BAŞKANI|OY\s+TOPLAMA\s+MEMURU|BAKANLIK\s+TEMSİLCİSİ)",
        flags=re.IGNORECASE
    )
    def cut_before_first_role(text: str) -> str:
        if not text: return text
        m = ROLE_REGEX.search(text)
        return text[m.start():] if m else text

    # ---------- gibberish / token filtre ----------
    _NAME_TOKEN_RE = re.compile(r"[A-Za-zÇĞİÖŞÜçğıöşü’']+")
    _BAD_TOKEN = {"VE","VEYA","ILE","İLE"}
    _NON_NAME_TOKENS = {
        "TOPLANTIDA","HAZIR","BULUNAN","ŞİRKETİN","ŞİRKET","PAYLARIN","PAYLARI","TOPLAMI","TOPLAM",
        "NİSAP","NİSABI","MEVCUT","ASGARİ","TİCARİ","MERKEZİ","ADANA","ANKARA","İSTANBUL","MAD","MADDE","SAYI",
        "KARAR","GÜNDEM","HAKKINDA","HAKKINDAKİ","HANELİ","VERGİ","NO","NOSU","MERKEZ","ADRESİ"
    }
    _NON_NAME_TOKENS_U = { _U(t) for t in _NON_NAME_TOKENS }
    _VOWELS = set(list("AEIİOÖUÜaeıioöuü"))
    def _has_vowel(s: str) -> bool:
        return any(ch in _VOWELS for ch in s)
    def _long_consonant_run(s: str, k: int = 5) -> bool:
        run = 0
        for ch in s:
            if ch.isalpha() and ch.upper() not in _VOWELS:
                run += 1
                if run >= k: return True
            else:
                run = 0
        return False
    def is_gibberish_token(tok: str) -> bool:
        U = _U(tok)
        if U in ROLE_TOKENS_U or U in _NON_NAME_TOKENS_U: return True
        if any(ch.isdigit() for ch in tok): return True
        if len(tok) < 2 or len(tok) > 20: return True
        if not _has_vowel(tok): return True
        if _long_consonant_run(tok, k=5): return True
        if re.search(r"[^\wÇĞİÖŞÜçğıöşü]", tok) and len(tok) <= 3: return True
        return False
    def filter_name_tokens(tokens: List[str]) -> List[str]:
        return [t for t in tokens if (not is_gibberish_token(t)) and (_U(t) not in _BAD_TOKEN)]

    # ---------- role skoru ----------
    def _alias_score(T: str, alias: str) -> float:
        A = _norm_ocr(alias)
        s1 = fuzz.token_set_ratio(T, A) / 100.0
        s2 = fuzz.partial_ratio(T, A) / 100.0
        s3 = fuzz.ratio(T, A) / 100.0
        return 0.5*s1 + 0.35*s2 + 0.15*s3
    def _anchor_bonus(T: str, role: str) -> float:
        toks = set(T.split()); ach = ROLE_ANCHORS.get(role, set())
        if not ach: return 0.0
        cov = len(toks & ach) / len(ach)
        return 0.15 * cov
    def best_role_for_text(text: str):
        T = _norm_ocr(text)
        if not T: return (None, 0.0)
        if re.search(r"\bYONETIM\s+KURULU\s+UYE(LERI|SI)\b", T): return ("yk_uyesi", 0.99)
        if re.search(r"\bDIVAN\s+BASKAN[I]?\b", T):              return ("divan_baskani", 0.99)
        meeting_hit = 1 if re.search(r"\bTOPLANTI\s+\S{0,6}\s+BASKAN[I]?\b", T) else 0
        scores = {}
        for role, aliases in ROLE_ALIASES.items():
            s_alias = max(_alias_score(T, a) for a in aliases)
            s = s_alias + _anchor_bonus(T, role)
            if role == "toplanti_baskani" and meeting_hit: s += 0.08
            scores[role] = s
        ranked = sorted(scores.items(), key=lambda kv: (-kv[1], ROLE_PRIORITY.index(kv[0])))
        return ranked[0]

    # ---------- TCKN ----------
    def find_tckn(text: str) -> Optional[str]:
        m = re.findall(r"(?<!\d)(\d{10,11})(?!\d)", (text or "").replace(" ", ""))
        return "; ".join(list(dict.fromkeys(m))) if m else None

    # ---------- sermaye (float) ----------
    _SEP = r"[.\,\s\u00A0\u202F\u2009]"
    _CURR_WORDS = ("TL","TRY","EUR","EURO","₺","€")
    _NUM_RE = re.compile(rf"(?<!\d)(\d{{1,3}}(?:{_SEP}\d{{3}})+|\d+)(?:{_SEP}?\d{{2}})?(?!\d)")
    def _clean_amount_context(text: str) -> str:
        if not text: return ""
        t = text
        for w in _CURR_WORDS: t = re.sub(rf"\b{w}\b", " ", t, flags=re.IGNORECASE)
        t = t.replace("₺"," ").replace("€"," ").replace("\u00A0"," ").replace("\u202F"," ").replace("\u2009"," ")
        return t
    def _to_float_from_token(token: str) -> float | None:
        s = token.replace("\u00A0"," ").replace("\u202F"," ").replace("\u2009"," ").strip().replace(" ","")
        has_dot, has_com = "." in s, "," in s
        if has_dot and has_com:
            last = max(s.rfind("."), s.rfind(","))
            if (len(s) - last - 1) == 2:
                dec = s[last]; other = "," if dec=="." else "."
                s = s.replace(other, "").replace(dec, ".")
            else:
                s = s.replace(".","").replace(",","")
        else:
            if s.count(",")==1 and len(s.split(",")[-1])==2: s = s.replace(",", ".")
            else: s = s.replace(",", "")
            if not (s.count(".")==1 and len(s.split(".")[-1])==2): s = s.replace(".","")
        try: return float(s)
        except Exception: return None
    def extract_amount_float(text: str) -> float | None:
        t = _clean_amount_context(text)
        toks = _NUM_RE.findall(t)
        best = None
        for tok in toks:
            v = _to_float_from_token(tok)
            if v is None: continue
            if (best is None) or (v > best): best = v
        return best

    # ---------- OCR ----------
    def _ocr_remote_png(img_gray, *, psm: int, oem: int) -> str:
        ok, buf = cv2.imencode(".png", img_gray)
        if not ok: return ""
        payload = {"image": base64.b64encode(buf.tobytes()).decode("ascii"), "lang": lang, "config": f"--psm {int(psm)} --oem {int(oem)}"}
        try:
            r = requests.post(ocr_url, data=json.dumps(payload), headers={"Content-Type":"application/json"}, timeout=60)
            r.raise_for_status(); j = r.json()
            return (j.get("text") or "").strip()
        except Exception:
            return ""
    def ocr_box(lower_img, xywh: Tuple[int,int,int,int], psm: int, oem: int) -> str:
        x,y,w,h = xywh
        crop = lower_img[max(0,y):y+h, max(0,x):x+w]
        if crop is None or getattr(crop, "size", 0) == 0: return ""
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY) if crop.ndim==3 else crop
        gray = cv2.fastNlMeansDenoising(gray, None, 15, 7, 21)
        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
        return _ocr_remote_png(bw, psm=psm, oem=oem)

    # ---------- boxes ----------
    final_xywh = [b for b in (_to_xywh(b) for b in final_boxes) if b is not None and b[2]>0 and b[3]>0]
    final_xyxy = [_to_xyxy(b) for b in final_xywh]
    sig_xyxy   = [_to_xyxy(b) for b in (sig_boxes or [])]
    role_xyxy  = [_to_xyxy(b) for b in (role_blocks or [])]
    serm_xyxy  = [_to_xyxy(b) for b in (sermaye_boxes or [])]
    known_pool = list(dict.fromkeys(known_names or []))

    def decide_psm_oem(loc: str) -> Tuple[int,int]:
        if loc == "sermaye": return 1, 1
        if loc == "roles":   return 11, 1
        return 11, 1

    # ---------- role-block seçimi ----------
    def _best_role_block_for(bxyxy: Tuple[int,int,int,int]) -> Optional[Tuple[int,int,int,int]]:
        if not role_xyxy: return None
        inside = [r for r in role_xyxy if _contains(bxyxy, r, pad=2)]
        if inside:
            inside.sort(key=_area, reverse=True); return inside[0]
        best, best_iou = None, 0.0
        for r in role_xyxy:
            i = _iou(bxyxy, r)
            if i > best_iou: best, best_iou = r, i
        return best if best_iou > 0 else None

    # ---------- Çoklu & sıralı isim çıkarımı (DP + rol-öncesi kırp + gibberish + known match) ----------
    def extract_names_multi_dp(text: str, pool: list[str], thr: float = 0.82, require_known_match: bool = True) -> List[str]:
        if not text:
            return []
        text = cut_before_first_role(text)

        toks_all = [(m.group(0), m.start(), m.end()) for m in re.finditer(r"[A-Za-zÇĞİÖŞÜçğıöşü’']+", text)]
        toks = [(t,s,e) for (t,s,e) in toks_all if not is_gibberish_token(t)]
        if not toks: return []

        windows = []
        for L in (3,2):
            for i in range(0, max(0, len(toks)-L+1)):
                seg = toks[i:i+L]
                wtxt = " ".join(t for (t,_,__) in seg)
                g_rate = np.mean([is_gibberish_token(t) for (t,_,__) in seg])
                if g_rate > 0.34:  # çok kirliyse at
                    continue
                s, mapped = 0.0, None
                if pool:
                    wN = _U(wtxt)
                    best_sc, best_nm = 0.0, None
                    for kn in pool:
                        kN = _U(kn)
                        sc = max(fuzz.ratio(wN, kN)/100.0, fuzz.partial_ratio(wN, kN)/100.0)  # sıra koruyan
                        if sc > best_sc:
                            best_sc, best_nm = sc, kn
                    if best_sc >= thr:
                        s += best_sc; mapped = best_nm
                if 6 <= len(wtxt) <= 40: s += 0.10
                if L == 3: s += 0.05
                windows.append((seg[0][1], seg[-1][2], i, i+L-1, wtxt, mapped, s))

        if not windows: return []

        windows.sort(key=lambda x: (x[3], x[0]))
        n = len(windows)
        p = []
        for j in range(n):
            ti = windows[j][2]
            k = j-1
            while k >= 0 and windows[k][3] >= ti:
                k -= 1
            p.append(k)
        dp = [0.0]*n; take = [False]*n
        for j in range(n):
            tscore = windows[j][6] + (dp[p[j]] if p[j]>=0 else 0.0)
            sscore = dp[j-1] if j>0 else 0.0
            if tscore > sscore:
                dp[j] = tscore; take[j] = True
            else:
                dp[j] = sscore
        sel=[]; j=n-1
        while j>=0:
            if take[j]:
                sel.append(j); j = p[j]
            else:
                j -= 1
        sel = sel[::-1]

        names=[]
        for j in sel:
            txt = windows[j][5] if (pool and require_known_match) else (windows[j][5] or windows[j][4])
            if not txt: continue
            toks2 = filter_name_tokens(_NAME_TOKEN_RE.findall(txt))
            if len(toks2) < 2:   # en az ad+soyad
                continue
            if any(len(t) == 1 for t in toks2):
                continue
            nm = " ".join(toks2[:4])
            if nm and all(fuzz.token_set_ratio(nm, ex) < 92 for ex in names):
                names.append(nm)
        return names

    # ---------- loop ----------
    rows = []
    for i, (b_wh, b_xyxy) in enumerate(zip(final_xywh, final_xyxy)):
        loc = "roles" if _any_overlap(b_xyxy, role_xyxy) else ("sermaye" if _any_overlap(b_xyxy, serm_xyxy) else "other")
        sig = any(_contains(b_xyxy, s, pad=2) or _iou(b_xyxy, s) >= 0.02 for s in sig_xyxy)

        psm0, oem0 = decide_psm_oem(loc)
        text0 = ocr_box(lower_img, b_wh, psm=psm0, oem=oem0)

        if loc == "roles":
            rb_xyxy = _best_role_block_for(b_xyxy)
            if rb_xyxy is not None:
                rb_xywh = _xyxy_to_xywh(rb_xyxy)
                preview_src = ocr_box(lower_img, rb_xywh, psm=11, oem=1)
                text_preview = re.sub(r"\s+"," ", preview_src)[:800]
            else:
                text_preview = re.sub(r"\s+"," ", text0)[:800]
        else:
            text_preview = re.sub(r"\s+"," ", text0)[:800]

        role_key, role_score = (None, 0.0)
        if loc == "roles":
            role_key, role_score = best_role_for_text(text0)

        if (not text_preview) or len(text_preview) < 6:
            text1 = ocr_box(lower_img, b_wh, psm=1, oem=1)
            if text1 and len(text1) > len(text_preview):
                if loc == "roles":
                    rk2, rs2 = best_role_for_text(text1)
                    role_key, role_score = rk2, rs2
                text_preview = re.sub(r"\s+"," ", text1)[:800]

        if loc == "sermaye":
            amount_val = extract_amount_float(text_preview) or extract_amount_float(text0)
            if amount_val is None:
                text1 = ocr_box(lower_img, b_wh, psm=1, oem=1)
                amount_val = extract_amount_float(text1)
            if amount_val is not None and float(amount_val).is_integer():
                amount_val = int(amount_val)
            name_in_box = amount_val
        else:
            # isim + TCKN
            tckn_p = find_tckn(text_preview)
            multi = extract_names_multi_dp(text_preview, known_pool, thr=name_sim_threshold, require_known_match=bool(known_pool))
            raw_name = "; ".join(multi) if multi else None

            # yalnız temizlik (sıra korunur, ayraç korunur)
            def sanitize_names_keep(raw_names: Optional[str], raw_text: str) -> Optional[str]:
                if not (raw_names or raw_text): return None
                parts = [p.strip() for p in re.split(r"[;]+", (raw_names or "")) if p.strip()]
                if not parts: parts = [(raw_text or "").strip()]
                cleaned=[]
                for p in parts:
                    toks = filter_name_tokens(_NAME_TOKEN_RE.findall(p))
                    if not toks: continue
                    cleaned.append(" ".join(toks[:4]))
                # tekrarları azalt
                out=[]
                for c in cleaned:
                    if all(fuzz.token_set_ratio(c, o) < 92 for o in out):
                        out.append(c)
                return "; ".join(out) if out else None

            name_clean = sanitize_names_keep(raw_name, raw_name or text_preview)
            name_in_box = (f"{name_clean} | {tckn_p}" if (name_clean and tckn_p) else (tckn_p if not name_clean else name_clean))

        rows.append({
            "i": i, "bbox": b_wh, "loc": loc, "sig": bool(sig),
            "role_best": role_key, "role_score": float(role_score),
            "name_in_box": name_in_box, "text_preview": text_preview
        })

    return pd.DataFrame(rows, columns=["i","bbox","loc","sig","role_best","role_score","name_in_box","text_preview"])