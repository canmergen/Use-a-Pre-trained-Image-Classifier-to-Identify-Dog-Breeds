import re
import unicodedata
from difflib import SequenceMatcher
from typing import Any, List

# --- Normalizasyon yardımcıları ---
_TURKISH_MAP = str.maketrans({
    "İ": "I", "I": "I", "ı": "i",
    "Ş": "S", "ş": "s",
    "Ğ": "G", "ğ": "g",
    "Ü": "U", "ü": "u",
    "Ö": "O", "ö": "o",
    "Ç": "C", "ç": "c",
})

def _normalize(s: str) -> str:
    """Aksan/boşluk/noktalama temizleyip lower'a çeker: 'DİVAN HEYETİ' -> 'divanheyeti'."""
    if not isinstance(s, str):
        return ""
    s = s.translate(_TURKISH_MAP)
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = re.sub(r"[^A-Za-z0-9]+", "", s).lower()
    return s

def _get_text(x: Any) -> str:
    """dict ya da string girdiden metni güvenle al."""
    if isinstance(x, str):
        return x
    if isinstance(x, dict):
        for k in ("text", "extractedText", "extracted_text", "full_text"):
            if k in x and isinstance(x[k], str):
                return x[k]
    return ""

def _sim(a: str, b: str) -> float:
    """difflib benzerlik skoru (0–100)."""
    return SequenceMatcher(a=a, b=b).ratio() * 100.0

# --- Ana fonksiyon ---
def build_paddleocr_regions_aligned(
    paddle_ocr_texts: List[Any],
    paddle_ocr_regions: List[List[dict]],
    fuzzy_threshold: float | None = None,
) -> List[List[dict]]:
    """
    Girdi:
      - paddle_ocr_texts: sayfa başına tek bir 'doğru' metin (string veya dict)
      - paddle_ocr_regions: sayfa başına region listesi (her region dict)
    Çıktı:
      - Aynı yapıdaki yeni liste (sadece region['text'] güncellenmiş olabilir).

    Eşleştirme kuralı:
      - normalize(region.text) == normalize(page_text) ise region['text'] = page_text
      - fuzzy_threshold verilirse, normalize metinler arası benzerlik >= eşik ise günceller.
    Ek:
      - Her region'a debug için 'text_norm' ve 'canonical_norm' alanları eklenir,
        fuzzy kullanılırsa 'match_score' eklenir.
    """
    # Derin kopya (input'u bozmamak için)
    out_pages: List[List[dict]] = []
    for i, regions_on_page in enumerate(paddle_ocr_regions):
        page_copy = [dict(r) for r in regions_on_page]
        canonical_raw = _get_text(paddle_ocr_texts[i]) if i < len(paddle_ocr_texts) else ""
        canonical_norm = _normalize(canonical_raw)

        for r in page_copy:
            r_text = _get_text(r)
            r_norm = _normalize(r_text)
            r["text_norm"] = r_norm
            r["canonical_norm"] = canonical_norm

            match = (r_norm == canonical_norm) and bool(canonical_raw)
            score = None
            if not match and fuzzy_threshold is not None and canonical_norm and r_norm:
                score = _sim(r_norm, canonical_norm)
                r["match_score"] = round(score, 1)
                match = score >= fuzzy_threshold

            if match:
                r["text"] = canonical_raw  # kanonik yazımı birebir uygula

        out_pages.append(page_copy)

    return out_pages

# Yeni adıyla, sadece text’leri düzeltilmiş kopya:
paddle_ocr_regions_aligned = build_paddleocr_regions_aligned(
    paddle_ocr_texts,
    paddle_ocr_regions,
    fuzzy_threshold=None      # istersen 95.0 gibi bir eşik ver
)