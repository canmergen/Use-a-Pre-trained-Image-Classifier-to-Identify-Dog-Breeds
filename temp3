import re, unicodedata
from typing import Any, List, Tuple
from rapidfuzz import fuzz

_TR_MAP = str.maketrans({
    "İ": "I", "I": "I", "ı": "i",
    "Ş": "S", "ş": "s",
    "Ğ": "G", "ğ": "g",
    "Ü": "U", "ü": "u",
    "Ö": "O", "ö": "o",
    "Ç": "C", "ç": "c",
})

def _norm(s: str) -> str:
    if not isinstance(s, str):
        return ""
    s = s.translate(_TR_MAP)
    s = unicodedata.normalize("NFKD", s)
    s = "".join(ch for ch in s if not unicodedata.combining(ch))
    s = re.sub(r"[^A-Za-z0-9]+", "", s).lower()
    return s

def _get_text(x: Any) -> str:
    if isinstance(x, str):
        return x
    if isinstance(x, dict):
        for k in ("text", "extractedText", "extracted_text", "full_text"):
            v = x.get(k)
            if isinstance(v, str):
                return v
    return ""

def _build_norm_stream_with_map(src: str) -> Tuple[str, List[int]]:
    norm_chars, norm2orig = [], []
    for i, ch in enumerate(src):
        ch_tr  = ch.translate(_TR_MAP)
        ch_dec = unicodedata.normalize("NFKD", ch_tr)
        base   = "".join(c for c in ch_dec if not unicodedata.combining(c))
        base   = re.sub(r"[^A-Za-z0-9]+", "", base)
        for _ in base.lower():
            norm_chars.append(_)
            norm2orig.append(i)
    return "".join(norm_chars), norm2orig

def align_region_texts_by_substring_fuzzy_v2(
    paddle_ocr_texts: Any,
    paddle_ocr_regions: Any,
    fuzzy_threshold: int = 90,
    length_tolerance: int = 2,  # norm penceresine ± tolerans
):
    """
    Sadece region['text']'i düzeltir:
      1) norm alt-dizi direkt eşleşirse: birebir parça.
      2) Aksi halde: norm akışında sabit uzunluklu (±tolerans) kaydırmalı fuzzy arama.
         En iyi skor >= threshold ise, tam o norm aralığının orijinal karşılığını al.
    Yapıyı korur (tek/çok sayfa).
    """
    is_multi = len(paddle_ocr_regions) > 0 and isinstance(paddle_ocr_regions[0], list)
    pages = paddle_ocr_regions if is_multi else [paddle_ocr_regions]
    page_texts = paddle_ocr_texts if isinstance(paddle_ocr_texts, list) else [paddle_ocr_texts]*len(pages)

    out_pages: List[List[dict]] = []
    for i, regs in enumerate(pages):
        page_text_raw = _get_text(page_texts[i]) if i < len(page_texts) else ""
        norm_stream, norm2orig = _build_norm_stream_with_map(page_text_raw)

        page_out = [dict(r) for r in regs]
        for r in page_out:
            r_txt  = _get_text(r)
            r_norm = _norm(r_txt)
            if not r_norm:
                continue

            L = len(r_norm)
            # 1) Doğrudan norm alt-dizi
            j = norm_stream.find(r_norm)
            if j != -1:
                s_o = norm2orig[j]
                e_o = norm2orig[j + L - 1]
                r["text"] = page_text_raw[s_o:e_o+1]
                continue

            # 2) Fuzzy: norm akışında sabit pencere (± tolerans)
            best_score, best_s, best_len = -1, None, None
            min_len = max(1, L - length_tolerance)
            max_len = min(len(norm_stream), L + length_tolerance)

            for win_len in range(min_len, max_len + 1):
                if win_len > len(norm_stream):
                    continue
                for start in range(0, len(norm_stream) - win_len + 1):
                    cand = norm_stream[start:start+win_len]
                    score = fuzz.ratio(cand, r_norm)
                    if score > best_score:
                        best_score, best_s, best_len = score, start, win_len

            if best_score is not None and best_score >= fuzzy_threshold:
                s_o = norm2orig[best_s]
                e_o = norm2orig[best_s + best_len - 1]
                r["text"] = page_text_raw[s_o:e_o+1]  # sadece tam eşleşen parça
                # eşik altıysa dokunma
        out_pages.append(page_out)

    return out_pages if is_multi else out_pages[0]

paddle_ocr_regions_aligned = align_region_texts_by_substring_fuzzy_v2(
    paddle_ocr_texts,
    paddle_ocr_regions,
    fuzzy_threshold=88,      # 85–92 arası pratik
    length_tolerance=2       # ekleme/silme için küçük tolerans
)