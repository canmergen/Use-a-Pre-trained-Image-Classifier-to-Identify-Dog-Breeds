def build_per_box_df_onecall(
    lower_img,
    final_boxes,
    *,
    sig_boxes,
    role_blocks,
    sermaye_boxes,
    known_names,
    ocr_url: str,
    lang: str = "tur+eng+lat",
    role_threshold: float = 0.80,      # sadece loc!="roles" için kullanılır
    name_sim_threshold: float = 0.82,
):
    """
    - text_preview: roles -> role_block OCR; diğerleri -> final_box OCR (fallback mümkün)
    - name_in_box: HER ZAMAN text_preview bazlı (çoklu isim + sıra korunur)
    - sermaye: amount öncelik text_preview; fallback text0/text1
    - ad/soyadda rol kelimeleri temizlenir; yeniden sıralama yapılmaz
    """
    import re, json, base64, unicodedata
    from typing import Any, Tuple, List, Dict, Optional
    import numpy as np
    import pandas as pd
    import cv2, requests
    from rapidfuzz import fuzz, process

    # ---------- geometry ----------
    def _to_xywh(b: Any) -> Optional[Tuple[int,int,int,int]]:
        if isinstance(b, (tuple, list, np.ndarray)) and len(b)==4:
            x,y,w,h = [int(round(float(v))) for v in b]; return (x,y,w,h)
        if isinstance(b, dict):
            if all(k in b for k in ("x","y","w","h")):  return int(b["x"]), int(b["y"]), int(b["w"]), int(b["h"])
            if all(k in b for k in ("x0","y0","x1","y1")):  return int(b["x0"]), int(b["y0"]), int(b["x1"]-b["x0"]), int(b["y1"]-b["y0"])
            if all(k in b for k in ("left","top","right","bottom")):  return int(b["left"]), int(b["top"]), int(b["right"]-b["left"]), int(b["bottom"]-b["top"])
        return None
    def _to_xyxy(b: Any) -> Tuple[int,int,int,int]:
        x,y,w,h = _to_xywh(b); return (x, y, x+w, y+h)
    def _iou(a, b) -> float:
        ax1,ay1,ax2,ay2 = a; bx1,by1,bx2,by2 = b
        ix1,iy1 = max(ax1,bx1), max(ay1,by1); ix2,iy2 = min(ax2,bx2), min(ay2,by2)
        iw, ih = max(0, ix2-ix1), max(0, iy2-iy1); inter = iw*ih
        if inter == 0: return 0.0
        aarea = (ax2-ax1)*(ay2-ay1); barea = (bx2-bx1)*(by2-by1)
        return inter / (aarea + barea - inter + 1e-9)
    def _contains(outer, inner, pad=2) -> bool:
        ox1,oy1,ox2,oy2 = outer; ix1,iy1,ix2,iy2 = inner
        return (ix1 >= ox1-pad) and (iy1 >= oy1-pad) and (ix2 <= ox2+pad) and (iy2 <= oy2+pad)
    def _any_overlap(a, group) -> bool:
        for g in group:
            if _iou(a, g) > 0 or _contains(a, g) or _contains(g, a): return True
        return False
    def _area(bxyxy) -> int:
        x1,y1,x2,y2 = bxyxy
        return max(0, x2-x1) * max(0, y2-y1)
    def _xyxy_to_xywh(bxyxy: Tuple[int,int,int,int]) -> Tuple[int,int,int,int]:
        x1,y1,x2,y2 = bxyxy
        return (x1, y1, max(0, x2-x1), max(0, y2-y1))

    # ---------- normalize ----------
    def _strip_diac(s: str) -> str:
        return "".join(c for c in unicodedata.normalize("NFKD", s) if not unicodedata.combining(c))
    def _U(s: str) -> str:
        s = (s or "").upper(); return re.sub(r"\s+"," ",_strip_diac(s)).strip()

    _OCR_SUBS = {"!":"I","|":"I","ı":"i","İ":"I","1":"I","l":"I","0":"O","€":"E"}
    def _norm_ocr(s: str) -> str:
        if not s: return ""
        s = "".join(c for c in unicodedata.normalize("NFKD", s) if not unicodedata.combining(c))
        s = "".join(_OCR_SUBS.get(c, c) for c in s)
        s = s.upper()
        s = re.sub(r"[^A-Z0-9\s]", " ", s)
        s = re.sub(r"\s+", " ", s).strip()
        return s

    # ---------- roles ----------
    ROLE_ALIASES: Dict[str, List[str]] = {
        "toplanti_baskani": ["TOPLANTI BAŞKANI","TOPLANTI BASKANI"],
        "divan_baskani":    ["DİVAN BAŞKANI","DIVAN BASKANI"],
        "yk_baskani":       ["YÖNETİM KURULU BAŞKANI","YONETIM KURULU BASKANI","YK BAŞKANI","YK BASKANI","YÖNETİM KURULU BAŞI"],
        "yk_uyesi":         ["YÖNETİM KURULU ÜYESİ","YONETİM KURULU UYESI","YK ÜYESİ","YK UYESI","YÖNETİM KURULU ÜYELERİ","YONETİM KURULU UYELERI"],
        "bakanlik_temsilcisi": ["BAKANLIK TEMSİLCİSİ","BAKANLIK TEMSILCISI","TİCARET BAKANLIĞI TEMSİLCİSİ","TICARET BAKANLIGI TEMSILCISI"],
        "katip": ["KÂTİP","KATİP","OY TOPLAMA MEMURU","OY TOPLAYICI"],
        "tutanak_yazmani": ["IUIANAK", "TUTANAK YAZMANI","YAZMAN"],
    }
    ROLE_ANCHORS = {
        "toplanti_baskani": {"TOPLANTI","BASKAN","BASKANI"},
        "divan_baskani":    {"DIVAN","BASKANI"},
        "yk_baskani":       {"YONETIM","KURULU","BASKANI","YK","BAŞKANI"},
        "yk_uyesi":         {"YONETIM","KURULU","UYESI","UYE","UYELERI","YK"},
        "bakanlik_temsilcisi": {"BAKANLIK","TEMSILCISI","TICARET"},
        "katip": {"KATIP","KÂTIP","KATİP","OY","TOPLAMA","MEMURU"},
        "tutanak_yazmani": {"IUIANAK", "TUTANAK","YAZMANI","YAZMAN"},
    }
    ROLE_PRIORITY = ["toplanti_baskani","divan_baskani","yk_baskani","yk_uyesi","bakanlik_temsilcisi","katip","tutanak_yazmani"]
    ROLE_TOKENS = set(sum([a.split() for v in ROLE_ALIASES.values() for a in v], [])) | {
        "YÖNETİM","KURULU","ÜYE","ÜYELERİ","ÜYELER","ÜYESİ","BAŞKAN","BAŞKANI","KATİP","KÂTİP",
        "DİVAN","OY","TOPLAMA","MEMURU","TEMSİLCİSİ","BAKANLIK","YAZMAN","İMZA","IMZA","KAŞE","MÜHÜR","STAMP"
    }
    ROLE_TOKENS_U = { _U(t) for t in ROLE_TOKENS }

    def _alias_score(T: str, alias: str) -> float:
        A = _norm_ocr(alias)
        s1 = fuzz.token_set_ratio(T, A)/100.0
        s2 = fuzz.partial_ratio(T, A)/100.0
        s3 = fuzz.ratio(T, A)/100.0
        return 0.5*s1 + 0.35*s2 + 0.15*s3
    def _anchor_bonus(T: str, role: str) -> float:
        toks = set(T.split()); ach = ROLE_ANCHORS.get(role, set())
        if not ach: return 0.0
        cov = len(toks & ach) / len(ach)
        return 0.15 * cov
    def best_role_for_text(text: str):
        T = _norm_ocr(text)
        if not T:
            return (None, 0.0)
        if re.search(r"\bYONETIM\s+KURULU\s+UYE(LERI|SI)\b", T): return ("yk_uyesi", 0.99)
        if re.search(r"\bDIVAN\s+BASKAN[I]?\b", T):              return ("divan_baskani", 0.99)
        meeting_hit = 1 if re.search(r"\bTOPLANTI\s+\S{0,6}\s+BASKAN[I]?\b", T) else 0
        scores = {}
        for role, aliases in ROLE_ALIASES.items():
            s_alias = max(_alias_score(T, a) for a in aliases)
            s = s_alias + _anchor_bonus(T, role)
            if role == "toplanti_baskani" and meeting_hit: s += 0.08
            scores[role] = s
        ranked = sorted(scores.items(), key=lambda kv: (-kv[1], ROLE_PRIORITY.index(kv[0])))
        return ranked[0]

    # ---------- name utils ----------
    _NAME_TOKEN_RE = re.compile(r"[A-Za-zÇĞİÖŞÜçğıöşü’']+")
    _BAD_TOKEN = {"VE","VEYA","ILE","İLE"}

    def _tokens_no_roles(s: str) -> str:
        if not s: return s
        toks = _NAME_TOKEN_RE.findall(s)
        toks = [t for t in toks if _U(t) not in ROLE_TOKENS_U]
        return " ".join(toks)

    def _normalize_name(s: str) -> str:
        return re.sub(r"\s+"," ", s.strip())

    def _split_candidates(name_str: str) -> List[str]:
        if not name_str: return []
        parts = re.split(r"[;|,/]+", name_str)
        return [_normalize_name(p) for p in parts if _normalize_name(p)]

    def _clean_tokens(s: str) -> str:
        toks = _NAME_TOKEN_RE.findall(s)
        toks = [t for t in toks if len(t) >= 2 and _U(t) not in _BAD_TOKEN]
        toks = toks[:3]
        return " ".join(toks)

    def _dedup_similar(names: List[str], thr: float = 0.92) -> List[str]:
        out: List[str] = []
        for n in names:
            if not out: out.append(n); continue
            simmax = max(fuzz.token_set_ratio(n, m)/100.0 for m in out)
            if simmax < thr: out.append(n)
        return out

    def sanitize_names_no_remap(raw_names: Optional[str], raw_text: str) -> Optional[str]:
        """
        Yalnızca temizlik yapar; known_names'a yeniden eşlemez (sıra bozulmasın).
        """
        raw_names = _tokens_no_roles(raw_names or "")
        raw_text  = _tokens_no_roles(raw_text or "")
        cands = _split_candidates(raw_names) if raw_names else []
        if not cands: cands = _split_candidates(_clean_tokens(raw_text))
        cands = [_clean_tokens(_tokens_no_roles(c)) for c in cands]
        cands = [c for c in cands if c]
        cands = _dedup_similar(cands, thr=0.92)
        # son güvenlik
        cleaned=[]
        for n in cands:
            tks = _NAME_TOKEN_RE.findall(n)
            tks = [t for t in tks if _U(t) not in ROLE_TOKENS_U]
            if tks: cleaned.append(" ".join(tks))
        return "; ".join(cleaned) if cleaned else None

    def merge_name_tckn(name: Optional[str], tckn: Optional[str]) -> Optional[str]:
        if name and tckn:
            uniq = list(dict.fromkeys([p.strip() for p in re.split(r"[;,\s]+", tckn) if p.strip()]))
            return f"{name} | {'; '.join(uniq)}"
        if tckn:
            uniq = list(dict.fromkeys([p.strip() for p in re.split(r'[;,\s]+', tckn) if p.strip()]))
            return "; ".join(uniq)
        return name

    # ---------- TCKN ----------
    def find_tckn(text: str) -> Optional[str]:
        m = re.findall(r"(?<!\d)(\d{10,11})(?!\d)", (text or "").replace(" ", ""))
        return "; ".join(list(dict.fromkeys(m))) if m else None

    # ---------- sermaye (float) ----------
    _SEP = r"[.\,\s\u00A0\u202F\u2009]"
    _CURR_WORDS = ("TL","TRY","EUR","EURO","₺","€")
    _NUM_RE = re.compile(rf"(?<!\d)(\d{{1,3}}(?:{_SEP}\d{{3}})+|\d+)(?:{_SEP}?\d{{2}})?(?!\d)")
    def _clean_amount_context(text: str) -> str:
        if not text: return ""
        t = text
        for w in _CURR_WORDS: t = re.sub(rf"\b{w}\b", " ", t, flags=re.IGNORECASE)
        t = t.replace("₺"," ").replace("€"," ").replace("\u00A0"," ").replace("\u202F"," ").replace("\u2009"," ")
        return t
    def _to_float_from_token(token: str) -> float | None:
        s = token.replace("\u00A0"," ").replace("\u202F"," ").replace("\u2009"," ").strip().replace(" ","")
        has_dot, has_com = "." in s, "," in s
        if has_dot and has_com:
            last = max(s.rfind("."), s.rfind(","))
            if (len(s) - last - 1) == 2:
                dec = s[last]; other = "," if dec=="." else "."
                s = s.replace(other, "").replace(dec, ".")
            else:
                s = s.replace(".","").replace(",","")
        else:
            if s.count(",")==1 and len(s.split(",")[-1])==2: s = s.replace(",", ".")
            else: s = s.replace(",", "")
            if not (s.count(".")==1 and len(s.split(".")[-1])==2): s = s.replace(".","")
        try: return float(s)
        except Exception: return None
    def extract_amount_float(text: str) -> float | None:
        t = _clean_amount_context(text)
        toks = _NUM_RE.findall(t)
        best = None
        for tok in toks:
            v = _to_float_from_token(tok)
            if v is None: continue
            if (best is None) or (v > best): best = v
        return best

    # ---------- OCR ----------
    def _ocr_remote_png(img_gray, *, psm: int, oem: int) -> str:
        ok, buf = cv2.imencode(".png", img_gray)
        if not ok: return ""
        payload = {"image": base64.b64encode(buf.tobytes()).decode("ascii"), "lang": lang, "config": f"--psm {int(psm)} --oem {int(oem)}"}
        try:
            r = requests.post(ocr_url, data=json.dumps(payload), headers={"Content-Type":"application/json"}, timeout=60)
            r.raise_for_status(); j = r.json()
            return (j.get("text") or "").strip()
        except Exception:
            return ""
    def ocr_box(lower_img, xywh: Tuple[int,int,int,int], psm: int, oem: int) -> str:
        x,y,w,h = xywh
        crop = lower_img[max(0,y):y+h, max(0,x):x+w]
        if crop is None or getattr(crop, "size", 0) == 0: return ""
        gray = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY) if crop.ndim==3 else crop
        gray = cv2.fastNlMeansDenoising(gray, None, 15, 7, 21)
        _, bw = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
        return _ocr_remote_png(bw, psm=psm, oem=oem)

    # ---------- boxes ----------
    final_xywh = [b for b in (_to_xywh(b) for b in final_boxes) if b is not None and b[2]>0 and b[3]>0]
    final_xyxy = [_to_xyxy(b) for b in final_xywh]
    sig_xyxy   = [_to_xyxy(b) for b in (sig_boxes or [])]
    role_xyxy  = [_to_xyxy(b) for b in (role_blocks or [])]
    serm_xyxy  = [_to_xyxy(b) for b in (sermaye_boxes or [])]
    known_pool = list(dict.fromkeys(known_names or []))

    def decide_psm_oem(loc: str) -> Tuple[int,int]:
        if loc == "sermaye": return 1, 1
        if loc == "roles":   return 11, 1
        return 11, 1

    # ---------- role-block seçimi ----------
    def _best_role_block_for(bxyxy: Tuple[int,int,int,int]) -> Optional[Tuple[int,int,int,int]]:
        if not role_xyxy: return None
        inside = [r for r in role_xyxy if _contains(bxyxy, r, pad=2)]
        if inside:
            inside.sort(key=_area, reverse=True)
            return inside[0]
        best, best_iou = None, 0.0
        for r in role_xyxy:
            i = _iou(bxyxy, r)
            if i > best_iou: best, best_iou = r, i
        return best if best_iou > 0 else None

    # ---------- SIRALI & ÇOKLU İSİM ----------
    def extract_names_multi_ordered(text: str, pool: list[str], thr: float = 0.82) -> List[str]:
        """
        - text: text_preview (rol kelimeleri henüz temizlenmemiş olabilir)
        - pool: known_names (kanonik adlar)
        - Dönen değer: soldan sağa sıralı, tekrarsız ad listesi
        """
        if not text:
            return []

        # 1) tokenize + pozisyon
        tokens = [(m.group(0), m.start(), m.end()) for m in re.finditer(r"[A-Za-zÇĞİÖŞÜçğıöşü’']+", text)]
        tokens = [(t,s,e) for (t,s,e) in tokens if _U(t) not in ROLE_TOKENS_U and len(t) >= 2]
        if not tokens:
            return []

        # 2) pencere üret (3 sonra 2 token)
        windows = []
        for L in (3, 2):
            for i in range(0, max(0, len(tokens)-L+1)):
                seg = tokens[i:i+L]
                wtxt = " ".join(t for (t,_,__) in seg)
                start, end = seg[0][1], seg[-1][2]
                # skor: order-preserving (ratio/partial_ratio), uzunluk bonusu
                s = 0.0
                if pool:
                    best = None
                    best_sc = 0.0
                    wN = _U(wtxt)
                    for kn in pool:
                        kN = _U(kn)
                        sc = max(
                            fuzz.ratio(wN, kN)/100.0,          # sıra koruyan
                            fuzz.partial_ratio(wN, kN)/100.0   # kısmi ama sıralı
                        )
                        if sc > best_sc:
                            best_sc = sc; best = kn
                    mapped = best if best_sc >= thr else None
                else:
                    mapped, best_sc = None, 0.0
                # sezgisel bonus
                if 6 <= len(wtxt) <= 40: best_sc += 0.10
                if L == 3: best_sc += 0.05
                windows.append((start, end, wtxt, mapped, best_sc, L))

        # 3) skorla sırala ve span-NMS uygula (sıra korunur, çakışma elenir)
        def span_iou(a, b):
            a1,a2 = a[0], a[1]; b1,b2 = b[0], b[1]
            inter = max(0, min(a2,b2)-max(a1,b1))
            union = (a2-a1) + (b2-b1) - inter + 1e-9
            return inter/union

        windows.sort(key=lambda x: (-x[4], x[0], -(x[5])))  # yüksek skor, daha erken, daha uzun
        selected = []
        for w in windows:
            if all(span_iou(w, s) < 0.35 for s in selected):
                selected.append(w)

        # 4) soldan sağa sırala ve isimleri derle (kanonik varsa onu kullan)
        selected.sort(key=lambda x: x[0])
        names = []
        seen = set()
        for (st, en, wtxt, mapped, sc, L) in selected:
            nm = mapped or wtxt
            nm_clean = " ".join([t for t in re.findall(r"[A-Za-zÇĞİÖŞÜçğıöşü’']+", nm) if _U(t) not in ROLE_TOKENS_U])[:200]
            if not nm_clean:
                continue
            # tekrarı engelle (sıra bozulmadan)
            if all(fuzz.token_set_ratio(nm_clean, ex) < 92 for ex in names):
                if nm_clean not in seen:
                    seen.add(nm_clean); names.append(nm_clean)

        return names

    # ---------- loop ----------
    rows = []
    for i, (b_wh, b_xyxy) in enumerate(zip(final_xywh, final_xyxy)):
        loc = "roles" if _any_overlap(b_xyxy, role_xyxy) else ("sermaye" if _any_overlap(b_xyxy, serm_xyxy) else "other")
        sig = any(_contains(b_xyxy, s, pad=2) or _iou(b_xyxy, s) >= 0.02 for s in sig_xyxy)
        psm0, oem0 = decide_psm_oem(loc)

        # final-box OCR
        text0 = ocr_box(lower_img, b_wh, psm=psm0, oem=oem0)

        # text_preview kaynağı
        if loc == "roles":
            rb_xyxy = _best_role_block_for(b_xyxy)
            if rb_xyxy is not None:
                rb_xywh = _xyxy_to_xywh(rb_xyxy)
                preview_src = ocr_box(lower_img, rb_xywh, psm=11, oem=1)
                text_preview = re.sub(r"\s+"," ", preview_src)[:600]
            else:
                text_preview = re.sub(r"\s+"," ", text0)[:600]
        else:
            text_preview = re.sub(r"\s+"," ", text0)[:600]

        # role_best (mevcut davranış)
        role_key, role_score = (None, 0.0)
        if loc == "roles":
            role_key, role_score = best_role_for_text(text0)

        # preview zayıfsa fallback
        if (not text_preview) or len(text_preview) < 6:
            text1 = ocr_box(lower_img, b_wh, psm=1, oem=1)
            if text1 and len(text1) > len(text_preview):
                if loc == "roles":
                    rk2, rs2 = best_role_for_text(text1)
                    role_key, role_score = rk2, rs2
                text_preview = re.sub(r"\s+"," ", text1)[:600]

        # name_in_box
        if loc == "sermaye":
            amount_val = extract_amount_float(text_preview)
            if amount_val is None:
                amount_val = extract_amount_float(text0)
                if amount_val is None:
                    text1 = ocr_box(lower_img, b_wh, psm=1, oem=1)
                    amount_val = extract_amount_float(text1)
            if amount_val is not None and float(amount_val).is_integer():
                amount_val = int(amount_val)
            name_in_box = amount_val
        else:
            tckn_p = find_tckn(text_preview)

            # Çoklu + sıralı isim çıkar
            multi_names = extract_names_multi_ordered(_tokens_no_roles(text_preview), known_pool, thr=name_sim_threshold)
            if not multi_names:
                # kenar durumları için sade fallback
                multi_names = [_clean_tokens(_tokens_no_roles(text_preview))] if _clean_tokens(_tokens_no_roles(text_preview)) else []

            raw_name = "; ".join([n for n in multi_names if n])

            # Yalnızca temizlik (yeniden eşleme YOK -> sıra bozulmasın)
            name_clean = sanitize_names_no_remap(raw_name, text_preview)

            name_in_box = merge_name_tckn(name_clean, tckn_p)

        rows.append({
            "i": i, "bbox": b_wh, "loc": loc, "sig": bool(sig),
            "role_best": role_key, "role_score": float(role_score),
            "name_in_box": name_in_box, "text_preview": text_preview
        })

    return pd.DataFrame(rows, columns=["i","bbox","loc","sig","role_best","role_score","name_in_box","text_preview"])