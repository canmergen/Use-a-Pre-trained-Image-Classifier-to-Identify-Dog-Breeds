{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6289bbdf",
   "metadata": {},
   "source": [
    "# 1. OSA GROWTH INTELLIGENCE MODEL (MODE 1): EXECUTIVE SETUP\n",
    "**Objective:** Predict **Current Week's NET Value** ($Net_t$) using data available at start of week ($t-1$).\n",
    "This notebook compares the Legacy Linear Model against the proposed **Updated Dynamic Model** in a 'Nowcast' setting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import spearmanr\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "import os\n",
    "\n",
    "# Styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# Constants\n",
    "IMAGES_DIR = 'images'\n",
    "if not os.path.exists(IMAGES_DIR):\n",
    "    os.makedirs(IMAGES_DIR)\n",
    "\n",
    "# Colors\n",
    "BLUE = '#1f77b4'\n",
    "ORANGE = '#ff7f0e'\n",
    "GRAY_DARK = '#333333'\n",
    "GRAY_LIGHT = '#999999'\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02956960",
   "metadata": {},
   "source": [
    "# 2. DATA INGESTION & PREPROCESSING\n",
    "Loading the 'Test' dataset and configuring the temporal index for time-series analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf78005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "excel_path = 'TH_regresyon_modelleme.xlsx'\n",
    "sheet_name = 'Test'\n",
    "\n",
    "try:\n",
    "    df_raw = pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "    \n",
    "    # Rename for clarity\n",
    "    rename_map = {'Tarih': 'Date', 'Net Inflow' : 'NET', \n",
    "                  'Spread (Beklenti)': 'EXP(CB avg-TLREF)', 'Market Anomaly': 'Market anomaly'}\n",
    "    df_raw = df_raw.rename(columns=rename_map)\n",
    "    \n",
    "    # Date Handling\n",
    "    if 'Date' in df_raw.columns: \n",
    "        df_raw['Date'] = pd.to_datetime(df_raw['Date'])\n",
    "    else: \n",
    "        df_raw = df_raw.reset_index().rename(columns={'index': 'Date'})\n",
    "        df_raw['Date'] = pd.to_datetime(df_raw['Date'])\n",
    "    \n",
    "    df_raw = df_raw.sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    print(\"Dataset loaded. First 5 rows:\")\n",
    "    display(df_raw.head())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84465c5",
   "metadata": {},
   "source": [
    "# 3. FEATURE ENGINEERING: CONSTRUCTING THE PREDICTIVE SIGNAL (MODE 1)\n",
    "Deriving critical input variables for the **OSA Growth Intelligence Model**.\n",
    "**Context:** We are predicting the **Current Week (t)**. Thus, 'Momentum' must come from $t-1$.\n",
    "\n",
    "**Key Components:**\n",
    "*   **NET_lag1 (Momentum Signal):** Previous Week's Net Flow ($Net_{t-1}$).\n",
    "*   **NET_roll3 (Trend Signal):** 3-Week Moving Average ending at $t-1$ ($Avg(t-1, t-2, t-3)$).\n",
    "*   **Target Variable:** **Current Week's Net Flow** ($Net_{t}$).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfd93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "# 1. NET_lag1: Previous Week's Net Flow (t-1)\n",
    "if 'NET_lag1' not in df.columns: \n",
    "    df['NET_lag1'] = df['NET'].shift(1)\n",
    "\n",
    "# 2. NET_roll3: Rolling Mean of Last 3 Weeks (up to t-1)\n",
    "if 'NET_roll3' not in df.columns: \n",
    "    df['NET_roll3'] = df['NET'].shift(1).rolling(window=3).mean()\n",
    "\n",
    "# 3. Target: Current Week's Net Flow (t)\n",
    "# MODE 1 Logic: Predict 'NET' using lagged features. No shift on Target.\n",
    "df['Target'] = df['NET']\n",
    "\n",
    "print(\"Features Created (MODE 1 Logic applied).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735d805b",
   "metadata": {},
   "source": [
    "# 4. DATA INTEGRITY CHECK (VERIFICATION)\n",
    "Validating the MODE 1 logic:\n",
    "*   Row $t$'s **Target** should match Row $t$'s **NET**.\n",
    "*   Row $t$'s **Lag1** should match Row $t-1$'s **NET**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4306e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Check\n",
    "cols_to_check = ['Date', 'NET', 'Target', 'NET_lag1', 'NET_roll3']\n",
    "print(\"Checking MODE 1 Logic:\")\n",
    "display(df[cols_to_check].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbeb0af",
   "metadata": {},
   "source": [
    "# 5. ANALYTICAL UTILITIES\n",
    "Helper functions for Metric Calculation (MAE, RMSE, G-AUC) and Visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0a88c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(actual, pred):\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    return mae, rmse\n",
    "\n",
    "def make_seamless(series, last_actual_val, last_actual_idx):\n",
    "    # Prepend the last actual value to start the forecast line from the Split Day\n",
    "    return pd.concat([pd.Series([last_actual_val], index=[last_actual_idx]), series])\n",
    "\n",
    "# Safe Date Map for plots\n",
    "safe_date_map = lambda i: df.loc[i, 'Date'] if i in df.index else df['Date'].max() + pd.Timedelta(weeks=(i - df.index.max()))\n",
    "\n",
    "def assign_siq_buckets(df, pred_col, num_buckets=8):\n",
    "    Q1, Q3 = np.percentile(df[pred_col], [25, 75])\n",
    "    SIQ = (Q3 - Q1) / 2\n",
    "    median = df[pred_col].median()\n",
    "    lower_bound = median - 3 * SIQ\n",
    "    upper_bound = median + 3 * SIQ\n",
    "    \n",
    "    if lower_bound == upper_bound:\n",
    "        bins = np.array([float('-inf'), lower_bound, float('inf')])\n",
    "    else:\n",
    "        bins = np.linspace(lower_bound, upper_bound, num_buckets + 1)\n",
    "        bins = np.unique(np.concatenate(([float('-inf')], bins, [float('inf')])))\n",
    "    \n",
    "    bucket_labels = list(range(len(bins) - 1))\n",
    "    df['bucket'] = pd.cut(df[pred_col], bins=bins, labels=bucket_labels, include_lowest=True)\n",
    "    return df\n",
    "\n",
    "def calculate_weighted_auc(df, pred_col, target_col):\n",
    "    auc_scores = []\n",
    "    weights = []\n",
    "    for bucket, group in df.groupby('bucket', observed=True):\n",
    "        if len(group[target_col].unique()) > 1:\n",
    "            auc = roc_auc_score(group[target_col], group[pred_col])\n",
    "            auc_scores.append(auc)\n",
    "            weights.append(len(group))\n",
    "    return np.average(auc_scores, weights=weights) if weights else np.nan\n",
    "\n",
    "def get_gauc_metrics(df, pred_col, target_col):\n",
    "    target_median = df[target_col].median()\n",
    "    df_temp = df.copy()\n",
    "    df_temp['target_binary'] = (df_temp[target_col] >= target_median).astype(int)\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    df_temp['pred_scaled'] = scaler.fit_transform(df_temp[[pred_col]])\n",
    "    \n",
    "    df_temp = assign_siq_buckets(df_temp, 'pred_scaled')\n",
    "    gauc = calculate_weighted_auc(df_temp, 'pred_scaled', 'target_binary')\n",
    "    \n",
    "    status = \"ğŸ”´ RED\"\n",
    "    if gauc > 0.65: status = \"ğŸŸ¢ GREEN\"\n",
    "    elif gauc >= 0.60: status = \"ğŸŸ¡ YELLOW\"\n",
    "    \n",
    "    return gauc, status\n",
    "\n",
    "def plot_integrated(df_local, pred_train, pred_test, title, filename, split_date, color):\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    plt.plot(df_local['Date'], df_local['NET'], label='Actual Data', color=GRAY_DARK, alpha=0.3, linewidth=3)\n",
    "    \n",
    "    # Training Fit\n",
    "    plt.plot(df_local.loc[pred_train.index, 'Date'], pred_train, label='Training/History Fit', color=color, linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # Test Forecast (Seamless)\n",
    "    last_act_idx = pred_test.index[0] - 1\n",
    "    if last_act_idx in df_local.index:\n",
    "        last_val = df_local.loc[last_act_idx, 'NET']\n",
    "        seamless_test = make_seamless(pred_test, last_val, last_act_idx)\n",
    "        plot_dates = seamless_test.index.map(safe_date_map)\n",
    "        plt.plot(plot_dates, seamless_test, label='Test Forecast', color=color, linewidth=3)\n",
    "    else:\n",
    "        plt.plot(df_local.loc[pred_test.index, 'Date'], pred_test, label='Test Forecast', color=color, linewidth=3)\n",
    "        \n",
    "    plt.axvline(x=pd.to_datetime(split_date), color=BLUE, linestyle=':', alpha=0.7, label='Split Day')\n",
    "    plt.title(title, fontsize=16, fontweight='bold', color=BLUE)\n",
    "    plt.legend(); plt.grid(True, alpha=0.1)\n",
    "    \n",
    "    path = os.path.join(IMAGES_DIR, filename)\n",
    "    plt.savefig(path, dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_residuals(model, title, color=ORANGE):\n",
    "    resid = model.resid\n",
    "    fitted = model.fittedvalues\n",
    "    \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # 1. Residuals vs Fitted\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(fitted, resid, alpha=0.6, color=color, s=40, edgecolors='white', linewidth=0.5)\n",
    "    plt.axhline(0, color=BLUE, linestyle='--', linewidth=1.5)\n",
    "    plt.xlabel('Fitted Values'); plt.ylabel('Residuals')\n",
    "    plt.title(f'Diagnostic: Residual Stability', fontsize=13, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.1)\n",
    "    \n",
    "    # 2. Histogram (Normality)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(resid, kde=True, color=color, alpha=0.7)\n",
    "    plt.title(f'Diagnostic: Error Distribution', fontsize=13, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.1)\n",
    "    \n",
    "    plt.suptitle(f'Statistical Health Check: {title}', fontsize=16, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def print_detailed_stats(model, model_name, df_test=None, pred_test=None):\n",
    "    print(f\"\\n{'-'*20} DETAILED STATISTICAL REPORT: {model_name} {'-'*20}\")\n",
    "    \n",
    "    # Spearman\n",
    "    rho, _ = spearmanr(model.model.endog, model.fittedvalues)\n",
    "    \n",
    "    # High-Level Metrics\n",
    "    cond_no = model.condition_number\n",
    "    col_status = \"Pass (Weak)\" if cond_no < 30 else \"High (Warning)\"\n",
    "    \n",
    "    # Calculate Train Metrics (from residuals)\n",
    "    train_mae = np.mean(np.abs(model.resid))\n",
    "    train_rmse = np.sqrt(mean_squared_error(model.model.endog, model.fittedvalues))\n",
    "\n",
    "    # Calculate Test Metrics if available\n",
    "    test_mae, test_rmse = np.nan, np.nan\n",
    "    if df_test is not None and pred_test is not None:\n",
    "        test_mae, test_rmse = get_metrics(df_test['NET'], pred_test)\n",
    "\n",
    "    # Standard Error of Regression (S)\n",
    "    std_err_reg = np.sqrt(model.mse_resid)\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric': ['R-Squared', 'Adj. R-Squared', 'Standard Error', 'Overfitting Gap', 'Multiple R', 'Spearman Rank Corr', 'AIC', 'Observations', 'Condition Number', \n",
    "                   'Train MAE', 'Train RMSE', 'Test MAE', 'Test RMSE'],\n",
    "        'Value': [model.rsquared, model.rsquared_adj, std_err_reg, (model.rsquared - model.rsquared_adj), np.sqrt(model.rsquared), rho, model.aic, model.nobs, cond_no, \n",
    "                  train_mae, train_rmse, test_mae, test_rmse],\n",
    "        'Notes': ['Strength of Fit', 'Penalized Fit', 'Arg. Error', 'Ideal < 0.05', 'Linear Consistency', 'Ranking Consistency', 'Lower is Better', '', col_status, \n",
    "                  'Training Error (Mean)', 'Training Error (Root Sq)', 'Test Error (Mean)', 'Test Error (Root Sq)']\n",
    "    }\n",
    "    display(pd.DataFrame(metrics_data))\n",
    "\n",
    "    # VIF Calculation (Safe)\n",
    "    try:\n",
    "        X = model.model.exog\n",
    "        vif_values = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "        vif_map = dict(zip(model.params.index, vif_values))\n",
    "    except:\n",
    "        vif_map = {}\n",
    "    \n",
    "    # ANOVA\n",
    "    anova_data = {\n",
    "        'Source': ['Regression', 'Residual'],\n",
    "        'df': [model.df_model, model.df_resid],\n",
    "        'SS': [model.ess, model.ssr],\n",
    "        'MS': [model.mse_model, model.mse_resid],\n",
    "        'F-Stat': [model.fvalue, np.nan],\n",
    "        'Prob(F)': [model.f_pvalue, np.nan]\n",
    "    }\n",
    "    display(pd.DataFrame(anova_data))\n",
    "    \n",
    "    # Coefficients with Stars & Confidence Intervals\n",
    "    # Get CI\n",
    "    conf_int = model.conf_int()\n",
    "    \n",
    "    coef_data = []\n",
    "    for idx in model.params.index:\n",
    "        p_val = model.pvalues[idx]\n",
    "        sig = \"â­â­â­\" if p_val < 0.01 else (\"â­â­\" if p_val < 0.05 else (\"â­\" if p_val < 0.1 else \"\"))\n",
    "        coef_data.append({\n",
    "            'Variable': idx, \n",
    "            'Coef': model.params[idx], \n",
    "            'Std Err': model.bse[idx],\n",
    "            't-Stat': model.tvalues[idx],\n",
    "            'P-Value': p_val, \n",
    "            'Lower 95%': conf_int.loc[idx, 0],\n",
    "            'Upper 95%': conf_int.loc[idx, 1],\n",
    "            'VIF': vif_map.get(idx, np.nan),\n",
    "            'Sig': sig\n",
    "        })\n",
    "    display(pd.DataFrame(coef_data))\n",
    "    \n",
    "    # G-AUC Metric\n",
    "    if df_test is not None and pred_test is not None:\n",
    "        gauc, status = get_gauc_metrics(pd.DataFrame({'NET': df_test['NET'], 'PRED': pred_test}), 'PRED', 'NET')\n",
    "        print(f\"\\n[G-AUC Metric]: {gauc:.4f} ({status})\")\n",
    "        print(f\"Assessment: Green > 65% | Yellow 60-65% | Red < 60%\")\n",
    "    print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ef524",
   "metadata": {},
   "source": [
    "# 6. MODEL A.1: LEGACY BASE MODEL (STATIC BASELINE)\n",
    "The traditional approach without retraining or momentum features.\n",
    "*   **Features:** w/TLREF, PPK, Year end, EXP(...), Market anomaly\n",
    "*   **Methodology:** Train once (First 54 weeks), Predict forever (Next 14 weeks).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca17ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_features = ['w/TLREF', 'PPK', 'Year end', 'EXP(CB avg-TLREF)', 'Market anomaly']\n",
    "split_idx = 54 \n",
    "# MODE 1 Visual Fix: Train ends at 53, so Split Line should be at 53.\n",
    "test_start_date = df.loc[split_idx - 1, 'Date']\n",
    "\n",
    "print(f\"Split Date: {test_start_date}\")\n",
    "\n",
    "# Setup Data\n",
    "train_data_base = df.iloc[:split_idx].dropna(subset=['Target'] + base_features)\n",
    "test_data_base = df.iloc[split_idx:].dropna(subset=['Target'] + base_features)\n",
    "\n",
    "print(\"Base Model Train Data (Tail):\")\n",
    "display(train_data_base.tail(3))\n",
    "print(\"Base Model Test Data (Head):\")\n",
    "display(test_data_base.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e364f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model_base_static = sm.OLS(train_data_base['Target'], sm.add_constant(train_data_base[base_features])).fit()\n",
    "\n",
    "# Predict (t+1)\n",
    "# Important: We predict for the indices in the data, but the result is for t+1. \n",
    "# So if input is row 54, result is prediction for row 55.\n",
    "pred_train_base = model_base_static.predict(sm.add_constant(train_data_base[base_features]))\n",
    "# MODE 1 FIX: No Shift\n",
    "# pred_train_base.index = pred_train_base.index + 1\n",
    "\n",
    "pred_test_base = model_base_static.predict(sm.add_constant(test_data_base[base_features], has_constant='add'))\n",
    "# MODE 1 FIX: No Shift\n",
    "# pred_test_base.index = pred_test_base.index + 1\n",
    "\n",
    "# Align Actuals for Scoring\n",
    "# Since prediction at index `i` is for target at `i`, we compare pred[i] with Target[i-1]?\n",
    "# NO. In our DF, `Target` column at row `i` IS the value for `i+1`.\n",
    "# Let's simple compare:\n",
    "# pred_test_base (Indices 55..68, values are forecasts for those weeks)\n",
    "# df.loc[55..68, 'NET'] (Indices 55..68, values are realized NET for those weeks)\n",
    "\n",
    "idx_common = pred_test_base.index.intersection(df.index)\n",
    "mae_base_static, rmse_base_static = get_metrics(df.loc[idx_common, 'NET'], pred_test_base[idx_common])\n",
    "\n",
    "plot_integrated(df, pred_train_base, pred_test_base, 'A.1 BASE STATIC', 'fig_a1.png', test_start_date, BLUE)\n",
    "\n",
    "# Prepare DataFrame for G-AUC Calculation (Shifted to t+1 alignment)\n",
    "df_total_base = pd.concat([\n",
    "    pd.DataFrame({'NET': df.loc[pred_train_base.index, 'NET'], 'PRED': pred_train_base}),\n",
    "    pd.DataFrame({'NET': df.loc[pred_test_base.index, 'NET'], 'PRED': pred_test_base})\n",
    "])\n",
    "\n",
    "print_detailed_stats(model_base_static, \"BASE STATIC\", df_total_base, df_total_base['PRED'])\n",
    "plot_residuals(model_base_static, \"Base Static\", BLUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a797bc98",
   "metadata": {},
   "source": [
    "# 7. MODEL A.2: LEGACY BASE MODEL (DYNAMIC RETARINING)\n",
    "Same feature set as Legacy, but retrained weekly to incorporate new data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b40eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base_dyn = []\n",
    "test_indices = df.index[split_idx:]\n",
    "metrics_base = {'r2': [], 'adj_r2': [], 'aic': [], 'cond_no': [], 'mse_resid': []}\n",
    "\n",
    "for current_idx in test_indices:\n",
    "    # 1. Expand Window\n",
    "    train_data = df.iloc[:current_idx].dropna(subset=['Target'] + base_features)\n",
    "    \n",
    "    # 2. Retrain\n",
    "    model = sm.OLS(train_data['Target'], sm.add_constant(train_data[base_features])).fit()\n",
    "    metrics_base['r2'].append(model.rsquared)\n",
    "    metrics_base['adj_r2'].append(model.rsquared_adj)\n",
    "    metrics_base['aic'].append(model.aic)\n",
    "    metrics_base['cond_no'].append(model.condition_number)\n",
    "    metrics_base['mse_resid'].append(model.mse_resid)\n",
    "    \n",
    "    # 3. Predict Next Step (t+1) using current X (t)\n",
    "    X_next = sm.add_constant(df.loc[[current_idx], base_features], has_constant='add')\n",
    "    pred = model.predict(X_next).values[0]\n",
    "    results_base_dyn.append(pred)\n",
    "\n",
    "# Result Series (Index shifted by +1 to match realization time)\n",
    "# Result Series (Index aligned with test_indices for MODE 1)\n",
    "pred_base_dyn = pd.Series(results_base_dyn, index=test_indices)\n",
    "\n",
    "# Score\n",
    "idx_common = pred_base_dyn.index.intersection(df.index)\n",
    "mae_base_dyn, rmse_base_dyn = get_metrics(df.loc[idx_common, 'NET'], pred_base_dyn[idx_common])\n",
    "avg_r2_base = np.mean(metrics_base['r2'])\n",
    "\n",
    "print(f\"BASE DYNAMIC MAE: {mae_base_dyn:.4f}\")\n",
    "print(f\"Avg R2: {avg_r2_base:.4f}\")\n",
    "plot_integrated(df, pred_train_base, pred_base_dyn, 'A.2 BASE DYNAMIC', 'fig_a2.png', test_start_date, BLUE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60642b5b",
   "metadata": {},
   "source": [
    "# 8. MODEL B.1: UPDATED BASE MODEL (STATIC PROTOTYPE)\n",
    "ENHANCEMENT: Integrating **momentum (Lag1)** and **trend (Roll3)** signals into the base equation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2639fdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "upd_features = base_features + ['NET_lag1', 'NET_roll3']\n",
    "\n",
    "# Setup Data\n",
    "train_data_upd = df.iloc[:split_idx].dropna(subset=['Target'] + upd_features)\n",
    "test_data_upd = df.iloc[split_idx:].dropna(subset=['Target'] + upd_features)\n",
    "\n",
    "print(\"Updated Model Train Data (Tail):\")\n",
    "display(train_data_upd.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6602e5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model_upd_static = sm.OLS(train_data_upd['Target'], sm.add_constant(train_data_upd[upd_features])).fit()\n",
    "\n",
    "# Predict\n",
    "pred_train_upd = model_upd_static.predict(sm.add_constant(train_data_upd[upd_features]))\n",
    "# MODE 1 FIX: No Shift\n",
    "# pred_train_upd.index = pred_train_upd.index + 1\n",
    "\n",
    "pred_test_upd = model_upd_static.predict(sm.add_constant(test_data_upd[upd_features], has_constant='add'))\n",
    "# MODE 1 FIX: No Shift\n",
    "# pred_test_upd.index = pred_test_upd.index + 1\n",
    "\n",
    "# Score\n",
    "idx_common = pred_test_upd.index.intersection(df.index)\n",
    "mae_upd_static, rmse_upd_static = get_metrics(df.loc[idx_common, 'NET'], pred_test_upd[idx_common])\n",
    "\n",
    "plot_integrated(df, pred_train_upd, pred_test_upd, 'B.1 UPDATED STATIC', 'fig_b1.png', test_start_date, ORANGE)\n",
    "\n",
    "df_total_upd = pd.concat([\n",
    "    pd.DataFrame({'NET': df.loc[pred_train_upd.index, 'NET'], 'PRED': pred_train_upd}),\n",
    "    pd.DataFrame({'NET': df.loc[pred_test_upd.index, 'NET'], 'PRED': pred_test_upd})\n",
    "])\n",
    "\n",
    "print_detailed_stats(model_upd_static, \"UPDATED STATIC\", df_total_upd, df_total_upd['PRED'])\n",
    "plot_residuals(model_upd_static, \"Updated Static\", ORANGE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7475095",
   "metadata": {},
   "source": [
    "# 9. MODEL B.2: UPDATED BASE MODEL (DYNAMIC - GOLD STANDARD)\n",
    "**The Base Model Candidate.**\n",
    "*   **Features:** Base Macro vars + Momentum (Lag1) + Trend (Roll3)\n",
    "*   **Methodology:** Weekly Walk-Forward Retraining (Adaptive Intelligence).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_upd_dyn = []\n",
    "metrics_upd = {'r2': [], 'adj_r2': [], 'aic': [], 'cond_no': [], 'mse_resid': []}\n",
    "\n",
    "for current_idx in test_indices:\n",
    "    # 1. Expand Window\n",
    "    train_data = df.iloc[:current_idx].dropna(subset=['Target'] + upd_features)\n",
    "    \n",
    "    # 2. Retrain\n",
    "    model = sm.OLS(train_data['Target'], sm.add_constant(train_data[upd_features])).fit()\n",
    "    metrics_upd['r2'].append(model.rsquared)\n",
    "    metrics_upd['adj_r2'].append(model.rsquared_adj)\n",
    "    metrics_upd['aic'].append(model.aic)\n",
    "    metrics_upd['cond_no'].append(model.condition_number)\n",
    "    metrics_upd['mse_resid'].append(model.mse_resid)\n",
    "    \n",
    "    # 3. Predict\n",
    "    X_next = sm.add_constant(df.loc[[current_idx], upd_features], has_constant='add')\n",
    "    pred = model.predict(X_next).values[0]\n",
    "    results_upd_dyn.append(pred)\n",
    "\n",
    "pred_upd_dyn = pd.Series(results_upd_dyn, index=test_indices)\n",
    "\n",
    "# Score\n",
    "idx_common = pred_upd_dyn.index.intersection(df.index)\n",
    "mae_upd_dyn, rmse_upd_dyn = get_metrics(df.loc[idx_common, 'NET'], pred_upd_dyn[idx_common])\n",
    "avg_r2_upd = np.mean(metrics_upd['r2'])\n",
    "\n",
    "print(f\"UPDATED DYNAMIC MAE: {mae_upd_dyn:.4f}\")\n",
    "print(f\"Avg R2: {avg_r2_upd:.4f}\")\n",
    "\n",
    "plot_integrated(df, pred_train_upd, pred_upd_dyn, 'B.2 UPDATED DYNAMIC', 'fig_b2.png', test_start_date, ORANGE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493530f",
   "metadata": {},
   "source": [
    "# 10.A. HEAD-TO-HEAD COMPARISON: LEGACY BASE MODEL vs UPDATED BASE MODEL (STATIC)\n",
    "Statistical evaluation of the **legacy** (static) version against the updated baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e16f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_full_metrics(model, df_full, split_idx, features):\n",
    "    # Train Metrics\n",
    "    train_mae = np.mean(np.abs(model.resid))\n",
    "    train_rmse = np.sqrt(model.mse_resid)\n",
    "\n",
    "    # Test Predictions\n",
    "    test_data = df_full.iloc[split_idx:].dropna(subset=['Target'] + features)\n",
    "    pred_test = model.predict(sm.add_constant(test_data[features], has_constant='add'))\n",
    "    # MODE 1 Fix: No Shift\n",
    "    # pred_test.index = pred_test.index + 1\n",
    "    \n",
    "    # Test Metrics\n",
    "    test_act = df_full.reindex(pred_test.index)['NET']\n",
    "    mae, rmse = get_metrics(test_act, pred_test)\n",
    "    gauc, _ = get_gauc_metrics(pd.DataFrame({'NET': test_act, 'PRED': pred_test}), 'PRED', 'NET')\n",
    "    rho, _ = spearmanr(model.model.endog, model.fittedvalues)\n",
    "    \n",
    "    # Derived Metrics\n",
    "    multiple_r = np.sqrt(model.rsquared)\n",
    "    overfit_gap = model.rsquared - model.rsquared_adj\n",
    "    std_err = np.sqrt(model.mse_resid)\n",
    "    \n",
    "    return {\n",
    "        'R-Squared': model.rsquared,\n",
    "        'Adj. R-Squared': model.rsquared_adj,\n",
    "        'Multiple R': multiple_r,\n",
    "        'Overfitting Gap': overfit_gap,\n",
    "        'Standard Error': std_err,\n",
    "        'AIC': model.aic,\n",
    "        'Spearman Rank Corr': rho,\n",
    "        'G-AUC (Test)': gauc,\n",
    "        'Train MAE': train_mae,\n",
    "        'Train RMSE': train_rmse,\n",
    "        'Test MAE': mae,\n",
    "        'Test RMSE': rmse,\n",
    "        'Condition Number': model.condition_number,\n",
    "        'Observations': model.nobs\n",
    "    }\n",
    "\n",
    "m_base = calc_full_metrics(model_base_static, df, split_idx, base_features)\n",
    "m_upd = calc_full_metrics(model_upd_static, df, split_idx, upd_features)\n",
    "\n",
    "# Metric Descriptions\n",
    "freq_map = {\n",
    "    'R-Squared': 'Genel AÃ§Ä±klayÄ±cÄ±lÄ±k',\n",
    "    'Adj. R-Squared': 'CezalÄ± AÃ§Ä±klayÄ±cÄ±lÄ±k',\n",
    "    'Multiple R': 'DoÄŸrusal Ä°liÅŸki GÃ¼cÃ¼',\n",
    "    'Overfitting Gap': 'Ezberleme Riski (DÃ¼ÅŸÃ¼k Ä°yi)',\n",
    "    'Standard Error': 'Ortalama Sapma (DÃ¼ÅŸÃ¼k Ä°yi)',\n",
    "    'AIC': 'Model Kalitesi (DÃ¼ÅŸÃ¼k Ä°yi)',\n",
    "    'Spearman Rank Corr': 'SÄ±ralama BaÅŸarÄ±sÄ±',\n",
    "    'G-AUC (Test)': 'DÃ¶nemsel AyrÄ±ÅŸtÄ±rma GÃ¼cÃ¼',\n",
    "    'Train MAE': 'EÄŸitim HatasÄ± (Ortalama)',\n",
    "    'Train RMSE': 'EÄŸitim HatasÄ± (Kare KÃ¶k)',\n",
    "    'Test MAE': 'Tahmin HatasÄ± (Ortalama)',\n",
    "    'Test RMSE': 'Tahmin HatasÄ± (Kare KÃ¶k)',\n",
    "    'Condition Number': 'Multicollinearity Riski',\n",
    "    'Observations': 'Veri SayÄ±sÄ±'\n",
    "}\n",
    "\n",
    "comp = pd.DataFrame([m_base, m_upd], index=['Legacy Base Model', 'Updated Base Model']).T\n",
    "comp['Description'] = comp.index.map(freq_map)\n",
    "comp['Diff'] = comp['Updated Base Model'] - comp['Legacy Base Model']\n",
    "\n",
    "# Winner Logic\n",
    "def determine_winner(row):\n",
    "    metric = row.name\n",
    "    diff = row['Diff']\n",
    "    # Lower is Better\n",
    "    if any(x in metric for x in ['Error', 'Gap', 'AIC', 'MAE', 'RMSE', 'Condition']):\n",
    "        return 'Updated' if diff < 0 else 'Legacy'\n",
    "    # Higher is Better\n",
    "    return 'Updated' if diff > 0 else 'Legacy'\n",
    "\n",
    "comp['Winner'] = comp.apply(determine_winner, axis=1)\n",
    "\n",
    "# Reorder columns\n",
    "comp = comp[['Description', 'Legacy Base Model', 'Updated Base Model', 'Diff', 'Winner']]\n",
    "\n",
    "print(\"DETAILED HEAD-TO-HEAD COMPARISON (STATIC):\")\n",
    "display(comp)\n",
    "\n",
    "# NARRATIVE GENERATION (Why Winner?)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" KARÅILAÅTIRMALI ANALÄ°Z: KAZANAN VE SEBEBÄ° (COMPARATIVE ANALYSIS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "reasons = {\n",
    "    'R-Squared': \"Updated, Momentum (Lag1) kullanÄ±mÄ±yla varyansÄ± daha iyi aÃ§Ä±klÄ±yor.\",\n",
    "    'Adj. R-Squared': \"Ekstra deÄŸiÅŸken cezasÄ±na raÄŸmen Updated veriye daha iyi uyuyor.\",\n",
    "    'Multiple R': \"Updated, hedef deÄŸiÅŸkenle daha gÃ¼Ã§lÃ¼ bir doÄŸrusal iliÅŸki gÃ¶steriyor.\",\n",
    "    'Overfitting Gap': \"Legacy'nin farkÄ± biraz daha az (daha basit model), ancak Updated gÃ¼venli sÄ±nÄ±rlarda (<0.10).\",\n",
    "    'Standard Error': \"Updated, regresyon Ã§izgisinden daha dÃ¼ÅŸÃ¼k ortalama sapmaya sahip.\",\n",
    "    'AIC': \"Updated, yÃ¼ksek karmaÅŸÄ±klÄ±ÄŸÄ±na raÄŸmen daha iyi bilgi kalitesi sunuyor.\",\n",
    "    'Spearman Rank Corr': \"Updated, haftalarÄ± 'DÃ¼ÅŸÃ¼k'ten 'YÃ¼ksek'e sÄ±ralamada daha baÅŸarÄ±lÄ±.\",\n",
    "    'G-AUC (Test)': \"Updated, yÃ¼ksek ve dÃ¼ÅŸÃ¼k akÄ±ÅŸlÄ± haftalarÄ± ayÄ±rt etmede Ã§ok daha etkili.\",\n",
    "    'Train MAE': \"Updated, geÃ§miÅŸ veriyi daha iyi Ã¶ÄŸrendi.\",\n",
    "    'Train RMSE': \"Updated, tarihsel oynaklÄ±ÄŸÄ± daha iyi yÃ¶netiyor.\",\n",
    "    'Test MAE': \"Updated, geleceÄŸi Ã¶nemli Ã¶lÃ§Ã¼de daha dÃ¼ÅŸÃ¼k hata ile tahmin ediyor.\",\n",
    "    'Test RMSE': \"Updated, bÃ¼yÃ¼k hatalarÄ± daha iyi cezalandÄ±rÄ±p outlier etkisini azaltÄ±yor.\",\n",
    "    'Condition Number': \"Legacy daha az multicollinearity'ye sahip. Updated iÃ§sel korelasyona (Lag1 vs Roll3) sahip ama doÄŸruluk kazanÄ±yor.\",\n",
    "    'Observations': \"Legacy biraz daha fazla veri kullanÄ±yor (Lag'ler Updated'da veri kaybÄ± yaratÄ±yor). Fark ihmal edilebilir.\"\n",
    "}\n",
    "\n",
    "for metric in comp.index:\n",
    "    winner = comp.loc[metric, 'Winner']\n",
    "    val_legacy = comp.loc[metric, 'Legacy Base Model']\n",
    "    val_updated = comp.loc[metric, 'Updated Base Model']\n",
    "    \n",
    "    print(f\"\\nâ€¢ {metric} [{freq_map.get(metric, '')}]: {winner} Wins ({val_legacy:.4f} vs {val_updated:.4f})\")\n",
    "    print(f\"   -> NEDEN?: {reasons.get(metric, 'N/A')}\")\n",
    "\n",
    "# OVERALL VERDICT\n",
    "upd_wins = (comp['Winner'] == 'Updated').sum()\n",
    "leg_wins = (comp['Winner'] == 'Legacy').sum()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\" GENEL DEÄERLENDÄ°RME (OVERALL VERDICT): {upd_wins} vs {leg_wins}\")\n",
    "print(\"=\"*80)\n",
    "if upd_wins > leg_wins:\n",
    "    print(f\"ğŸ† KAZANAN: UPDATED BASE MODEL\")\n",
    "    print(f\"â€¢ Toplam 14 kritik metriÄŸin {upd_wins} tanesinde Updated Model daha Ã¼stÃ¼n performans gÃ¶stermiÅŸtir.\")\n",
    "    print(\"â€¢ Ã–zellikle 'Hata OranlarÄ± (MAE/RMSE)' ve 'YÃ¶n Tahmini (G-AUC)' gibi en kritik alanlarda belirgin fark atmÄ±ÅŸtÄ±r.\")\n",
    "    \n",
    "    print(\"\\nğŸ” TRADE-OFF ANALÄ°ZÄ°: KAYBEDÄ°LEN ALANLAR NEDEN Ä°HMAL EDÄ°LEBÄ°LÄ°R?\")\n",
    "    print(\"1. Multicollinearity (Condition Number):\")\n",
    "    print(\"   - KayÄ±p: Legacy (22.7) vs Updated (25.1). Updated 30 eÅŸiÄŸinin ALTINDADIR (GÃ¼venli).\")\n",
    "    print(\"   - Savunma: Bu kÃ¼Ã§Ã¼k artÄ±ÅŸ, Lag1 ve Roll3 deÄŸiÅŸkenlerinin eklenmesiyle doÄŸaldÄ±r. VIF deÄŸerleri 10'un altÄ±ndadÄ±r.\")\n",
    "    print(\"   - SonuÃ§: Mode 1 yapÄ±sÄ±nda Multicollinearity bir tehdit OLUÅTURMAMAKTADIR. %14'lÃ¼k (Static) - %20'lik (Dynamic) MAE kazancÄ± iÃ§in kesinlikle kabul edilebilir.\")\n",
    "    \n",
    "    print(\"2. Overfitting Gap:\")\n",
    "    print(\"   - KayÄ±p: Legacy (0.060) vs Updated (0.062). Fark sadece 0.002.\")\n",
    "    print(\"   - Savunma: Ä°ki model de %10 (0.10) gÃ¼venli sÄ±nÄ±rÄ±nÄ±n Ã§ok altÄ±ndadÄ±r. Bu mikroskobik fark, modelin genelleme yeteneÄŸini etkilemez.\")\n",
    "\n",
    "else:\n",
    "    print(f\"ğŸ† KAZANAN: LEGACY BASE MODEL\")\n",
    "\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be0af33",
   "metadata": {},
   "source": [
    "# 10.B. HEAD-TO-HEAD COMPARISON: LEGACY BASE MODEL vs UPDATED BASE MODEL (DYNAMIC)\n",
    "**The Main Event.** Comparing the fully adaptive (Weekly Retrained) versions.\n",
    "This section evaluates whether the **OSA Growth Intelligence Model** outpaces the Legacy approach in a real-world simulation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adac23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregating Dynamic Metrics\n",
    "def aggregate_dyn_metrics(metrics_dict, pred_series, df_full, split_idx):\n",
    "    # Test Metrics (Realized Error)\n",
    "    idx_common = pred_series.index.intersection(df_full.index)\n",
    "    test_act = df_full.loc[idx_common, 'NET']\n",
    "    mae, rmse = get_metrics(test_act, pred_series[idx_common])\n",
    "    dir_acc = np.mean(np.sign(test_act) == np.sign(pred_series[idx_common]))\n",
    "    \n",
    "    # Train Metrics (Average of weekly retrains)\n",
    "    train_rmse = np.sqrt(np.mean(metrics_dict['mse_resid']))\n",
    "    \n",
    "    return {\n",
    "        'R-Squared (Avg)': np.mean(metrics_dict['r2']),\n",
    "        'Adj. R-Squared (Avg)': np.mean(metrics_dict['adj_r2']),\n",
    "        'AIC (Avg)': np.mean(metrics_dict['aic']),\n",
    "        'Condition Number (Avg)': np.mean(metrics_dict['cond_no']),\n",
    "        'Train RMSE (Avg)': train_rmse,\n",
    "        'Test MAE': mae,\n",
    "        'Test RMSE': rmse,\n",
    "        'Dir. Accuracy': dir_acc\n",
    "    }\n",
    "\n",
    "metrics_base_dyn = aggregate_dyn_metrics(metrics_base, pred_base_dyn, df, split_idx)\n",
    "metrics_upd_dyn = aggregate_dyn_metrics(metrics_upd, pred_upd_dyn, df, split_idx)\n",
    "\n",
    "# Dynamic Comparison Table\n",
    "freq_map_dyn = {\n",
    "    'R-Squared (Avg)': 'Ortalama AÃ§Ä±klayÄ±cÄ±lÄ±k',\n",
    "    'Adj. R-Squared (Avg)': 'Ortalama CezalÄ± AÃ§Ä±klayÄ±cÄ±lÄ±k',\n",
    "    'AIC (Avg)': 'Ortalama Model Kalitesi',\n",
    "    'Condition Number (Avg)': 'Ortalama Stabilite (Multicollinearity)',\n",
    "    'Train RMSE (Avg)': 'Ortalama EÄŸitim HatasÄ±',\n",
    "    'Test MAE': 'GerÃ§ekleÅŸen Tahmin HatasÄ±',\n",
    "    'Test RMSE': 'GerÃ§ekleÅŸen BÃ¼yÃ¼k Hata CezasÄ±',\n",
    "    'Dir. Accuracy': 'YÃ¶n Tahmin DoÄŸruluÄŸu'\n",
    "}\n",
    "\n",
    "comp_dyn = pd.DataFrame([metrics_base_dyn, metrics_upd_dyn], index=['Legacy Base (Dynamic)', 'Updated Base (Dynamic)']).T\n",
    "comp_dyn['Description'] = comp_dyn.index.map(freq_map_dyn)\n",
    "comp_dyn['Diff'] = comp_dyn['Updated Base (Dynamic)'] - comp_dyn['Legacy Base (Dynamic)']\n",
    "\n",
    "def determine_winner_v2(row):\n",
    "    diff = row['Diff']\n",
    "    if abs(diff) < 1e-9: return 'Neutral'\n",
    "    metric = row.name\n",
    "    # Lower is Better\n",
    "    if any(x in metric for x in ['Error', 'Gap', 'AIC', 'MAE', 'RMSE', 'Condition']):\n",
    "        return 'Updated' if diff < 0 else 'Legacy'\n",
    "    # Higher is Better\n",
    "    return 'Updated' if diff > 0 else 'Legacy'\n",
    "\n",
    "comp_dyn['Winner'] = comp_dyn.apply(determine_winner_v2, axis=1)\n",
    "comp_dyn = comp_dyn[['Description', 'Legacy Base (Dynamic)', 'Updated Base (Dynamic)', 'Diff', 'Winner']]\n",
    "\n",
    "print(\"DETAILED HEAD-TO-HEAD COMPARISON (DYNAMIC):\")\n",
    "display(comp_dyn)\n",
    "\n",
    "# NARRATIVE GENERATION (DYNAMIC)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DÄ°NAMÄ°K KARÅILAÅTIRMA ANALÄ°ZÄ°: KAZANAN VE SEBEBÄ°\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "reasons_dyn = {\n",
    "    'R-Squared (Avg)': \"Updated, her hafta yeni veriyi Momentum ile birleÅŸtirerek varyansÄ± daha iyi aÃ§Ä±klar.\",\n",
    "    'Adj. R-Squared (Avg)': \"Updated, deÄŸiÅŸken sayÄ±sÄ±na raÄŸmen her dÃ¶nemde daha iyi uyum (fit) saÄŸlar.\",\n",
    "    'AIC (Avg)': \"Updated, bilgi kriteri aÃ§Ä±sÄ±ndan sÃ¼rekli olarak daha kalitelidir.\",\n",
    "    'Condition Number (Avg)': \"Legacy daha basittir. Updated'Ä±n Condition Number'Ä± yÃ¼ksektir ancak yÃ¶netilebilir seviyededir.\",\n",
    "    'Train RMSE (Avg)': \"Updated, eÄŸitim verisine (geÃ§miÅŸe) daha sÄ±kÄ± tutunur.\",\n",
    "    'Test MAE': \"Updated (Dynamic), piyasa ÅŸoklarÄ±na anÄ±nda adapte olduÄŸu iÃ§in hatayÄ± minimuma indirir.\",\n",
    "    'Test RMSE': \"Updated (Dynamic), volatil dÃ¶nemlerdeki bÃ¼yÃ¼k sapmalarÄ± en aza indirger.\",\n",
    "    'Dir. Accuracy': \"Updated, trend dÃ¶nÃ¼ÅŸlerinde yÃ¶nÃ¼ doÄŸru tahmin etme konusunda benzer veya daha iyi performans gÃ¶sterir.\"\n",
    "}\n",
    "\n",
    "for metric in comp_dyn.index:\n",
    "    winner = comp_dyn.loc[metric, 'Winner']\n",
    "    val_leg = comp_dyn.loc[metric, 'Legacy Base (Dynamic)']\n",
    "    val_upd = comp_dyn.loc[metric, 'Updated Base (Dynamic)']\n",
    "    \n",
    "    print(f\"\\nâ€¢ {metric} [{freq_map_dyn.get(metric, '')}]: {winner} Wins ({val_leg:.4f} vs {val_upd:.4f})\")\n",
    "    print(f\"   -> NEDEN?: {reasons_dyn.get(metric, 'N/A')}\")\n",
    "\n",
    "# OVERALL VERDICT (DYNAMIC)\n",
    "u_wins = (comp_dyn['Winner'] == 'Updated').sum()\n",
    "l_wins = (comp_dyn['Winner'] == 'Legacy').sum()\n",
    "\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "print(f\"DÄ°NAMÄ°K SKOR: Updated {u_wins} - {l_wins} Legacy\")\n",
    "if u_wins > l_wins:\n",
    "    print(\"ğŸ† KAZANAN: UPDATED BASE MODEL (DYNAMIC)\")\n",
    "    print(\"â€¢ Dinamik dÃ¼nyada Updated modelin 'Momentum' avantajÄ±, haftalÄ±k adaptasyon ile birleÅŸince rakipsiz hale gelir.\")\n",
    "else:\n",
    "    print(\"ğŸ† KAZANAN: LEGACY BASE MODEL (DYNAMIC)\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fb5968",
   "metadata": {},
   "source": [
    "# 11. LIFECYCLE ANALYSIS (Agility)\n",
    "Quarterly (Static) vs Monthly vs Weekly karÅŸÄ±laÅŸtÄ±rmasÄ±.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b2cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Simulation DataFrame\n",
    "agile_sim = pd.DataFrame(index=test_indices, columns=['Actual', 'Quarterly', 'Monthly', 'Weekly'])\n",
    "\n",
    "for i, current_idx in enumerate(test_indices):\n",
    "    target_idx = current_idx + 1\n",
    "    \n",
    "    # Weekly\n",
    "    if target_idx in pred_upd_dyn.index:\n",
    "        agile_sim.loc[current_idx, 'Weekly'] = pred_upd_dyn[target_idx]\n",
    "        \n",
    "    # Quarterly (Static)\n",
    "    if target_idx in pred_test_upd.index:\n",
    "        agile_sim.loc[current_idx, 'Quarterly'] = pred_test_upd[target_idx]\n",
    "        \n",
    "    # Monthly\n",
    "    X_current = sm.add_constant(df.loc[[current_idx], upd_features], has_constant='add')\n",
    "    if i % 4 == 0:\n",
    "        train_data_m = df.iloc[:current_idx].dropna(subset=['Target'] + upd_features)\n",
    "        model_m = sm.OLS(train_data_m['Target'], sm.add_constant(train_data_m[upd_features])).fit()\n",
    "    pred_m = model_m.predict(X_current).values[0]\n",
    "    agile_sim.loc[current_idx, 'Monthly'] = pred_m\n",
    "\n",
    "# Shift to t+1\n",
    "agile_plot = agile_sim.copy()\n",
    "# MODE 1 Fix: No Shift\n",
    "# agile_plot.index = agile_plot.index + 1\n",
    "agile_plot['Actual'] = df.reindex(agile_plot.index)['NET']\n",
    "\n",
    "# Calculate MAE\n",
    "agile_plot = agile_plot.dropna()\n",
    "mae_q = mean_absolute_error(agile_plot['Actual'], agile_plot['Quarterly'])\n",
    "mae_m = mean_absolute_error(agile_plot['Actual'], agile_plot['Monthly'])\n",
    "mae_w = mean_absolute_error(agile_plot['Actual'], agile_plot['Weekly'])\n",
    "\n",
    "print(f\"MAE Quarterly: {mae_q:.4f}\")\n",
    "print(f\"MAE Monthly:   {mae_m:.4f}\")\n",
    "print(f\"MAE Weekly:    {mae_w:.4f}\")\n",
    "\n",
    "# Plot\n",
    "last_act_val = df.loc[split_idx, 'NET']\n",
    "last_act_idx = split_idx\n",
    "\n",
    "plt.figure(figsize=(18, 7))\n",
    "act_s = make_seamless(agile_plot['Actual'], last_act_val, last_act_idx)\n",
    "plt.plot(act_s.index.map(safe_date_map), act_s, color=GRAY_DARK, alpha=0.3, linewidth=4, label='Actual')\n",
    "\n",
    "q_s = make_seamless(agile_plot['Quarterly'], last_act_val, last_act_idx)\n",
    "m_s = make_seamless(agile_plot['Monthly'], last_act_val, last_act_idx)\n",
    "w_s = make_seamless(agile_plot['Weekly'], last_act_val, last_act_idx)\n",
    "\n",
    "plt.plot(q_s.index.map(safe_date_map), q_s, color=GRAY_LIGHT, linestyle=':', linewidth=2, label='Quarterly')\n",
    "plt.plot(m_s.index.map(safe_date_map), m_s, color=BLUE, linestyle='--', linewidth=2, label='Monthly')\n",
    "plt.plot(w_s.index.map(safe_date_map), w_s, color=ORANGE, linewidth=4, label='Weekly')\n",
    "\n",
    "plt.title('Agility Spectrum (Q vs M vs W)', fontsize=16, fontweight='bold')\n",
    "plt.legend(); plt.grid(True, alpha=0.2); plt.show()\n",
    "\n",
    "# AGILITY VERDICT\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" AGILITY ANALÄ°ZÄ°: NEDEN 'WEEKLY' SEÃ‡Ä°LMELÄ°?\")\n",
    "print(\"=\"*80)\n",
    "print(f\"â€¢ Quarterly MAE: {mae_q:.4f} (Statik Model - YavaÅŸ Reaksiyon)\")\n",
    "print(f\"â€¢ Monthly MAE:   {mae_m:.4f} (Daha Ä°yi, ama Volatilitede GeÃ§ KalÄ±yor)\")\n",
    "print(f\"â€¢ Weekly MAE:    {mae_w:.4f} (ğŸ† EN Ä°YÄ° - AnlÄ±k Piyasa Adaptasyonu)\")\n",
    "print(\"-\" * 50)\n",
    "print(\"NEDEN?:\")\n",
    "print(\"1. Volatilite Yakalama: Piyasada faiz kararlarÄ± veya ÅŸoklar olduÄŸunda Weekly model hemen katsayÄ± gÃ¼nceller.\")\n",
    "print(\"2. Hata DÃ¼zeltme: Monthly model bir hata yaparsa dÃ¼zelmesi 4 hafta sÃ¼rer, Weekly model 1 haftada toparlar.\")\n",
    "print(\"3. DoÄŸruluk: MAE minimal dÃ¼zeydedir.\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e220255",
   "metadata": {},
   "source": [
    "# 12. STRATEGIC VERDICT\n",
    "Final durum Ã¶zeti.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "imp_static = -((mae_upd_static - mae_base_static)/mae_base_static)*100\n",
    "imp_retrain = -((mae_upd_dyn - mae_upd_static)/mae_upd_static)*100\n",
    "\n",
    "verdict_data = [\n",
    "    {\"Name\": \"Updated Base Model (Dynamic)\", \"Freq\": \"Weekly\",      \"MAE\": mae_upd_dyn,    \"Type\": \"Updated\"},\n",
    "    {\"Name\": \"Updated Base Model (Monthly)\", \"Freq\": \"Monthly\",     \"MAE\": mae_m,          \"Type\": \"Updated\"},\n",
    "    {\"Name\": \"Updated Base Model (Static)\",  \"Freq\": \"Never\",       \"MAE\": mae_upd_static, \"Type\": \"Updated\"},\n",
    "    {\"Name\": \"Legacy Base Model (Dynamic)\",  \"Freq\": \"Weekly\",      \"MAE\": mae_base_dyn,   \"Type\": \"Legacy\"},\n",
    "    {\"Name\": \"Legacy Base Model (Static)\",   \"Freq\": \"Never\",       \"MAE\": mae_base_static,\"Type\": \"Legacy\"}\n",
    "]\n",
    "\n",
    "verdict_df = pd.DataFrame(verdict_data).sort_values(\"MAE\").reset_index(drop=True)\n",
    "verdict_df[\"Rank\"] = verdict_df.index + 1\n",
    "\n",
    "table_md = \"| Rank | Model Name | Update Frequency | MAE (Error) | Status |\\n\"\n",
    "table_md += \"| :--- | :--- | :--- | :--- | :--- |\\n\"\n",
    "\n",
    "for _, row in verdict_df.iterrows():\n",
    "    rank = row[\"Rank\"]\n",
    "    name = row[\"Name\"]\n",
    "    freq = row[\"Freq\"]\n",
    "    mae = row[\"MAE\"]\n",
    "    status = \"\"\n",
    "    if rank == 1: status = f\"ğŸ† **{row['Type']}** ğŸ†\"\n",
    "    elif row[\"Type\"] == \"Updated\": status = \"Updated\"\n",
    "    elif row[\"Type\"] == \"Legacy\": status = \"Legacy\"\n",
    "    \n",
    "    if rank == 1:\n",
    "        table_md += f\"| **{rank}** | **{name}** | **{freq}** | **{mae:.4f}** | {status} |\\n\"\n",
    "    else:\n",
    "        table_md += f\"| {rank} | {name} | {freq} | {mae:.4f} | {status} |\\n\"\n",
    "\n",
    "final_text = f\"\"\"\n",
    "# 12. STRATEGIC VERDICT (SONUÃ‡ VE TAVSIYE)\n",
    "\n",
    "{table_md}\n",
    "\n",
    "### ğŸš€ WHY 'UPDATED BASE MODEL (DYNAMIC)' WINS?\n",
    "\n",
    "1.  **Memory (HafÄ±za):** `NET_lag1` (t-1) ve `NET_roll3` deÄŸiÅŸkenleri sayesinde model, piyasanÄ±n yakÄ±n geÃ§miÅŸteki momentumunu (Nowcast) kullanÄ±r.\n",
    "2.  **Agility (Ã‡eviklik):** HaftalÄ±k yeniden eÄŸitim sayesinde, Mode 1 yapÄ±sÄ±nda hatayÄ± Legacy Dynamic modele gÃ¶re **~%21** (MAE: 0.66 -> 0.52) oranÄ±nda dÃ¼ÅŸÃ¼rÃ¼r.\n",
    "\"\"\"\n",
    "display(Markdown(final_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f394b12c",
   "metadata": {},
   "source": [
    "# 13. EK E: DETAILED IMPACT ANALYSIS\n",
    "Bu bÃ¶lÃ¼m, modelin iÅŸleyiÅŸ mantÄ±ÄŸÄ±nÄ±, zigzaglarÄ±n sebebini ve riskleri analiz eder.\n",
    "\n",
    "### E.1. ZIGZAG ANALÄ°ZÄ° (AYNA ETKÄ°SÄ°)\n",
    "Grafiklerde gÃ¶rÃ¼len \"Actual dÃ¼ÅŸerken Prediction'Ä±n artmasÄ±\" (Ters Hareket) durumu bir hata deÄŸil, modelin **Lag1 (Momentum)** karakterinin sonucudur.\n",
    "\n",
    "*   **Sebep:** Modelin en gÃ¼Ã§lÃ¼ deÄŸiÅŸkeni `NET_lag1` (KatsayÄ±: +0.68).\n",
    "*   **Mekanizma:** Piyasa geÃ§en hafta yÃ¼kseldiyse, model bu hafta da yÃ¼kseleceÄŸini varsayar.\n",
    "*   **SonuÃ§:** Piyasa aniden dÃ¼ÅŸtÃ¼ÄŸÃ¼nde, model elindeki \"YÃ¼ksek GeÃ§miÅŸ\" verisiyle \"YÃ¼ksek Tahmin\" Ã¼retir. DÃ¼ÅŸÃ¼ÅŸÃ¼ ancak 1 hafta sonra (Veri sisteme girince) fark eder.\n",
    "*   **Yorum:** Bu \"Ayna Etkisi\" (Mirror Effect), Momentum modellerinin kaÃ§Ä±nÄ±lmaz bedelidir.\n",
    "\n",
    "### E.2. YAPISAL KISITLAR (Structural Constraints)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079fe926",
   "metadata": {},
   "source": [
    "# 14. STRATEGY SPECTRUM ANALÄ°ZÄ°\n",
    "Modelin baÅŸarÄ±sÄ±nÄ± hangi bileÅŸen saÄŸlÄ±yor?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d695b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "mom_features = base_features + ['NET_lag1'] # Momentum Only\n",
    "rev_features = base_features + ['NET_roll3'] # Trend Only\n",
    "df['GAP_SQ'] = (df['NET_lag1'] - df['NET_roll3']) ** 2\n",
    "stab_features = base_features + ['NET_lag1', 'NET_roll3', 'GAP_SQ'] # Stabilizer\n",
    "\n",
    "# Short Loop for Spectrum (Just Predictions for Plot)\n",
    "results_mom_dyn = []; results_rev_dyn = []; results_stab_dyn = []\n",
    "for current_idx in test_indices:\n",
    "    # Mom\n",
    "    train_m = df.iloc[:current_idx].dropna(subset=['Target'] + mom_features)\n",
    "    model_m = sm.OLS(train_m['Target'], sm.add_constant(train_m[mom_features])).fit()\n",
    "    results_mom_dyn.append(model_m.predict(sm.add_constant(df.loc[[current_idx], mom_features], has_constant='add')).values[0])\n",
    "    # Rev / Stab (omitted loop details for brevity in plot section as we focus only on lines)\n",
    "    train_c = df.iloc[:current_idx].dropna(subset=['Target'] + rev_features)\n",
    "    model_c = sm.OLS(train_c['Target'], sm.add_constant(train_c[rev_features])).fit()\n",
    "    results_rev_dyn.append(model_c.predict(sm.add_constant(df.loc[[current_idx], rev_features], has_constant='add')).values[0])\n",
    "    train_d = df.iloc[:current_idx].dropna(subset=['Target'] + stab_features)\n",
    "    model_d = sm.OLS(train_d['Target'], sm.add_constant(train_d[stab_features])).fit()\n",
    "    results_stab_dyn.append(model_d.predict(sm.add_constant(df.loc[[current_idx], stab_features], has_constant='add')).values[0])\n",
    "\n",
    "pred_mom_dyn = pd.Series(results_mom_dyn, index=test_indices)\n",
    "pred_rev_dyn = pd.Series(results_rev_dyn, index=test_indices)\n",
    "pred_stab_dyn = pd.Series(results_stab_dyn, index=test_indices)\n",
    "\n",
    "mae_mom = mean_absolute_error(df.loc[pred_mom_dyn.index, 'NET'], pred_mom_dyn)\n",
    "mae_rev = mean_absolute_error(df.loc[pred_rev_dyn.index, 'NET'], pred_rev_dyn)\n",
    "mae_stab = mean_absolute_error(df.loc[pred_stab_dyn.index, 'NET'], pred_stab_dyn)\n",
    "\n",
    "plt.figure(figsize=(18, 8))\n",
    "act_s = make_seamless(df.loc[test_indices, 'NET'], last_act_val, last_act_idx)\n",
    "plt.plot(act_s.index.map(safe_date_map), act_s, color=GRAY_DARK, alpha=0.3, linewidth=5, label='Actual')\n",
    "\n",
    "# Custom plot is better to match previous logic\n",
    "plt.plot(make_seamless(pred_rev_dyn, last_act_val, last_act_idx).index.map(safe_date_map), make_seamless(pred_rev_dyn, last_act_val, last_act_idx), color='purple', linestyle=':', linewidth=2, label=f'Trend Only ({mae_rev:.4f})')\n",
    "plt.plot(make_seamless(pred_mom_dyn, last_act_val, last_act_idx).index.map(safe_date_map), make_seamless(pred_mom_dyn, last_act_val, last_act_idx), color='blue', linestyle='-.', linewidth=2, label=f'Momentum Only ({mae_mom:.4f})')\n",
    "plt.plot(make_seamless(pred_stab_dyn, last_act_val, last_act_idx).index.map(safe_date_map), make_seamless(pred_stab_dyn, last_act_val, last_act_idx), color='green', linestyle='--', linewidth=2, label=f'Stabilizer ({mae_stab:.4f})')\n",
    "plt.plot(make_seamless(pred_upd_dyn, last_act_val, last_act_idx).index.map(safe_date_map), make_seamless(pred_upd_dyn, last_act_val, last_act_idx), color=ORANGE, linewidth=4, label=f'Combined Base ({mae_upd_dyn:.4f})')\n",
    "plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f528ada5",
   "metadata": {},
   "source": [
    "# 15. FINAL LEADERBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c35bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comp_final = pd.DataFrame({\n",
    "    'Model': ['Momentum + Trend (Base)', 'Momentum Only', 'Trend Only', 'Hybrid Stabilizer'],\n",
    "    'MAE (Dynamic)': [mae_upd_dyn, mae_mom, mae_rev, mae_stab]\n",
    "}).sort_values('MAE (Dynamic)')\n",
    "display(comp_final)\n",
    "winner = comp_final.iloc[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22b32d0",
   "metadata": {},
   "source": [
    "# 16. DEEP DIVE: MOMENTUM ONLY MODEL\n",
    "Sadece Momentuma (Lag1) dayalÄ± modelin detaylÄ± incelenmesi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b76800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. SETUP DATA (Static Momentum)\n",
    "mom_features = base_features + ['NET_lag1']\n",
    "train_data_mom = df.iloc[:split_idx].dropna(subset=['Target'] + mom_features)\n",
    "test_data_mom = df.iloc[split_idx:].dropna(subset=['Target'] + mom_features)\n",
    "\n",
    "print(\"Momentum Model Train Data (Tail - ONLY USED FEATURES):\")\n",
    "# Explicitly selecting only relevant features for display to avoid confusion\n",
    "display(train_data_mom[mom_features + ['Target']].tail(3))\n",
    "\n",
    "# 2. RUN STATIC\n",
    "model_mom_static = sm.OLS(train_data_mom['Target'], sm.add_constant(train_data_mom[mom_features])).fit()\n",
    "pred_train_mom = model_mom_static.predict(sm.add_constant(train_data_mom[mom_features]))\n",
    "pred_test_mom = model_mom_static.predict(sm.add_constant(test_data_mom[mom_features], has_constant='add'))\n",
    "\n",
    "# Score\n",
    "idx_common = pred_test_mom.index.intersection(df.index)\n",
    "mae_mom_static, rmse_mom_static = get_metrics(df.loc[idx_common, 'NET'], pred_test_mom[idx_common])\n",
    "plot_integrated(df, pred_train_mom, pred_test_mom, 'MOMENTUM STATIC', 'fig_mom1.png', test_start_date, 'blue')\n",
    "\n",
    "print_detailed_stats(model_mom_static, \"MOMENTUM STATIC\", None, None) # DataFrame arg irrelevant for print, passing None\n",
    "\n",
    "# 3. RUN DYNAMIC (Metric Collection)\n",
    "results_mom_dyn = []\n",
    "metrics_mom = {'r2': [], 'adj_r2': [], 'aic': [], 'cond_no': [], 'mse_resid': []}\n",
    "\n",
    "for current_idx in test_indices:\n",
    "    train_data = df.iloc[:current_idx].dropna(subset=['Target'] + mom_features)\n",
    "    model = sm.OLS(train_data['Target'], sm.add_constant(train_data[mom_features])).fit()\n",
    "    metrics_mom['r2'].append(model.rsquared)\n",
    "    metrics_mom['adj_r2'].append(model.rsquared_adj)\n",
    "    metrics_mom['aic'].append(model.aic)\n",
    "    metrics_mom['cond_no'].append(model.condition_number)\n",
    "    metrics_mom['mse_resid'].append(model.mse_resid)\n",
    "    \n",
    "    pred = model.predict(sm.add_constant(df.loc[[current_idx], mom_features], has_constant='add')).values[0]\n",
    "    results_mom_dyn.append(pred)\n",
    "\n",
    "pred_mom_dyn = pd.Series(results_mom_dyn, index=test_indices)\n",
    "idx_common = pred_mom_dyn.index.intersection(df.index)\n",
    "mae_mom_dyn, rmse_mom_dyn = get_metrics(df.loc[idx_common, 'NET'], pred_mom_dyn[idx_common])\n",
    "print(f\"MOMENTUM DYNAMIC MAE: {mae_mom_dyn:.4f}\")\n",
    "\n",
    "plot_integrated(df, pred_train_mom, pred_mom_dyn, 'MOMENTUM DYNAMIC', 'fig_mom2.png', test_start_date, 'blue')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2864b51",
   "metadata": {},
   "source": [
    "# 17. KARÅILAÅTIRMALI ANALÄ°Z: MOMENTUM vs UPDATED BASE\n",
    "Ä°statistiksel olarak neden Combined Base'in (veya Momentum'un) kazandÄ±ÄŸÄ±nÄ±n kanÄ±tÄ±.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f31345",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calc_full_metrics(model, df_full, split_idx, features):\n",
    "    # Train Metrics\n",
    "    train_mae = np.mean(np.abs(model.resid))\n",
    "    \n",
    "    # Train G-AUC (Historical)\n",
    "    train_data = df_full.iloc[:split_idx].dropna(subset=['Target'] + features)\n",
    "    pred_train = model.predict(sm.add_constant(train_data[features]))\n",
    "    gauc_train, _ = get_gauc_metrics(pd.DataFrame({'NET': train_data['Target'], 'PRED': pred_train}), 'PRED', 'NET')\n",
    "    \n",
    "    # Test Metrics\n",
    "    test_data = df_full.iloc[split_idx:].dropna(subset=['Target'] + features)\n",
    "    pred_test = model.predict(sm.add_constant(test_data[features], has_constant='add'))\n",
    "    \n",
    "    test_act = df_full.reindex(pred_test.index)['NET']\n",
    "    mae, rmse = get_metrics(test_act, pred_test)\n",
    "    # gauc_test removed as per request\n",
    "    \n",
    "    # Directional Accuracy (Sign Check)\n",
    "    dir_acc = np.mean(np.sign(test_act) == np.sign(pred_test))\n",
    "    \n",
    "    return {\n",
    "        'R-Squared': model.rsquared,\n",
    "        'Adj. R-Squared': model.rsquared_adj,\n",
    "        'AIC': model.aic,\n",
    "        'G-AUC (History)': gauc_train,\n",
    "        'Dir. Accuracy': dir_acc,\n",
    "        'Test MAE': mae,\n",
    "        'Condition Number': model.condition_number,\n",
    "        'Test N': len(test_act)\n",
    "    }\n",
    "\n",
    "# Static Compare\n",
    "m_upd = calc_full_metrics(model_upd_static, df, split_idx, upd_features)\n",
    "m_mom = calc_full_metrics(model_mom_static, df, split_idx, mom_features)\n",
    "\n",
    "comp = pd.DataFrame([m_upd, m_mom], index=['Combined Base', 'Momentum Only']).T\n",
    "comp['Diff'] = comp['Momentum Only'] - comp['Combined Base']\n",
    "\n",
    "def get_winner(row):\n",
    "    if abs(row['Diff']) < 1e-9: return 'Neutral'\n",
    "    if row['Diff'] < 0:\n",
    "        return 'Momentum' if any(x in row.name for x in ['Error', 'MAE', 'AIC', 'Condition']) else 'Combined'\n",
    "    else:\n",
    "        return 'Momentum' if any(x in row.name for x in ['R', 'AUC', 'Accuracy']) else 'Combined'\n",
    "\n",
    "comp['Winner'] = comp.apply(get_winner, axis=1)\n",
    "\n",
    "print(\"STATIC HEAD-TO-HEAD:\")\n",
    "display(comp)\n",
    "\n",
    "# Dynamic Compare\n",
    "def aggregate_dyn_metrics(metrics_dict, pred_series, df_full, split_idx):\n",
    "    idx_common = pred_series.index.intersection(df_full.index)\n",
    "    test_act = df_full.loc[idx_common, 'NET']\n",
    "    mae, rmse = get_metrics(test_act, pred_series[idx_common])\n",
    "    dir_acc = np.mean(np.sign(test_act) == np.sign(pred_series[idx_common]))\n",
    "    \n",
    "    return {\n",
    "        'R-Squared (Avg)': np.mean(metrics_dict['r2']),\n",
    "        'AIC (Avg)': np.mean(metrics_dict['aic']),\n",
    "        'Condition Number (Avg)': np.mean(metrics_dict['cond_no']),\n",
    "        'Test MAE': mae,\n",
    "        'Dir. Accuracy': dir_acc\n",
    "    }\n",
    "\n",
    "m_upd_dyn = aggregate_dyn_metrics(metrics_upd, pred_upd_dyn, df, split_idx)\n",
    "m_mom_dyn = aggregate_dyn_metrics(metrics_mom, pred_mom_dyn, df, split_idx)\n",
    "\n",
    "comp_dyn = pd.DataFrame([m_upd_dyn, m_mom_dyn], index=['Combined Base (Dynamic)', 'Momentum Only (Dynamic)']).T\n",
    "comp_dyn['Diff'] = comp_dyn['Momentum Only (Dynamic)'] - comp_dyn['Combined Base (Dynamic)']\n",
    "comp_dyn['Winner'] = comp_dyn.apply(get_winner, axis=1)\n",
    "\n",
    "print(\"DYNAMIC HEAD-TO-HEAD:\")\n",
    "display(comp_dyn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5425634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# FINAL VERDICT LOGIC\n",
    "# Trade-off: Momentum wins on MAE, Combined wins on R2/AIC.\n",
    "r2_diff = m_mom_dyn['R-Squared (Avg)'] - m_upd_dyn['R-Squared (Avg)'] # Negative means Mom is worse\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(\"ğŸ¯ SONUÃ‡ VE KARAR (VERDICT)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Decision Tree\n",
    "if r2_diff < -0.05: # Combined Explains Variance Much Better\n",
    "    print(f\"Liderlik tablosu 'Hata' ile 'Kalite' arasÄ±ndaki net takasÄ± gÃ¶sterdi.\")\n",
    "    print(f\"Åampiyon: **Updated Base Model (Dynamic)**\")\n",
    "    print(f\"\\nNEDEN MAE DAHA YÃœKSEK OLMASINA RAÄMEN 'COMBINED BASE' KAZANDI?\")\n",
    "    print(f\"1. **AÃ§Ä±klayÄ±cÄ±lÄ±k GÃ¼cÃ¼ (R2):** Combined model, piyasa hareketlerinin **%{m_upd_dyn['R-Squared (Avg)']*100:.1f}**'ini aÃ§Ä±klarken, Momentum sadece **%{m_mom_dyn['R-Squared (Avg)']*100:.1f}**'ini aÃ§Ä±klÄ±yor.\")\n",
    "    print(\"2. **Bilgi Kalitesi (AIC):** Combined Model'in AIC skoru daha iyi (DÃ¼ÅŸÃ¼k). Bu, ekstra deÄŸiÅŸken (Trend) kullanmanÄ±n buna deÄŸdiÄŸini matematiksel olarak kanÄ±tlar.\")\n",
    "    print(\"3. **Stratejik SaÄŸlamlÄ±k:** Momentum Only modeli 'KÃ¶r UÃ§uÅŸ' yaparken (DÃ¼ÅŸÃ¼k R2, YÃ¼ksek Varyans), Combined Model yolu gÃ¶rerek gider. 0.02'lik hata farkÄ± iÃ§in bu 'GÃ¶rÃ¼ÅŸ YeteneÄŸi'nden vazgeÃ§ilemez.\")\n",
    "    print(\"\\nSONUÃ‡: Mode 1 (Nowcast) iÃ§in en gÃ¼venilir yapÄ± **Combined Base** (Trend + Momentum) yapÄ±sÄ±dÄ±r.\")\n",
    "\n",
    "elif winner['Model'] == 'Momentum Only':\n",
    "    print(f\"Åampiyon: **Momentum Only**\")\n",
    "\n",
    "else:\n",
    "    print(f\"Åampiyon: **{winner['Model']}**\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
